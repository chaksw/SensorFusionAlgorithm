# SensorFusion - 多传感器数据融合

## Sujet de stage - 基于摄像头与雷达数据（多传感器数据融合）的ADAS环境感知、定位及路径规划研究 - 暂定

#感知 # 定位 # 规划 # 决策 # 控制 # 组合导航 # 多传感器融合 

### 实习项目说明 - Fiche de formalisation

在智能驾驶领域中，基于Sensor Fusion多传感器数据融合技术实现的环境感知、路径跟踪与规划以及最终的自动驾驶控制在近年来得到广泛的重视和应用。

在本次实习中，我将研究如何从汽车领域中应用较多的几类传感器（摄像头、超声波雷达、毫米波雷达、红外雷达等）中获得的数据构建多传感器数据融合系统，并通过系统实现ADAS中的环境感知、路径规划。

由于多传感器数据融合是一个多学科的研究领域，在对于构建整个多传感器关联数据处理系统中，我将着重研究一下几个方面：

1.  几类广泛应用于汽车领域的传感器的物理信号响应原理及实际应用中的选型（依据）
2.  对传感器信号处理过程中的用到的各种算法。
3.  多传感器数据融合处理系统构建的一些基本原理、方案、具体实现方法以及其优缺点

在构建传感器系统后，我将结合对现实中各种干扰背景下（如天气、杂乱回波）的分析，对实现环境的允许下对系统进行仿真测试。

如上述提到，多传感器数据融合是一个多学科的研究领域，但事实上，该项目的研究将涉及到我在硕士阶段所学习的多个内容，其中包括：1：基于各类原理实现的传感器技术（电磁传感器、光学传感器、红外传感等）及其信号处理（数字信号处理、图像信号处理），2：多传感器数据融合系统构建涉及的统计学各类算法基础知识（贝叶斯推理、虚拟传感器、机器学习等）。

同时，目前涉及该项目研究的一些学科的研究已经相当成熟，这为我在完备研究内容提供了良好的新知识补充环境。而我将要工作的智能驾驶部门有着十分成熟先进的研发经验和技术实力，能提供对于该研究于实际应用中的实践经验知识以及基于Matlab+Simulink实现系统及测试环境搭建上的协助。这让我有信心能够在该部门工作的过程中完成我对于该项目的研究。

### 实习合同信息 - Fiche contractuelle

北京经纬恒润科技有限公司（HiRain Technologies）AE AD智能驾驶部致力于提供智能驾驶涵盖的环境感知、决策规划、控制执行、系统集成等智能驾驶全栈解决方案。部门针对L2，L3级别的ADAS自动驾驶（[SAE J3016](https://www.sae.org/news/2019/01/sae-updates-j3016-automated-driving-graphic)）需求，融合毫米波雷达、摄像头模组等器件数据，设计出能稳定检测出驾驶环境和道路设施的识别算法及路径预测算法，并精确建模描述车道线、路缘、隔离带等多种路面信息。

在本次实习中，实习生将就目前部门研发的数据融合系统及算法进行实际场景的仿真测试，校验及参数调整相关工作，具体地，实习生将负责：

1.  协助环境感知、决策、路径规划、导航定位等算法的开发、维护和测试
2.  根据应用场景需求，利用Matlab+Simulink搭建仿真开发及测试环境。
3.  负责各类算法的调研并撰写相关报告。

在实习过程中，在完成实习工作的基础上，部门将为实习生的项目研究提供：

1.  数据融合系统及相关算法的知识指导。
2.  基于Matlab+Simulink的仿真测试环境搭建实践
3.  其余在不触犯保密协议下，完成项目的技术知识指导和协助。

### Fiche de formalisation

Dans le domaine de ADAS (Advanced Driver Assistance Systems), la perception de l'environnement, le suivi et la planification des trajectoires et en final, le contrôle de conduite automatique basé sur la technologie Sensor Fuision ont réçu une attention et des applications approfondies de plus en plus ces dérnières années.

Pendant ce stage, ma étude sera dérouler sur la construction d'un système de Sensor Fusion à partir des données obtenus à partir de plusieurs type de capteurs (caméras, radars à ultrasons, radars à ondes millimétriques, radars infrarouges, etc...) qui sont largement utilisés dans le domaine automoblie, et plusieur algorithmes seront réalisés à travers le système Sensor Fusion concernant la perception de l'environnement, le suivi et la planification des trajectoires.

Comme le Sensor Fusion étant un domaine de recheche multidisciplinaire, je me concentrerai sur les procésure suivants:

1.  Pricipe de réponse physiaue du signal de plusieurs types de capteurs largement utilises dans le domaine automobile et le fondement de sélection des capteurs dans des applications pratiques.
2.  Réalisation de divers algorithmes utilisés pour le traitement du signal de capteur.
3.  les principes de base de système Sensor Fusion et les algorithmes le plus utilisés pour construcire un système Sensor Fusion.

À partir de système Sensor Fusion construit, des tests de simulation sur le système sera mise en œuvre en combinerant l'analyse de divers l'interférences dans la réalité (comme la météo, l'écho de fouillis)  sur Matlab.

Le Sensor Fusion est un domaine de recheche multidisciplinaire. En fait, ce projet porte sur plusieurs discipline que j'ai étudié pendant le master: 1:Techonologie de capteurs base sur  divers principles (optique, ultrason, électromagnétique, etc...). 2: traitement du sigal numérque et des images. 3: des connaissances fondamentales de statistiques et de capteur virtuel qui sont les base de algorithme de Sensor Fusion.

Dans le même temps, Le département de conduite intelligente dans lequel je travaillerai possède une expérience en R&D très mature et avancée et une force technique, et peut fournir une expérience pratique et une assistance dans la mise en œuvre du système et de l'environnement de test basé sur Matlab + Simulink. 

### Fiche contractuelle

Le département ADAS qui dépend de HiRain Technologies s'engage à fournir des solutions complètes de conduite intelligente couvrant la perception de l'environnement, la planification des décisions, l'exécution des contrôles et l'intégration du système. Le département répond aux besoins de la conduite autonome ADAS L2 et L3 ([SAE J3016](https://www.sae.org/news/2019/01/sae-updates-j3016-automated-driving-graphic)) et intègre le radar à ondes millimétriques, le module de caméra et d'autres données de l'appareil conçoivent un algorithme de reconnaissance et un algorithme de prédiction de trajectoire capables de détecter de manière stable l'environnement de conduite et les installations routières, et de modéliser et de décrire avec précision diverses informations routières telles que les lignes de voie, les bordures et les ceintures d'isolation.

Dans ce stage, les stagiaires effectueront des tests de simulation, des vérifications et des ajustements de paramètres liés à la scène réelle à partir du système et des algorithmes de Sensor Fusion développés par le département actuel. Plus précisément, les stagiaires seront chargé sur :

1.  Aider au développement, à la maintenance et aux tests d'algorithmes de la perception de l'environnement,  de la prise de décision, de la planification des chemins, et de la navigation.
2.  Utilisez Matlab + Simulink pour créer un environnement de développement et de test de simulation selon les exigences des scénarios d'application, 
3. chargé sur  la recherche de divers algorithmes et rédiger des rapports connexes.

Au cours du processus de stage, le département mettra à disposition des stagiaires pour la recherche du projet:

1. Connaissance du système de Sensor Fusion et des algorithmes associés.
2. Expérience de l'environnement de test de simulation basé sur Matlab + Simulink
3. Autres connaissances techniques, conseils et assistance pour mener à bien le projet.

## Questionnaire

-   过去工作（转部门前），工作部门（AE- 内外饰电控技术部）、相关的工作（测试、脚本、音乐节拍算法）
-   过去工作（转部门后），转岗时间刚好赶上了国庆假期，所以今天是第一天正式工作，阅读了CDS使用手册。

De 1 octrobre à 8 octrobre est la fête national de la Chine, donc en fait j'ai commencé mon travail depuis aujourd'hui. et comme je vous'ai dit, j'ai changer le département, avance j'ai travailé dans le départment qui s'engage au dévelopement de composant à l'inférieur d'une voiture(softwave et hardwave), j'ai chargé principalment sur les petits project comme programmer le scénario et l'algorithme.

j'ai lit les manuels.

les travail à venir, il y a pas un project ou un recherche très precicé, mon travaille est principalement:

-   utilisation de CDS (cloud data server) pour l'analyse des données émanées de capteurs (caméra Lidar Radar à ondes millimétrques)  et output d'algorithme, écrit un rapport à partir de l'analyse.
-   évaluation de performance des capteurs, ctd évaluer s'il y a des data erroné ou fraudé de l'algorithme de fusion. 
-   échantillonnage de data par utilisant CANoe.
-   recherche de l'algorithme de perception, lire les document et les résumé pour finalement faire un demo de l'algorithme 

-   未来工作 
    1.  基于CDS (cloud data server )工具链使用，传感器评估算法的开发和优化，传感器感知数据分析，相关报告的撰写。
    2.  传感器性能（摄像头、激光雷达、毫米波雷达）融合算法输出数据的误报(data erroné)漏报(data fraudé)情况，测试与分析：包含传感器数据采集 (Data sampling)，CANoe (Controller Area Network)使用 (capl - CAN Access Programming Language)，数据分析(Data Analyse)
    3.  感知工作调研 (recherche de l'algorithme de perception)：包含文献调研，形成概述，传感器数据采集算法demo协同开发。

## 自动（无人）驾驶 Self-Driving 

### 工作原理

无人驾驶包括五个核心部件，计算机视觉 (Computer Vision)、**传感器融合 (Sensor Fusion)**、定位(Location)、路径规划 (Path planning)、控制 (Control)。这些核心部件涉及了**高精地图、定位、感知、预测、规划、控制**等模块知识。

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1l2s9tij30m80bst91.jpg)

其中我们使用CV (Computer Vison) 和 Sensor Fusion，获取一副关于我们在世界的位置上的丰富画面（高精地图、感知）、使用定位确定我们在这个世界的精确位置（定位），然后使用路径规划 (Path planning) 来绘制一条通过这个世界到达目的地的路径（预测、规划），通过控制移动车辆（控制）。从本质上讲，其他一切无人车都是这些核心功能更复杂的实现。

### 高精地图

高精地图主要服务于自动驾驶车辆，通过一套独特的导航体系，帮助自动驾驶解决系统性能问题，扩展传感器检测边界。高精地图（以Apollo为例）主要应用在高精定位、环境感知、决策规划、仿真运行四大场景。

**高精地图是无人驾驶技术不可或缺的一部分，**它包含了大量驾驶辅助信息，最重要包含道路往的精确三维表征（交叉路口布局和路标位置、附近建筑物、树、行人等地标位置信息）

另外，高精地图包含了大量的语义信息，包括交通灯不同颜色的含义，路标标志含义、车道（左转道、直道、右转道）的含义

而高精地图最最重要的特征，就是**精度**，手机上的导航地图只能达到米级进度，而高精地图可以使车辆达到厘米级精度，这对确保无人车的安全性至关重要。

高精度地图的构建由五个过程组成：**数据采集、数据处理、对象检测、手动验证和地图发布**。

......

**数据采集**是一项庞大的密集型任务，近300辆Apollo测试车辆负责收集用于制作地图的源数据，以便确保每次道路发生改变时，地图均会得到快速更新。测试车辆使用了多种传感器，如GPS、IMU、激光雷达（LiDAR）、[雷达(RaDAR)](https://baike.baidu.com/item/%E9%9B%B7%E8%BE%BE%E6%B3%A2%E6%AE%B5/14118316)、摄像机。Apollo定义了一个硬件框架，将这些传感器集成到单个自主系统中，通过支持多种类的传感器，Apollo收集各类数据将这些数据融合，最终生成高精度地图。

......

#### 高精地图用于定位

无人车的整个定位过程都取决于高精度地图，在对无人驾驶车进行定位过程中，我们需要**根据各类传感器收集到的数据（摄像机图像数据、激光雷达收集的三维点云数据等）来查找地标。然后与高精地图上的已知地标进比较**，这个匹配过程是需要**预处理、坐标转换、数据融合**的复杂过程

#### 高精地图之于感知

无人车可以通过高精地图来**协助感知**，在自动驾驶中，无人车通过各类传感器进行感知，而感知过程就像（目的是模仿）人通过眼睛和耳朵感知身边环境。而就像人的眼睛和耳朵会收到环境因素的影响一样，摄像机、激光雷达、雷达探测物体的能力在超过一定距离或在恶劣天气｜环境下会受到限制。或者，当车辆遇到障碍物时，传感器无法透过障碍物来确定障碍物后面的物体，进而无法完成准确的感知->决策->规划的过程。这时借助高精地图存储的数据（相关信息），将相应缺少的信息提供给软件栈的其余部分，补充感知过程，帮助车辆完成一个决策。

另一个好处在于，高精地图可帮助传感器缩小检测范围。如高精地图可能告知我们在特定位置寻找停车标志，传感器可以进中在该位置（被称为**感兴趣区域ROI - Region Of Interest**）检测停车标志，帮助我们提高检测精确度和速度，节约计算资源。

#### 高精地图之于规划

高精地图可帮助车辆识别车道的确切中心线，这样车辆可以尽可能地靠近中心行驶。在具有低速限制、人行横道或减速带的区域，高精地图可以使车辆能够提前查看并预先减速。如果前方有障碍物，车辆可能需要变道，可帮助车辆缩小选择范围，以便选择最佳方案。

### 定位 - Location 重点 GPS + IMU + 激光雷达 多传感器数据融合定位系统

#定位第9讲

#### 定位 #1 GPS + IMU 

[参考资料](https://mp.weixin.qq.com/s/KJbm4wfsTLxT5LGR7GV_SA)

##### 基于GNSS + RTK 定位

通过卫星系统+地面卫星控制站+手机｜汽车等设备上的卫星信号接收器获得设备位置，进一步可以结合RTK（实时运动定位）,通过地面上位置（坐标）已知的基站，基站同时接受卫星测量出的基站信息，结合真实值和测量值获得误差参考值，来矫正卫星测量出的设备的坐标。

优点是数据精确，缺点是卫星的数据更新速度较慢 (10Hz)，适合长时间的定位

##### 惯性导航

惯性测量单元 - IMU 由加速度计和陀螺仪组成，优点是数据更新速度快 (1kHz， 接近实时)，缺点是运动误差会随时间增大，适合短时间内的定位。

**结合 GPS 和 IMU 进行数据融合定位，可以让两种定位方式实现互补**，但当汽车驾驶在山谷、城市偏僻区域、或者隧道等可能长时间无法获取GPS数据的地方时，这种数据融合定位的方法并不能提供准确的定位信息

#### 定位 #2 激光雷达定位 - 基于激光雷达数据的定位算法 

迭代最近点 ICP

直方图滤波 (Histogram Filter) - SSD

卡尔曼滤波 (Kalman Filter)

#### 定位 #3 视觉定位 - 粒子滤波

### 感知 - Perceive

在无人驾驶领域，主体（无人车、无人机、无人船等）通过**摄像头、雷达、激光雷达**等传感器测量出的海量数据（主体原始距离、与周围环境物理的距离），来模仿人脑理解这个世界的能力。这个模仿的过程涉及神经网络（Neural Networks）、人工智能 （Artificial intelligence）、机器学习 （Machine learning）等知识。

CNN - 卷积神经网络 Sensor Fusion 传感器数据融合

在无人驾驶中，主要有4个感知世界的核心任务：

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1l87ayoj30m80axwes.jpg)

1.  检测 - Detection，检测出物体的“存在”，并找出物体在环境中的位置
2.  分类| 识别 - Classification | Identification  ，明确对象是什么
3.  跟踪 - Tracking，随时间的推移观察移动的物体
4.  语义分割  - Segmentation，将图像的每个像素（pixel）与语义类别进行匹配（分辨出他是什么，如道路、汽车、天空）

感知的输入数据一般为**摄像头图像、雷达测量的数据、激光雷达测量的点云图（空间信息）**

#### 分类器

将分类作为作为研究计算机视觉一般数据流程的例子。图像分类器是一种将图像作为输入，并输出标识该图像的标签的算法，例如交通标志分类器查看停车标志并识别它是停车标志、让路标志、限速标志、其他标志。分类其甚至可以识别行为，比如一个人是在走路还是在跑步。

分类器有很多种，但它们都包含一系列类似的步骤。首先计算机接收类似摄像头等成像设备的输入。然后通过预处理发送每个图像，预处理对每个图像进行了标准化处理，常见的预处理包括调整图像大小、旋转图像、将图像从一个色彩空间转换为另一个色彩空间，比如从全彩到灰度，处理可帮助我们的模型更快地处理和学习图像。接下来，提取特征，特征有助于计算机理解图像，例如将汽车与自行车区分开来的一些特征，汽车通常具有更大的形状并且有四个轮子而不是两个，形状和车轮将是汽车的显著特征。最后这些特征被输入到分类模型中。此步骤使用特征来选择图像类别，例如分类器可以确定图像是否包含汽车、自行车、行人、不包含这样的对象。

#### 机器学习

#### 神经网络

卷积神经网络（CNN - Convolutional neural networks）

#### 反向传播法

#### 传感器数据融合&卡尔曼滤波

#### 传感器数据及其测量性能比较

![image-20200916141652212](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1ld8os1j314a0icjzl.jpg)

### 预测 - Prediction 实时性&准确性

预测是指在通过感知获取主体及主体周边环境各种物体的位置后，对周边物体的运动进行运动航迹预测的方法。有两种基本预测类型 - 基于模型&基于数据驱动

#### 递归神经网络 - RNN

### 规划 - Planning

规划是在定位获取主体位置、感知获取周围环境情况、预测到周围环境物体的运动航迹后，对主体本身运动航迹及行驶路径的规划方法。

#### 路线导航

规划的第一步是路线导航，**侧重于研究如何从地图上的A点前往B点**，在路线导航时，将地图数据作为输入，并输出可行驶路径。手机导航系统是路线导航的一个示例。一旦我们构建出高水平的路线，我们就会放大至航迹规划。该航迹由一系列点定义，**每个点都有一个关联速度和一个指示何时应抵达那个点的时间戳。**通过航迹规划，我们可以做出微妙的决策，以**避开障碍物**。路线规划的目标是，**找到从地图上的A前往B的最佳路径。航迹规划的目标是找到避免碰撞和保持舒适度的可执行航迹。**

路径规划使用三个输入，第一个输入为地图，包括**公路网和实时交通信息**。第二个输入为我们当前在地图上的**位置**。第三个输入为我们的**目的地**，目的地取决于车辆中的乘客。

##### 图

当人们试图在地图上找到从A到B的路线时，通常会沿着道路追踪路径，以查看是否存在通往目的地的任何路径，这被称为**搜索**。在进行智能搜索算法以前，我们需要将地图数据重新格式化为“**图形**”的数据结构。该图形由**“节点”(node)和“边缘”(edge)**组成。节点代表路段，边缘代表这些路段之间的连接。

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1li3ad4j30ia0bewer.jpg)

路径搜索和规划的根本思想在于对起点到目的地的**所需成本**进行建模。

##### 路径搜索算法 - A* 算法

[基本原理](https://mp.weixin.qq.com/s/ZBHKDtnaEI9sVCfEfeeUlQ)

#### 航迹生成

通过搜索算法，我们为从A点到B点生成了一个地图上的导航线路，但这只是规划过程的一部分，我们仍需要构建沿这条路线前进的低等级航迹。这意味着在实际的车辆行进过程中，我们需要与一些不存在地图上的物体进行“互动”，**通过定位、感知和预测获得的结果规划一条更高精度度的航迹**。

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1lp6x66j30ja0bfmxl.jpg)

航迹生成的目标是生成一系列路径点所定义的航迹。我们为每个路径点分配了一个**时间戳和速度**。由于移动的障碍物可能会暂时阻挡部分路段，航迹中的每个路径点都有时间戳。**我们可以将时间戳与预测模块的输出相结合，以确保我们计划通过时，航迹上的每个路径点均未被占用。**这些**时间戳和空间上的两个维度（2D position）共同创建了一个三维航迹（3D  Trajectory）**。我们还为每个路径点指定了一个速度，用于确保车辆按时到达每个路径点。

>   现实世界中的规划面临多种约束。首先航迹应能免于碰撞，这意味着必须没有障碍物。其次，要让乘客感到舒适，所以路径点之间的过渡以及速度的任何变化都必须平滑。再者，路径点对车辆应实际可行，例如高速行驶的汽车不能立即做180度转弯。我们不能构建包含这种不可行机动的航迹。最后，航迹应合法。我们需要了解每个路径点的交通法律，并确保航迹遵守这些法律法规。
>
>   在道路的任何两点，可能会有多个不会发生碰撞、行驶舒适、可行且合法的航迹。我们如何选择最佳航迹呢？答案是使用**“成本函数”**。**成本函数为每个航迹分配了一个“成本”，我们选择成本最低的航迹。航迹“成本”由各种犯规处罚组成，例如：偏离道路中心，有可能产生碰撞，速度限制，航迹的曲率和加速度让乘客感到不舒服等。**
>
>   ![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1lx15zyj30lu0bpt94.jpg)

##### 总结

规划分为两个基本步骤，一个是基于地图信息的整体路线导航规划，这个步骤主要是通过搜索算法解决从起始点到目的地的线路选择问题，第二个是在依据导航规划的线路行驶的过程中，通过定位、感知、预测的结果进行车辆行驶航迹的规划，得到多条“成本”不一的航迹，在通过成本函数分析出最佳航迹。**航迹规划的最终目的是构建一条不会发生碰撞的合理合法的路线**，关于航迹规划的方法有两种，路径-速度解耦规划和Lattice规划

#### 路径-速度解耦规划

**路径-速度解耦规划**将航迹规划分为两步：**路径规划**、**速度规划**。首先在路径规划步骤中生成候选曲线，这是车辆可行驶的路径。**使用成本函数对每条路径进行评估**，该函数包含平滑度、安全性、与车道中心的偏离以及开发者想要考虑的其他任何因素。然后按成本对路径进行排名并选择成本最低的路径。

下一步是确定沿这条路线行进的速度。我们可能希望改变在该路径上的速度，所以真正需要选择的是与路径点相关的一系列速度，而不是单个速度。我们将该序列称作“速度曲线”。我们可以使用优化功能为路径选择受到各种限制的良好速度曲线。通过将路径和速度曲线相结合可构建车辆行驶航迹。

##### 路径规划 - 路径生成与选择

路径的生成是指**生成候选路径**，首先将路段分割成单元格，然后对这些单元格中的点进行随机采样。通过从每个单元格中取一个点并将点连接创建候选路径。重复此步骤可以获取多个候选路径。然后使用成本函数对这些路径进行评估并选择成本最低的路径，成本函数可能考虑以下因素：与车道中心的偏离、与障碍物的距离、速度和曲率的变化、对车辆的压力等等，我们也可以根据实际场景分析列入任何其他因素。

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1m3dgktj30u00axgm1.jpg)

##### ST图

根据成本函数得出最佳路径后，我们需要选择与该路径关联的速度曲线，一个被称为“ST 图” 的工具可以帮助设计和选择速度曲线。

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1v2ghf8j30ji0bbaas.jpg)

在ST图中，`s`表示车辆的纵向位移、`t`表示时间。ST图上的曲线是对车辆运动的描述，她说明了车辆在不同时间的位置，由于速度是位置变化的速率$v = \frac{s}{t}$，所以可以通过查看曲线的斜率从ST图上推断速度。在ST图中，**斜率越大表示更短时间内有更大的波动，对应更快的速度**。

##### 速度规划

为构建最佳速度曲线，我们将ST图离散称多个单元格。**单元格之间的速度有所变化，但在每个单元格内速度保持不变，**该方法可以简化速度曲线的构建并维持曲线的近似度。同时，我们可以在ST图上模拟行驶时可能遇到的障碍情况及相应的处理手段。例如，假设预测模块预测到在$t_0$到$t_1$的时间段将有车辆驶入车道。由于该车在此期间占据了$s_0$到$s_1$的位置，为避免碰撞，速度曲线不得与此矩形相交，而达到“不相交”的情况对应的速度曲线有很多种，我们可以使用优化引擎为该图选择最佳的速度曲线。优化算法通过复杂的数学运算来搜索受到各种限制的低成本解决方法。这些限制可能包括：法律限制、如限速；距离限制：即与障碍物的距离；汽车的物理限制，如加速度限制。

##### 优化

**路径-速度解耦规划**的性能很大程度取决于离散化。路径选择涉及将道路划分为单元格，速度曲线构建涉及将ST图划分为单元格。尽管离散化使这些问题更容易解决，但如果离散化程度过低，得出的航迹往往并不平滑。

为了将离散解决方案得出的航迹转换成平滑航迹，可使用”二次规划“技术 (Quadratic Programming)。二次规划将平滑的非线性曲线与这些分段式线性段拟合。**尽管二次规划背后的数学运算很复杂，但对于我们的目的而言，细节并不是必需的。我们只需简单实用几种不同的优化包种的一种**。

##### 总结

回顾一下**端到端路径-速度解耦规划**。假设我们正在路上行驶，**感知系统**观察到一辆缓慢行驶的车辆离我们越来越近。首先，在这辆车的周围生成多条候选路线，**使用成本函数对这些候选路径进行评估并选择成本最低的路径。**然后**使用 ST 图来进行速度规划**，根据其他车辆随时间变化的位置**在ST 图中画出的阻挡的部分区域**。优化引擎可帮助确定该图的最佳速度曲线，该曲线受制于约束和成本函数。我们可以使用二次规划让路径和速度曲线变平滑。最后，将路径和速度曲线合并构建航迹。这里的航迹在速度较快时为红色，在速度较慢时为蓝色。我们使用该航迹来安全地绕开其他车辆并继续我们的旅程。

#### Lattice 规划

Lattice 航迹规划是通过使用 Frenet 坐标将环境投射到纵轴和横轴上，生成三维航迹：纵向维度；横向维度；时间维度。

##### Frenet 坐标系

大多数位置分析中，我们都使用笛卡尔坐标系来描述物体的位置，但笛卡尔坐标对车辆来说并不是最佳选择。即使给出了车辆位置$(x,y)$，如果我们不知道道路的位置，就无法判断车辆行驶情况（走了多远，是否偏离了道路中心）。

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1v35wrcj30gt0agdfw.jpg)

为此，我们替代解决方案是使用 **Frenet 坐标系**。Frenet坐标系描述了汽车相对于道路的位置。在Frenet框架中，**$s$代表了沿道路的距离，也被称为纵坐标**，$d$ 表示与纵向线的位移，也被称为横坐标，在道路的每个点上，横轴和纵轴都是垂直的。纵坐标表示道路的行驶距离，横坐标表示汽车偏离中心线的距离。

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1v3nrj5j30fs09u3yi.jpg)

使用 Lattice 航迹规划，我们将三维问题分解成两个单独的二维问题，这是痛殴分离航迹的纵向和横向分量来解决的。其中**一个二维航迹具有时间戳的纵向航迹称之为ST航迹（也就是ST图）**，另**一个二维航迹是相对于纵向航迹的横向偏移，称之为SL航迹。**

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1v444faj30jc0a2wei.jpg)

Lattice 规划分别建立 ST 和 SL 航迹，然后将它们合并称生成纵向和横向二维航迹。先将初始车辆状态投射到ST坐标系和SL坐标系中，通过对预选模式中分析出的的多个候选最终状态进行采样。对于每个候选最终状态构建了将车辆从初始状态转换为最终状态的候选航迹，使用成本函数对这些航迹评估并选择成本最低的航迹。

##### ST航迹的最终状态

根据情况可以将状态分成 3 组：**巡航** 、**跟随**、**停止**。这三种状态的核心参数都是速度和加速度

-   巡航意味着车辆将在完成规划步骤后定速行驶，实际上在对图上的点进行采样，在图中横轴代表时间，纵轴代表速度。对于该图上的点，这意味着汽车将进入巡航状态，在时间 t 以 s 点的速度巡航，**对于这种模式，所有最终状态的加速度均为零。**

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1v4jieyj30iy09wdg8.jpg)

-   下一个要考虑的模式为跟随车辆，在这种情况下要对位置和时间状态进行采样，并尝试在时间t出现在某辆车后面，在跟随车辆时，需要与前方的车保持安全距离，**这时速度和加速度将取决于要跟随的车辆，这意味着在这种模式下，速度和加速度都会进行修正。**

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1v502zkj30ka0azdg0.jpg)

-   最后一种模式是停止，对于这种模式只需对汽车何时何地停止进行抽样，**这里速度和加速度会被修正为 0 。**

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1v5z90rj30lx0b13yp.jpg)

##### SL航迹的最终状态

根据这样一个假设来进行SL 规划，即无论车辆进入怎样的终止状态，车辆都应该稳定地与车道中心线对齐。这意味着只需要在一个小区域内，对横向终止位置进行采样。具体来说采样的是道路上相邻车道中心线周围的位置。为了确保稳定性，汽车驶向的终止状态应该与车道中心一致。当用横向位置与纵向位置作图时 ，想要的候选航迹应该以车辆与车道对齐并直线行驶而结束。为了达到这种终止状态，**车的朝向和位置的一阶和二阶导数都应该为零。这意味着车辆既不是横向移动的，那是一阶导数；也不是横向加速，那是二阶导数。这意味着车辆正沿着车道直行。**

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1v6vx7bj30gz0bhglo.jpg)

##### 航迹生成

一旦同时拥有了 ST 和 SL 航迹，就需要将它们重新转换为笛卡尔坐标系。然后可以将它们相结合构建由二维路径点和一维时间戳组成的三维航迹。ST 航迹是随时间变化的纵向位移，SL 航迹是纵向航迹上每个点的横向偏移。**由于两个航迹都有纵坐标 S，所以可以通过将其 S 值进行匹配来合并航迹。**

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1v7sljwj30ik0bmglo.jpg)

### 控制

控制是**实现航迹拟合**的过程，即控制器使用一系列店接受规划输出的路径航迹信息，然后使用控制输入让车辆通过这些的路径点。对汽车而言，最基本的输入为转向、加速和制动。

>   首先，控制器必须**准确**，这意味着它应避免偏离目标航迹。这对于安全来说，尤为重要。即使路面潮湿或者道路比较陡峭，控制器任需要准确地执行航迹。其次，控制策略对汽车应该具备**可行性**。例如，如果你的汽车向北行驶，而你希望它立即向东转。你可以在游戏中做到这一点，但在现实中无法实现。最后，需要考虑的是**平稳度**。舒适的驾驶非常重要。如果车辆行驶得不规律，那乘客永远不会想再次乘坐它了。要使控制顺利进行，驱动必须是连续的。这意味着你应避免突然转向、加速或制动。

总的来说，控制的目标是使用可行的控制输入，最大限度地降低与目标航迹的偏差，最大限度地给乘客提供舒适度。

#### 控制流程

控制器预计有两种输入：目标航迹和车辆状态。目标航迹来自规划模块，在每个航迹点，规划模块指定一个位置和参考速度。在每个时间戳都对航迹进行更新，同时我们还需要了解车辆状态，车辆状态包括：通过本地模块来计算的车辆位置、从车辆内部传感器获取的数据（如速度、转向、加速度）。我们使用这两个输入来计算目标航迹与实际行进航迹之间的偏差。

控制器的输出是控制输入（转向、加速和制动）的值。当偏离目标航迹时，我们希望采取控制输入来纠正这种偏差。在无人驾驶中，我们使用不同的控制算法，计算出这三个控制输入。常用的控制算法有：**比例积分微分控制（或PID）**、**线性二次调节器（或LQR）**、**模型预测控制（或MPC）**。

##### PID 控制

PID (比例｜积分｜微分 Proportional Integral Derivative) 分为三个组件，其中P代表比例 （Proportional），设想一辆车正试图遵循目标航迹，P控制器在车辆开始偏离时立即将其拉回目标航迹。比例控制意味着P控制器是根据比例进行纠正的，也意味着车辆偏离越远，控制其越难其拉回目标航迹。

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1v8tupcj30gv08y3z8.jpg)

图中$K_p$代表比例修正参数，$e$代表误差，$a$代表修正结果，在实践中P控制其的一个问题在于，它很容易超出参考航迹，当车辆越来越接近目标航迹时，我们需要另外的控制其来稳定，D (Derivative) 控制器相当于P控制器的阻尼器，它致力于最大限度地减少控制器输出的变化速度。是运动处于稳定状态。

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1v9s04zj30jl09u0su.jpg)

图中$K_d$代表微分修正参数，$\frac{de}{dt}$代表对误差进行时间上的微分。

PID控制器中的最后一项**I代表积分**（Integral），该项负责纠正车辆的任何系统性偏差。例如，转向可能失准，这可能造成恒定的转向偏移。在这种情况下，我们需要稍微向一侧转向以保持直行。为解决这一问题，控制器会对系统的累积误差进行惩罚。我们可以将P、I和D组件结合构成PID控制器。

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vat7bbj30iy09udgm.jpg)

##### 总结

PID控制器很简单，但它在很多情况下的效果很好。对于PID控制器，你只需要知道你的车辆与目标航迹之间的偏差。但是**PID控制器只是一种线性算法**，对于非常复杂的系统而言，这是不够的。例如，**为控制具有多个关节的四轴飞行器或机器人，我们需要建立机器人的物理模型**。对无人驾驶而言，我们需要应用**不同的PID控制器来控制转向和加速，这意味着很难将横向和纵向控制结合起来**。另一个问题在于PID控制器依赖于实时误差测量，这意味着受到测量延迟限制时可能会失效。

#### 线性二次调节器 - Linear Quadratic Regulator（暂不深究）

线性二次调节器 （LQR ）是基于模型的控制器，它使用车辆的状态来使误差最小化。Apollo使用LQR进行**横向控制**。横向控制包含四个组件：横向误差、横向误差的变化率、朝向误差和朝向误差的变化率。变化率与导数相同，我们用变量名上面的一个点来代表。我们称这四个组件的集合为X，这个集合$X$捕获车辆的状态。除了状态之外，该车有三个**控制输入**：转向、加速和制动。我们将这个控制输入集合称为$U$。

![image-20200917145529610](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vc6zdoj30id0br410.jpg)

LQR处理线性控制，这种类型的模型可以用等式来表示（详见下图）。$\dot{x}=Ax+Bu$，$\dot{x}$向量是导数，或$X$向量的变化率。所以$\dot{x}$的每个分量只是$x$对应分量的导数。等式$\dot{x}=Ax+Bu$，该等式捕捉状态里的变化，即$x$点是如何受当前状态$ x $和控制输入 $u $的影响的。

![image-20200917145548761](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vd4iamj30iu0bfta7.jpg)

这个等式是**线性的**，因为我们用$∆x$来改变$x$时，并用$∆u$来改变$u$。$x$点的变化也会让这个等式成立（见下图等式）。现在我们了解了LQR中的L。

![3_meitu_4.jpg](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vdva6jj30ij0an3ym.jpg)

接下来我们学习LQR中的Q。这里的目标是为了让误差最小化，但我们也希望尽可能少地使用控制输入。由于使用这些会有成本，例如：耗费气体或电力。为了尽量减少这些因素，我们可以**保持误差的运行总和和控制输入的运行总和**。当车往右转的特别厉害之际，添加到误差总和中。当控制输入将汽车往左侧转时，从控制输入总和中减去一点。然而，这种方法会导致问题。因为右侧的正误差只需将左侧的负误差消除即可。对控制输入来说也是如此。相反，我们可以让x和u与自身相乘，这样负值也会产生正平方，我们称这些为二次项。我们为这些项分配权重，并将它们加在一起。

![img](https://mmbiz.qpic.cn/mmbiz_jpg/C4wVziccAsSLfsd8n3gbAavOo7qR9v2S7lCO0wYicTKibZ0WNvp1ofeEaib3F0PsrwVDpmLmDicySvD2icjBZBJ7EKtg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

最优的$u$应该最小化二次项的和随时间的积分。在数学中我们将这个积分值称为**成本函数**（形式见下图）。我们经常以紧凑的矩阵形式表示加权二次项的总和。

![img](https://mmbiz.qpic.cn/mmbiz_jpg/C4wVziccAsSLfsd8n3gbAavOo7qR9v2S7rVbIxMctWeLpFso1OpbD0uxGicfFJC1XHicd5ibDXkoGXjg1BWj8HumMQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

这里的$Q$和$R$代表$x$和$u$的权重集合。$x^T$和$u^T$是转置矩阵，这意味着它们几乎与$x$和$u$相同，只是重新排列以便矩阵相乘。$x$乘以$x^T$，$u$乘以$u^T$，实质上是将每个矩阵乘以它自己。最小化成本函数是一个复杂的过程，但通常我们可以依靠**数值计算器**为我们找到解决方案。Apollo就提供了一个这样的求解方案。在LQR中，控制方法被描述为$u=-Kx$。其中，$K$代表一个复杂的$skeme$，代表如何从$x$计算出$u$。所以找到一个最优的$u$就是找到一个最优的$K$。许多工具都可以轻松地用来解决K，尤其当你提供了模拟车辆物理特征的$A、B$，以及$x$和$u$的权重$Q、R$。

#### 模型控制预测 （暂不深究）

**模型预测控制（或MPC）**是一种更复杂的控制器，它非常依赖于数学优化，但基本上可以将MPC归结为三个步骤：

1.  **建立车辆模型。**
2.  **使用优化引擎计算有限时间范围内的控制输入。**
3.  **执行第一组控制输入。**

MPC是一个重复过程，它着眼未来，计算一系列控制输入，并优化该序列。但控制器实际上只实现了序列中的第一组控制输入，然后控制器再次重复该循环。为什么我们不执行整个控制输入序列呢？那是因为我们只采用了近似测量与计算。如果实现了整个控制输入序列，实际产生的车辆状态与我们的模型有很大差异，最好在每个时间步不断地重新评估控制输入的最优序列。

MPC的第一步为定义车辆模型，该模型近似于汽车的物理特性，该模型估计了假如将一组控制输入应用于车辆时会发生什么。接下来，我们决定MPC预测未来的能力。预测越深入，控制器就越精确，不过需要的时间也越长。所以，我们需要在准确度与快速获取结果之间做出取舍。获取结果的速度越快，越能快速地将控制输入应用到实际车辆中。

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1veethcj30ja0b9t8z.jpg)

下一步是将模型发送到搜索最佳控制输入的优化引擎。该优化引擎的工作原理是通过搜索密集数学空间来寻求最佳解决方案。为缩小搜索范围，优化引擎依赖于车辆模型的约束条件。

优化引擎可间接评估控制输入，它通过使用以下方法对车辆航迹进行建模：通过成本函数对航迹进行评估。成本函数主要基于与目标航迹的偏差；其次，基于其他因素，如加速度和提升旅客舒适度的措施。

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vfamduj30l40bs74m.jpg)

为使乘客感觉更舒适，对控制输入的调整应该很小。因为动作变化幅度过大会让乘客感到不舒服。根据具体情况，我们可能需要为其考虑进一步的成本，并设计成本函数。模型、约束和成本函数合并在一起，并作为优化问题加以解决。我们可以在不同的优化引擎中，选择一种来寻找最佳解决方案。

##### 总结

控制实际上是无人驾驶汽车实现自动移动的方式。在控制中，我们使用转向、加速和制动来运行我们的目标航迹。我们研究了几种不同类型的控制器。**PID控制**是一种简单而强大的控制算法，**线性二次调节器和模型预测控制**是另外两种类型的控制器，它们更复杂，但也更强大、更准确。Apollo支持所有这三种控制器，而你也可以选择最适合自己的控制器！

# 多传感器数据融合理论及应用

## 1.概述

>   数据融合是一个多级、多层面的数据处理过程，主要完成对来自多个信息源的数据进行自动检测、关联、相关、估计及组合等处理。
>
>   如果事先对信号的产生过程或对可测量的“量”的性质都清楚的话，那么我们就可以设计出一个多传感器系统，对整个多传感器处理系统产生影响的因素主要有：对要探测的目标及其所处背景的了解程度、传感器的选用、信号处理的各种算法、在检测环境中隐含的某些统计信息、能够利用的通信方法以及最后所用的融合手段等，这些因素决定了融合系统是否具有合理而完善的设计，并具有最佳的性价比。

**本文重要的知识着重在电磁传感器能响应的物理信号、大气的影响、数据融合算法及目标检测、分类、识别及跟踪框架的构造。**

传感器获得的信号及数据主要与以下几个因素有关：

1.  传感器接受的能量的类型（电磁波、声波、超声波、磁信号、地震信号（横波纵波）等）
2.  传感器的工作类型，即主动式或被动式，以及传感器工作的中心频率、极化情况、带宽及入射角等
3.  传感器对应于目标尺寸的空间分辨率
4.  目标与传感器的运动状态
5.  恶劣天气、杂乱回拨及反测量的影响。

一个多传感器系统，应该是能捕捉到物理现象各个方面所特有的一些性质并将其具现化为人类所能理解的信号的系统。为此，我们可以选择多个传感器，分别响应对应的物理属性，这些传感器的输出合并融合后所得到的结果是能免受恶劣天气、杂乱回拨和各种反测量等干扰因素的影响。在通常情况下，经过多传感器融合处理后的结果能提供其他单传感器系统所不能得到的**”知识“（信息）**，或者至少经过数据融合处理的结果，其**精度**要比单传感器高很多。

融合结构的设计，主要依据特定的应用场合、传感器的分辨率以及可以利用的信息处理资源等因素。

1.  应用场合 (l'occasion de l'application)，相对于目标跟踪系统来说，自动目标识别系统的各个传感器在处理它们各自的数据时具有更大的自主权 (l'autonomie)。在自动目标识别系统中，大多数相对自主的传感器的处理结果甚至可以和之前不属于该融合体系结果中的传感器的输出进行融合。**但对于许多目标跟踪问题来说，只有将未处理过的多个传感器数据集中合并后再去识别一条新的航迹或与一条已经存在的航迹相关联（Corrélation），才会得到更加可靠的航迹估计值。**
2.  传感器分辨率：如果传感器可以分辨出我们感兴趣目标（Région d'intérêt）所占的多个像素（图像级），那么这些传感器数据就可以按照像素对像素的办法合并起来（像素级融合），产生一个新的融合图像。利用这个新的融合图像能够分析出所感兴趣的目标是否出现。我们还有另外一种分析方法：具体步骤为：
    1.  从每个传感器数据中提取特征
    2.  将这些特征组合后形成一个**新的维数更大的特征向量**
    3.  基于该向量来确定目标的所属类别，比如我们可以将该向量输入给一个**基于统计的算法**来确定目标的分类。
3.  信息处理资源：如果每个传感器都具备充足的处理资源，则每个传感器可以用来对数据进行**预处理**。在这种情况下，由每个传感器获得的检测和分类预决策信息被送到一个融合处理器以得到最终的分类结果。如果各个传感器分布在一个相对比较大的区域，但是具备高的数据传输率和带宽通信媒介，那么系统就有能力传输未做处理的原始数据到融合中心，这样，我们可以实现一个更加集中的数据处理和融合算法。

关于多传感器数据融合：涉及到能产生信号的物理现象以及与多传感器系统有关的有点、多传感器数据融合处理的结构、以及适用于目标自动识别、目标跟踪估计以及姿态估计的各类算法。例如：贝叶斯方法、D-S证据理论、表决逻辑、模糊逻辑等。这些方法都有一个共同特点，**即需要来自于设计者的专家知识或信息来确定各算法中所需对应的先验概率和似然函数、概率分配值、信任级别、隶属函数以及产生式规则。**对于其他算法、如经典概率推理、基于知识的推理以及模式识别等，也需要设计者事先假定概率密度函数、规则、以及其他相关的参数才能进行实际操作。所以，数据融合算法的实现要依赖于设计者的专门知识，对工作环境的分析以及传感器数据所提供的信息类型等。

## 2.多传感器系统的应用及优势、大气对信号的衰减作用

>   ![<u>image-20200921111357504</u>](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1e15nj1j311o0majxv.jpg)
>
>   毫米波雷达（传感器）是指工作在毫米波段 （millimeter wave）探测的雷达。工作频段一般为$[30GHz, 300GHz]$，波长 $[1mm, 10mm]$，介于微波和厘米波之间，而车载毫米波雷达的工作频率一般为$[24GHz,77GHz]$
>   $$
>   \lambda = \frac{c}{f}
>   $$
>   毫米波雷达可以实现同时多个目标进行测距、测速以及方位测量；测速时根据多普勒效应，而方位测量（包括水平角度和垂直角度）是通过天线的阵列方式来实现的。
>
>   -   **测距：**（TOF）通过给目标连续发送毫米波信号，然后用传感器接收从物体返回的毫米波，通过探测毫米波的飞行（往返）时间来得到目标物距离。
>   -   **测速：**根据多普勒效应，通过计算返回接收天线的雷达波的频率变化就可以得到目标相对于雷达的运动速度，简单地说就是相对速度正比于频率变化量。
>   -   **测方位角：**通过并列的接收天线收到同一目标反射的雷达波的相位差计算得到目标的方位角；
>
>   红外雷达（传感器）是指工作在红外波段（波长介乎微波和可见光之间）的探测雷达，红外波长在$[760nm, 1mm]$之间，对应频率约是在$[430THz,300GHz]$，室温下发出的热辐射多都在此波段。

毫米波传感器（MMV）和红外（IR）传感器在自主式多传感器系统中经常被组合使用，因它们的工作频率可以**设计成互补状态**。使用多个传感器，收集来自多种物理现象产生的信号，相比起一个传感器收集到的信息，更能或者比较容易实现对目标的辨识，通过使用足够宽的电磁波频率范围，即使在恶劣天气、密集回拨和干扰环境下，仍然可以对目标实现相对高的检测率和分类，同时是错误率控制在一个可以接受的范围内。除此之外，有其他如主动式雷达发射器、被动式雷达接收器、以及红外和可见光传感器也可以提供多种物理量的数据，如温度、湿度、雨量、风俗、暴风雨航迹、雪和云的恶覆盖情况以及作物的类型和成熟度等。这些信号数据也可以和其他类型传感器的数据进行融合，所使用的算法和结构基本相同。

>   通常一个传感器由两个部分组成、一个是前端电路装置、称之为感应器：一个是数据处理器。感应器把进入传感器中的能量转化为信号，据此信号可以在数据处理器中将目标和背景的分离信息进行抽取。

### 2.1 多传感器系统中数据融合的应用

在一个多传感器系统中，有些应用场景可能需要一个大视野的传感器来对大范围区域进行搜索（对应无人驾驶的高精地图），而我们所重点关心的区域（ROI）也可能是其中一部分，所以需要把这一部分区域让具有更高分辨率的传感器进行搜索，以获取更高进度的目标航迹和身份信息（感知）。而把我们感兴趣的区域让更具有更高分辨率的传感器进行搜索处理，能充分利用数据融合的功能。

另外，有时为了增加目标信号被检测的概率，我们往往采用多个传感器的组合，因为多个传感器能对不同的屋里信号进行分别响应。有时某个传感器在某些气候、回波或干扰背景下无法检测到目标，但加上其他类型的一些传感器就可以获得该目标的数据。如在无人驾驶领域中，雷达提供距离数据给具有更高分辨率的红外传感器，而这个距离信息正是红外传感器所不能得到。通过选择合适的信号处理算法来组合距离数据和红外传感器提供的数据，我们就可以可以得到目标的实际尺寸这一新的信息。这种组合多种传感器数据的过程也涉及到数据融合的技术

### 2.2 传感器的选择

**当多传感器的工作频率选择得足够宽，能尽可能地包含整个电磁波谱，而且更进一步，如果既有传感器工作在主动（发射和接受信号）模式，又有传感器工作在被动（仅能接受信号）模式，来自多传感器数据间的独立性有可能得到加强。**主动式传感器有毫米波和激光雷达等，而被动式传感器有毫米波辐射计和红外辐射计、FLIR（前视红外）传感器以及IRST（红外搜索与跟踪）传感器等。在选择工作频率或波长时，**往往要把外形尺寸、分辨率、天气状况、大气环境、回拨情况，干扰以及价格等因素综合起来进行考虑**。**例如一个微波雷达工作在相对低频波段时，就较少受大气影响，（特别是短程应用时），但却有相对较大的外形尺寸以及不能提供足够高的分辨率。对于工作在较高频率的雷达，再相同孔径条件下，尽管具有较小的外形尺寸和相对高的分辨率，但价格也会提高，而且易受大气环境及气象条件的影响。**

>   雷达传感器工作的频段一般用字母来标识，在K波段及以下的频率通常称为微波，在Ka波段及以上的频率通常称为毫米波
>
>   ![image-20200921144534294](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1edzxcoj31360imwgl.jpg)

红外传感器可以工作在近红外波段、中红外波段及远红外波段内，对应波长分别为$[0.77~1.5um]$，$[1.5,6um]$，$[6,40um]$。这些波段有时需要同滤波器限定得更加严格，以使对特定物体或分子所对应的信号最强，从而消除周围大气及背景所产生的虚警。

主动式传感器如毫米波雷达可以工作在单基地或双基地下。在单基地的模式中，发射器和接收器时同一装置，接收器处理的是在视野范围内从目标反向散射来的能量。在双基地模式中，发射器和接收器在空间上是分离的，此时接收器处理的是由目标散射回来的能量。

![image-20200921151158240](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1eud9pfj310y0n8n0z.jpg)

在毫米波雷达接收到的信号中，包含有散射物的尺寸及位置等信息，另外红外激光雷达也能提供类似信息，其波长较短，所以其提供信息的分辨率要高很多。然而红外激光雷达的信号受大气衰减的影响较大，而且不能在很短的时间内实现大范围区域的搜索，激光雷达接收到的能量中，除了含有散射物的大小、形状和位置等信息以外，还反应了物体反射和背景反射能量的差异这个重要信息。这个差异信息可以帮助我们把目标从背景和其他物体中区分出来。（所以激光雷达在无人驾驶的分类过程由比较多的应用-点云图）

>   传感器的分辨率与波长成反比关系

红外被动式传感器，例如辐射计，可以响应目标和背景的表面温度差。而表面温度是由物体在辐射计视野范围内的绝对温度及物体在红外波段内的热辐射度所决定的。

一种传感器的设计并不能满足对所有应用所提出的要求（外形尺寸、分辨率、天气状况、大气环境、回拨情况，干扰以及价格等因素。）在性价比方面，传感器与所应用的场景相关，多传感器系统设计的一个目标就是减少成本。

>   如果我们需要多传感器系统输出目标的航迹估计，那么许多实例证明另外一种融合成过去数据的方法能更准确地估计出目标的航迹，这种方法就是中央级融合方法，它需要把最小程度处理过的传感器数据输入到融合处理器中进行关联，然后再把关联后的数据进行融合，最后形成融合后的航迹来估计目标在未来时刻的位置。详细内容将在第3章中加以介绍。

### 2.3 多传感器系统的优势

#### 2.3.1 系统检测率的提高 - 虚警抑制？？

假设虚警率恒定时，系统检测率与信噪比由类线性的关系，单传感器会随着信噪比的下降而急速下降，导致检测率不能再被我们接受。然而，如果采用三种传感器来检测目标，其中每个传感器响应不同的物理信号，并且对统一事件**假设三个传感器不会同时产生虚警时**，则虚警抑制可以分配在三个传感器上。随后我们采用某种算法，例如通过串联和并联来组合多个传感器结果的表决融合算法，使得系统对虚警的抑制进行了分散，具体分配到以下缓解：信号的获取、对所有传感器信号的处理以及融合算法。实际上，这种结构让每个传感器工作在较高的虚警率中，这样当目标信号被抑制时还能做到具有较高的检测率。

### 2.3.2 识别能力的提高

下图说明了融合主动式毫米波雷达和被动式毫米波辐射计的数据时如何提高物体的识别能力的。从图中我们可以看出对毫米波雷达来说卡车和房顶的信号是不能区分的，因为两者都有相同的雷达敬射面积，从而具有相同的反向散射回波，所以说毫米波雷达也就很难区分卡车顶和房顶。但是如果把毫米波辐射计加入到这个系统后，此时这两个物体信号的差异就能显现出来，具体表现在垂直坐标轴所表示的目标/背景温度对比这个量上。反过来，如果仅使用毫米波辐射计，我们也很难区分沥青路面和卡车这两个物体，同样此时如果加入毫米波雷达信号，则再区分这两个物体就变得可能了。

![image-20200921163358775](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1fe2bkbj30oc0hujt1.jpg)

另外，当出现密集回拨或者恶劣天气时，多传感器系统也常常工作在互相协作的模式下，某个传感器，比如毫米波雷达，在大量积雪引起的杂波下往往收到影响，此时可以用一个被动式传感器来帮助它实现对目标的检测，**因为被动式传感器不受积雪杂波的影响。**同样的，红外传感器容易收到灰尘或云层的影响，我们可以用毫米波雷达来帮助它实现对目标的检测，**因为毫米波雷达不受灰尘或云层的影响。**

### 2.4 信号波长对其在大气衰减中影响

在大气环境下，信号发生衰减主要由以下两个原因造成的——大气吸收和大气散射，大气吸收主要与传感器的工作频率和在大气中是否存在**吸收气体和污染物**等因素有关。大气散射主要与散射物体的尺寸、形状、介电常数以及入射能量的波长等因素有关，大气中各气体，如氧气、水蒸气和二氧化碳等的含量的比例起到了至关重要的作用。**这些气体分子的内在能量状态决定了分子吸收能量时的频率，由此造成了信号在这些频段上的高衰减特性。**，这样的频段通常用来进行近距离通讯。而在电磁波的有些频段范围内，信号被大气削弱的影响相对来说比较低，我们称这些地方为信号能通过的“窗口”频段。工作在“窗口”频段的传感器能够长距离传播能量，所以适用于远距离目标检测。

相对于晴好天气来说，一些恶劣天气状况，如雨、雾或雪等可以进一步加强大气对信号的吸收和散射作用，从而限制了传感器的性能发挥。对此，**我们可以应用一些模型来充分地预测在毫米波和红外频段上大气对信号的吸收和散射情况。**

-   **在电磁波谱的微波到毫米波频段，大气对信号的削弱作用往往随着工作频率的增大而加剧。**
-   **而在电磁波的红外频段，大气对信号的衰减是与大气中的气体和污染物等因素密切相关的**

更高分辨率的红外和可见光传感器信号更容易受大气的削弱作用，红外频段的信号在大气中的衰减主要是由于大气中气体分子的旋转和振动所引起。

**更多关于信号波长对其大气衰减中影响可以查看多传感器数据融合理论及应用(第二版)2.4章**，值得思考的是，大气衰减效应不仅是一个负面影响，我们还可以根据这些影响，通过对发射和接受信号的衰减情况和原因分析计算出实际环境中的天气情况。在细致些，如果能够计算出衰减参数，对于我们在构建预测天气模型时有很大的帮助。

### 2.5 毫米波传感器的工作频率对其性能的影响

下图列出了毫米波传感器的工作频率与天线的分辨率，大气对信号的衰减以及硬件设计参数之间的关系。

![image-20200922101724494](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vfw2wcj30xk0hitdp.jpg)

对于一个固定孔径的天线，高的工作频率将减少辐射波束的宽度及增加分辨率。高的分辨率可以提高高定位精度且减少像素单元的大小。但反过来也会影响在规定的时间内进行大面积搜索的能力，这是由于**传感器的分辨率与其视野范围成反比关系（高分辨率对应小视野），**或换言之，**传感器的分辨率与扫描速度成正比关系**（高分辨意味着对于给定的区域或给定的分配空间，需要更快的扫描速度才行）。

### 2.6 雨和雾对毫米波雷达信号能量的吸收 - 雾吸收系数$K_a$

**雨主要是通过吸收和反向反射能量**来影响毫米波的传播的，下图中的上图给出了毫米波信号在通过雨和雾的单程吸收系数（$dB/km$）与下雨强度（对应工作频率为：$15.5GHz $ ，$35GHz$ ，$70GHz$， $94GHz$， $140GHz$， $225GHz$）。对于双程雷达而言，吸收系数需要加倍，然后如果再乘以目标与发射器之间的距离就能得到当信号到达传感器时被吸收的分贝数。但是我们很难得到再雾环境下吸收系数的测量值，因为**雾一直是处于一种不稳定的状态**（详见文章2.5章）。

下图中的第二张图给出了降雨强度为$0.25mm/h$，$1mm/h$，$4mm/h$，$16mm/h$时理论模型预测吸收系数与信号波长的关系。该模型假设雨滴的大小根据下雨的强度服从$Laws$ 和$Parsons$规则，从而再计算得到的吸收系数的值。**该规则规定雨是由包含各种离散直径大小的雨滴（$[0.05cm, 0.7cm]$，步长为$0.05cm$）构成的，每种直径的雨滴数与各种降雨强度（从$[0.25,150]mm/h$）占总降水量的百分比成正比，研究发现，根据$Laws$ 和$Parsons$规则计算得到的吸收系数值和经过大量观测雨滴尺寸分布和计算得到的吸收系数在高于$50GHz$时的差别在统计意义上不是很明显，**对于更高频率而言，对小雨滴的分布测量影响了计算吸收系数和下雨强度间关系的精度。因此，再更高频段，我们就不能区分吸收系数与下雨强度关系的误差是由于不同雨滴模型误差造成的，还是由于计算吸收信号时的误差造成的。**对于信号被大气吸收的情况，由于模型预测的量和实际测量的量在毫米波工作的很大一部分频段内及各种降雨程度的条件下都基本一致。**，所以当我们缺乏大气对信号吸收的实际测量时，我们可以使用模型预测量来代替。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gjvjymkb6zj30u0112gwb.jpg" alt="image-20200922103328857" style="zoom:50%;" />

由于雾中的水滴直径比毫米比波长的尺寸要小很多，所以由散射造成的毫米波能量的损失相比于被雾吸收的能量来说可以忽略不计。在雾中单程吸收系数与雾中的水汽的量和传感器的工作波长相关。具体的吸收系数$K_a$为：
$$
K_a = \frac{0.438M_w}{\lambda^2}
$$
式中：

$K_a$ —— 单程吸收系数，$dB/km$

$M_w$ —— 单位体积的空气中水汽的质量， $g/m^3$

$\lambda$ —— 传感器的工作波长, $cm$

当传感器的波长$\lambda$是在$[5,10]cm$，且雨滴尺寸足够小（直径在$[0.001,0.005]cm$），上式的误差不超过5%。另外，当$M_w = 1 g/m^3$时，往往对应着雾中最大的水汽含量（但海洋上的浓雾除外。），在多数雾的状态下，$M_w$是远小于1的。而雾气平均水含量$\bar{M_w}$与可见光的能见度之间的经验公式。
$$
\bar{M_w}  = 1660V_i^{1.43}
$$
这里$V_i$是能见度，单位为$in^*$，$\bar{M_w}$为95%情况下的$M_w$，其值一般位于$[0.5M_w, 2M_w]$之间，这个关系在无法得到$M_w$的更精确的数值时就显得很实用。

### 2.7 在雨中毫米波能量的反向反射 - 反向反射系数 $\eta$

反向反射主要体现在体积效应上。因此，如果雨的反向反射系数$\eta$（单位为$m^2/m^3$）乘以雷达的体积分辨单元$V$（$m^3$），就可以得到雨的等价雷达波束横截面（$S_{RC}$ $m^2$）。所以雨的$S_{RC}$ 可以看作是“伪目标”将能量散射到雷达接收器上，这样反射的能量有时会与真正目标的发射能量大致相当。（即由于雷达的分辨单元对于任何物体都是一样的，对于接受到的反射能量，有一部分可能是经过雨滴反射而来的，这时的雨其实是一个“伪目标”，导致如距离，速度等数据测量出现误差）。

雷达的体积分辨单元$V$的公式如下：
$$
V = \frac{\pi}{4}(R\theta_{az})(R\theta_{el})(\frac{c\tau}{2}) \ \ \ (m^3)
$$
式中

-   $R$ —— 从雷达到雨分辨单元之间的距离， $m$
-   $\theta_{az}$，$\theta_{el}$ —— 天线方位角与高低角 $3dB$波束角度， $rad$
-   $\tau$ ——发射脉冲的宽度，$s$;
-   $c$ —— 光速， $m/s$

于是，雨的$S_{RC}$为：
$$
S_{RC} = \eta V \ (m^2)
$$
如果从雷达到与分辨单元之间的距离被限定在$L$（单位为$m$）内，则单元分辨单元$V$公式中的$\frac{c\tau}{2}$可以由$L$代替。

反向反射系数$\eta$与传感器工作频率的有一定的关系，对于线性极化雷达，雨的反向反射信号与信号频率关系曲线，左边用$Marshall-Palmer$雨滴尺寸分布计算出的理论值，右边是实测值由下图给出（暂不深究），对于反响反射来说，通常是大雨滴占绝大多数，此时对于特定的降雨量（$mm/h$），反响反射系数与工作频率的关系应呈指数分布，但根据$Crane$的研究结果，认为雨滴的尺寸分布的实际测量值即使在同一个位置也因雨的类型和强度的不同存在着很大的变化，因此，雨滴尺寸的分布则应该认为是一种平均值。而不是个体值。

![image-20200922110905212](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vh0knej313o0rwdo6.jpg)

### 2.8 红外传感器工作波长对性能的影响

与雷达的衰减数据（吸收系数$K_a$&反向反射系数$\eta$）不同，对红外主要采用的是传播系数，也就是被传播能量占总能量的百分数。**大气中对红外波长具有固定吸收情况的成分有二氧化碳、一氧化二氮及甲烷。还有些成分吸收红外的量随浓度而时刻在变化，如水蒸气和臭氧等。大气除了对红外有吸收作用，其中的分子和小颗粒对红外还有散射作用。**当红外波长小于$2um$时常常忽略大气中分子的散射，但是来自于大气中小颗粒的散射却不能忽略，其散射强度与散射物的半径除以红外波长这个量有关。这里的小颗粒通常把包括雨、灰尘、雾及烟等。

![image-20200922113115520](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vhqo2hj310c0juq6d.jpg)

大气的传播系数$\tau_{R}$可以由Eambet-Beer建立的数学模型计算如下：
$$
\tau(\lambda) = exp[-\gamma(\lambda)R]
$$
其中：

$\gamma$ —— 消光系数或功率衰减系数，$Np/km$

R —— 路径长度， $km$

当奈培（$Np, Nepers$）出现在指数函数中时，它在指数上是一个自然单位，如果$Np$在乘以衰减系数的值$0.23$，单位是$dB/km$后，那么就把单位转变成$Np/km$ 即 $\gamma = 0.23Np$

消光系数$\gamma(\lambda)$是吸收系数$k(\lambda)$与散射系数$\sigma(\lambda)$的和
$$
\gamma(\lambda) = k(\lambda) + \sigma(\lambda)
$$
同样吸收系数与散射系数，又分别可以分为大气中的分子和小颗粒的**吸收和散射系数**，分别在下标用$m$和$a$来表示，这样就有：
$$
k(\lambda) = k_m(\lambda) + k_a(\lambda)
$$

$$
\sigma(\lambda) = \sigma_m(\lambda) + \sigma_a(\lambda)
$$

消光系数是红外波长的一个复杂函数。但我们可以通过积分求出平均传播系数。
$$
\bar{\tau_a} = \frac{1}{\lambda_2 - \lambda1}\int_{\lambda_1}^{\lambda_2}exp[-\gamma(\lambda)R]d\lambda
$$
这个均值$\bar{\tau_a}$通常是由计算机程序计算得出。

### 2.9 能见度度量及其与消光系数的关系

能见度分为两种，一种是主观能见度，是指人眼能看到的定量数据，一是客观能见度，是指定量的气象距离。

#### 2.9.1 主观能见度

主观能见度是一种定量的距离描述，它定义为人裸眼所能看见并能辨认物体的最远距离，他的定义可以从

1.  白天，辨认时的场景为深色物体处于水平方向的天空中
2.  夜晚，辨认时物体要求具有中等亮度。

如果主观能见度$V_{obs}$的信息可以获取，那么客观能见度，即气象距离$V$可以用下式来估计
$$
V = (1.3 \pm 0.3)V_{obs}
$$

#### 2.9.2 客观能见度——气象距离

气象距离是基于某种波长的可见光对比度衰减来定义的，这里某种波长可见光对赌的衰减抓药是由于大气对$0.55um$波长的吸收而引起的，当一个辐射远在距离$x$处被探测到，其可见光对比度$C_x$定义为：
$$
C_x = \frac{R_{ax} - R_{bx}}{R_{bx}}
$$
其中$R_{ax}$和$R_{bx}$分别是距离辐射源$x$处，辐射源和背景的可见光辐射度。

当$x= V$处的可见光对比度与辐射源处$x=0$处的可见光对比度的比值减少到2%时，该$x = V$就为气象距离，有时也叫做视程，即：
$$
\frac{C_{x= V}}{C_0} = \frac{\frac{R_{ax} - R_{bx}}{R_{bx}}}{\frac{R_{a0} - R_{b0}}{R_{b0}}} = 0.02
$$
上式通常使用波长$\lambda = 0.55um$计算的。

如果任意距离内辐射源的辐射度远大于背景的辐射度，即$R_s >> Rb$，并且背景的辐射度为常数，即$R_{b0} = R_{bx}$时，则气象距离可以表是为可见光对比去的函数，即：
$$
\frac{C_{x = V}}{C_0} = \frac{R_{aV}}{R_{a0}} = 0.02
$$

$$
ln(\frac{R_{aV}}{R_{a0}}) = -0.39
$$

大气传播度$\tau_{a}(\lambda)$的$Lambert-Beer$定律可以把消光系数（包括大气吸收和散射效应）

和气象距离联系起来。因此，大气传播可以写为
$$
\tau(\lambda) = \frac{R_{aV}}{R_{a0}} = exp[-\gamma(\lambda)R]
$$
其中：

$\gamma$ —— 消光系数或功率衰减系数，$Np/km$

R —— 路径长度， $km$

对两边取自然对数，同时取$R = V$，则有：
$$
\gamma(\lambda) = 3.91/V \ \ \ \ \ \ \  \lambda = 0.55um
$$
这样，就得到了**气象距离与消光系数的关系**。它能帮助确定大气的传播系数，从而确定红外传感器在气象距离传播中的能量衰减情况。（即：气象距离一定程度上反应了可见光在传播过程中由于大气吸收和散射导致的衰减程度，它 ($V$)可以通过主观能见度获取，同时，这个表征可见光衰减程度的值与描述红外线在大气中的衰减情况的消光系数$\gamma$有一定的比例关系$\gamma(\lambda) = \frac{3.91}{V}$，而后传播系数又与消光系数和路径长度有指数关系，所以，我们可以通过可见光的衰减程度计算出到红外线在大气的传播系数）

### 2.10 红外能量在雨中的衰减

雨能够削弱红外图像中目标与背景的对比度，主要表现为两种形式：**第一种是使信号在到达接收器的途中收到衰减：第二种是使目标的温度降低。**，下图小时了一组由$LOWTRAN6$绘制的大气传播率曲线，分别对应着降雨强度为$0mm/h$，$1mm/h$，$10mm/h$，$30mm/h$及$100mm/h$。此处的波数和波长相对应，定位为每$cm$所包含的波长数，测量距离为$300m$，地表及结露点温度均为$10^{\circ}C$及在无雨的状态下的气象距离为$23km$。图中的上半部分图形对应中红外和远红外的传播特性，而下半部分则对应于可见光及近红外的传播特性。

>   可见光比红外的波长更短，对应的频率越高

![image-20200922181603058](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1viqpfxj30rs14ogs8.jpg)

### 2.11 消光系数值（典型）

下表给出了可见光、红外和毫米波等频段内消光系数相对于各大气削弱物的数值范围，这里消光系数的单位为$Np/km$，表下半部分给出了视程（气象距离）和消光系数的定性关系。

![image-20200922134501517](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vku0alj316u0qen4r.jpg)

### 2.12 电磁波类传感器优缺点小结

分辨率、天气状况、白天/晚上的工作性能、回波情况以及是否采用反测量技术会影响对电磁传感器的选择。**选择合适的电磁传感器主要还是i为了更好地对目标进行辨识和航迹估计。随着频率的提高，分辨率也将提高，设计的部件也将变得更加紧凑，但大气及人为干扰所带来的衰减也随之增大（可以理解为高频率对应短波长，即被大气吸收和散射的影响会更大（因为光束体积｜横截面更小））,并且快速大面积的搜索能力也随之降低。**主动式雷达比较容易获取目标的距离和速度信息，而被动式雷达则可以暗中隐秘工作（这对无人驾驶好像没什么用）。

![image-20200922143835297](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vlv56lj316u0qen4r.jpg)

![image-20200922143851645](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vmudc5j30u00uik3z.jpg)

### 2.13 大气与传感器系统的计算机仿真模型（请看源资料）

### 总结

本章列举了主动式和被动式传感器在微波、毫米波以及红外等电磁频段内的属性，并且说明了由这些传感器组成的多传感器系统的优越性，**另外，选择毫米波和红外传感器的不同工作频率对分辨率、硬件和其他性能都有很大的影响，不仅如此，工作频率的选择也影响到我们感兴趣的目标和背景信号与传感器工作频率的匹配度。**

本章还介绍了毫米波和红外能量在晴天、雨天和雾天时所产生的大气吸收散射现象，并给出了相应的测量数据及模型。我们可以为毫末波和红外能量的衰减进行建模，主要使用消光系数这个参数，该参数综合考虑了吸收和散射这两个因素。当实际吸收和散射数据不能得到时，可以使用模型数据来预测传感器的性能。

## 3. 数据融合算法与融合结构

>   为了鼓励使用一种容错性好，可在恶劣环境下生存，并且便于维护的多传感器数据融合技术以提高实时目标识别、跟踪、现场态势及威胁估计等方面的性能，美国芳芳不住里机构十圈实验室数据融合小组联合指导委员会对数据融合中出现的专有名词进行规范化，并通过交换各种技术，促进对数据融合这种技术使用的有效性。基于美国国防部建立的模型，将数据融合分为两层，低处理层和高处理层。
>
>   PS：本书中大部分的理论解释和说明都是基于军事应用所建立的模型开展的，这有时与民用方面有出入。所以在进行总结时，某些功能的应用层次解释需要针对民用方面（具体的说：智能驾驶方面）结合自己的理解进行解释，并尝试在后续进行完善。

-   **低处理层包括：直接数据处理，目标检测、分类与识别、目标跟踪等：**
-   **高处理层包括态势估计及对融合结果的进一步调整。**

目前已有多种不同的算法用于目标检测、分类及航迹的融合。另外，为了满足这个两层模型的需要，已提出了多种融合多传感器数据的结构，**这些融合结构的区别就在于对传感器数据直接处理程度的不同以及对融合数据分辨率要求的不同。**

### 3.1 融合数据的定义

**数据融合是一个多级、多层面的数据处理过程，主要完成对来自多个信息源的数据进行自动检测、关联、相关、估计及组合等的处理**

数据融合的目标，由5个（原本提到的4个，但事实是将$Level \ 0$并入到信号与处理功能模块中，这是因为有些数据并不需要进行预处理，可以直接输入给下一个级别的处理层）不同级别的处理层实现，如下图所示。

![image-20200923094945988](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vnpzc7j30te0j4whd.jpg)

-   处理层 0 - 预处理（$Level \ 0 $）：通过预先对输入数据进行标准化、格式化、次序化、批处理化、压缩等处理、来满足后续的估计及处理器对计算量和计算顺序的要求；
-   处理层 1- 感知（$Level \ 1$）: 通过对单个传感器获得的位置与身份类别的估计信息进行融合，获得更加精确的目标位置与身份类别的估计；
-   处理层 2 - 预测#1（$Level \ 2$）： 辅助实时实现对目标进行状态评估、行为模式的检测，以及未来行为的预测
-   处理层 3 - 预测#2 （$Level \ 3$）：辅助实时实现对危险的评估和预测
-   处理层 4 - 修正 （$Level \ 4$）：通过对上述估计的不断修正，不断评价是否需要其他信息的补充，以及是否需要修改处理过程本身的算法来获得更加精确可靠的结果。

从各个合适的信息源获得的数据，都输送到融合系统进行处理（如下图左端），这些数据包括实施的传感器信息、情报信息、地图信息、天气状况信息、目标状态信息、危险信息及级别（立即的、紧急的、潜在的等），对威胁的预测以及来自其他数据库的信息等。这些信息又些需要经过与处理（$Level \ 0$），有些则可以直接输入给相应级别的融合层。为了进行第三和第四层的数据融合，往往需要相当数量的外部数据库信息。

![image-20200923115002779](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vq1ivcj30vs0jen86.jpg)

### 3.2 处理层 1 - 感知

处理层1属于低级别处理层，通过这一层可以得到目标的航迹估计与目标识别信息，对于识别具有不同层次，从低到高包括检测、定位、分类（识别）和辨识（在ADAS中，我们把检测和定位步骤统一为检测步骤，把辨识称为语义分割），**到达能到达识别的哪一层取决于传感器的分辨率和输入到传感器信号的信噪比。这些参数可以相互调整以分别满足检测、分类与辨识的要求。**

![image-20200923155517647](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vswlagj30vs0jen86.jpg)

传感器的输出通过数据关联进行融合，以获得感兴趣的物体、目标识别信息及目标位置估计与跟踪航迹。**用于检测与分类的融合算法不一定与用于融合航迹估计与预测的算法一样。**例如：我们在对目标的检测和分类时，由于每个传感器对相应的物理信号分别产生相应，所以最后的算法可能是先对各传感器的数据进行预处理，使每个传感器具有最好的识别估计，然后把处理过的数据再送入融合算法中。但是当我们通过分析和关联各传感器的数据，最终要形成航迹时，最好的算法可能是直接接受经过最少处理的各传感器数据，以便得到最准确的航迹位置估计。

#### 3.2.1 数据融合中的检测、分类和识别算法

在处理层1中所用到的各种检测、分类与识别算法的分类情况如下图所示。主要分为**基于物理模型的算法、基于特征推理技术的算法和基于知识的算法。**

![image-20200923165352137](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vsw2f1j318c0bcgty.jpg)

>   另外，近几年又发展了**基于现代数学模型的数据融合方法**，主要包括随机**集合理论，条件代数、相关事件代数**等。随机集合理论的随机变量为集合，而不是传统的随机变量。$
>
>   Goodman$等人通过集合理论将多传感器多目标估计问题转换成单传感器单目标估计问题。他们还应用随机集合理论把模糊证据（例如用自然语言描述的报表和规则）引入到多传感器多目标估计问题中，同时他们还应用该理论把不同的专家系统模型（例如模糊逻辑和基于规则的推理逻辑）引入到多传感器多目标估计问题中。
>
>   条件事件代数是一种**适合于对某些偶然事件计算其概率的方法**，这些偶然事件包括一些基于知识的规则并作偶然决策等。
>
>   相关事件代数是条件事件代数的推广，它给出**缺乏证据时如何解决此问题的系统的理论基础。**

-   **物理模型**——物理模型能反映物体的一些判别属性，当然这些属性需要能很容易且很准确地测量或计算得到。这些判别属性例如图像轮廓的高度；雷达波束的横截面（和物体的方位角有关），红外辐射程度（和机动车辆的类型、发动机的问题或者物体表面的特性有关：表面特性包括表面粗糙度、表面辐射能力和表面温度等。）、基于物理模型的目标分类与识别算法主要时通过匹配实际观测数据与各物理模型或预先存储的目标信号来实现的。中间用刀的技术包括仿真、估计以及句法的方法。具体的估计方法如卡尔曼滤波、极大似然估计和最小方差逼近方法，类似于在[3.2.2节](#3.2.2 数据融合中的状态估计和跟踪算法)将介绍的状态估计和跟踪算法。而对于基于句法的方法们将会在信息论技术中的模式识别部分中加以讨论。

-   **基于特征的推理技术**——基于特征的推理技术是通过把数据映射到识别空间中来实现的。这些数据包括物体的统计信息或者物体的特征数据等。基于特征的推理技术可以进一步划分为基于参数的方法和基于信息论技术的方法，后者由$Waltz$和$Llinas$等人提出。

##### 1. 特征推理——基于参数的方法

基于参数的方法直接把参数数据（例如特征数据）映射到识别空间中，在此过程中并不用到物理模型。基于参数的方法包括古典概率推理、贝叶斯推理、D-S方法和广义证据处理等。

###### 古典概率推理

**古典概率推理给出了在给定假设事件下，观测是来源于某一物体或事件的概率。**这种方法的主要缺点是：1⃣️用于分类物体或事件的观测量的概率密度函数难以得到；2⃣️在多变量数据情况下，计算的复杂性加大；3⃣️一次只能评估两个假设事件；4⃣️无法直接应用先验似然函数这个有用的先验知识。

###### 1.1 贝叶斯推理

贝特斯推理部分解决了古典概率中无法解决的问题。**该方法使用新得到的观测数据来更新假设事件旧的似然函数，从而得到其新的似然函数。同时，该方法还适用于多于两个假设事件时的情况。**贝叶斯方法的缺点主要由：1⃣️确定先验的似然函数非常困难；2⃣️当潜在具有多个假设事件并且是多个事件条件依赖时，计算将变得非常复杂；3⃣️各假设事件要求互斥；4⃣️不能处理广义的不确定问题。**关于贝叶斯推理将在第4章进行进一步的介绍。**

###### 1.2 D-S 方法

D-S 方法将贝叶斯理论进行了推广。**该方法通过分配给某一命题（例如物体属于某一类型）及其包括该命题的并命题（联合命题）支持度的方法引入了不确定性。**任何不直接分配给该命题或者其反命题的支持度将分配给由所有命题构成的假设空间（也就是说不确定）。当原子命题互斥。并且没有把支持度分配给不确定（也就是假设空间）时，D-S 方法具有与贝叶斯方法相同的结果。D-S 方法的不足之处是，在每个传感器中，都要为每个命题分配合适的概率分配值。**D-S 方法在数据融合中的具体应用将在第5章中加以介绍。**

###### 1.3 广义证据处理 （GEP）

把决策空间分为若干个假设事件（命题），然后把贝叶斯方法推广到此假设空间（在 D-S 理论中称为识别框架）中。经过这样的处理，GEP 方法就可以考虑多个假设事件了（如同 D-S 方法一样）。在此方法中，来自非互斥命题的证据可以使用贝叶斯公式融合，从而得到某一判决。正如 D-S方法那样，GEP使用来自多个传感器的证据，并且对于每个证据分配给相应的概率分配至。而GEP使用来自多个传感器的证据，并且对每个证据分配给相应的概率分配值。而GEP 方法与 D-S 方法的不同之处就在于，其概率分配值的赋予与融合是基于命题或假设事件的先验条件概率的。

##### 2. 特征推理——基于信息论技术的方法

**基于信息论技术的方法能把参数数据转换或映射到识别空间。**所有这些方法都有着相同的概念，**即识别空间中的相似是通过观测空间中的参数的相似来反映的**，但是我们却不能直接对观测数据的某方面建立明确的识别函数。在这一类方法中，我们可以采用的技术包括**参数模版匹配、人工神经网络法、聚类算法、表决算法、熵测量技术、品质因数、模式识别以及相关测量**等技术。

###### 2.1 参数模版匹配

**参数模版匹配是把一段时间内得到的多传感器数据与多个信息源按照预先选择好的条件进行匹配，然后判断观测量是否包含支持某一现象的证据。**参数模版匹配发可以应用于对某一事件的检测、态势估计及简单的目标识别等。

###### 2.2 人工神经网络

人工神经网络可以是一套硬件或软件系统。**该系统经过训练后，可以把输入数据映射到正确的输出分类中。这个转换过程是通过许多神经元来完成的，这些神经元通过模仿生物神经系统的神经元来进行对输入数据的处理。详细将在第6章介绍。**

###### 2.3 聚类算法

聚类算法能自动将数据聚类成不同的类别，有些类别是很自然的集合，但有些类别可能需要分析员解释，看它们是否代表了一种有意义的分类。**所有的聚类算法都需要一个度量准则，该度量准则能说明任何两个特征矢量之间的靠近程度。**例如这两个特征矢量一个代表着输入数据，另一个则代表着该输入数据所属的潜在类。一般的聚类算法依据以下五个步骤进行操作：1⃣️从观测数据中选择一些样本数据；2⃣️定义一些变量集或特征向量来表征样本中的实体；3⃣️计算数据的相似性；4⃣️运用聚类分析方法依据数据相似度原则产生一些数据聚集类；5⃣️进一步确认这些聚类结果的有效性。

**使用聚类分析方法有可能得到有偏差的结果，这是因为这类算法具有启发式的性质。**一般来说，数据的规范化、度量尺度及算法的选择，甚至输入数据的次序都可能非常大地影响聚类结果，因此，在使用聚类分析方法时应用有效性和可重复性进行判断，以形成有意义的聚类结果。

###### 2.4 表决算法

表决算法把多传感器的检测和分类结果进行融合。在该算法中，把每个传感器的判决作为表决过程中的一票，**表决可以采用少数服从多数或者决策树的规则等。**我们还可以对各传感器的判决采取甲醛的办法来的到其他的判别函数，**这种方式主要是基于布尔代数的理论，将在第7章中详细介绍。**

###### 2.5（信息）熵测量

熵测量这个名字来源于通信理论。**它试图通过事件发生的概率来度量事件中所包含的信息的重要程度。**通常高概率事件包含较低价值的信息，而低概率事件包含有较高价值的信息，因此，度量信息价值的函数具有这样的性质，即信息价值的大小与接受到该信息的概率成反比。

###### 2.6 品质因数

品质因数是一种度量机制，它来源于一些直观的或具有启发式的证据，这些证据有助于在观察值与物体属性之间建立起关联。**在该类算法中包含了很多灵活的算法来度量这种关联强度。而品质因数技术就是试图在多个证据间找到某种关系，以改善输入数据间关联和分类的效果。**有时也将品质因数法看作是[模版匹配法](#参数模版匹配)，这是因为品质因数法实际上反映了期望的观测值、期望的行为特征、期望的逻辑关系以及任何期望的目标属性。

###### 2.7 模式识别

模式识别主要用来解决数据描述和分类问题。历史上模式识别主要有两类方法，**一是基于统计理论（或决策理论），另一种方法则是基于句法规则（或结构学）。最近，人工神经网络作为第三种方法被提出。**

在统计模式识别中，可以从输入数据中提取出一系列的特征值，然后把特征值分配为$c$类中的某一类。**假定特征向量是由属性状态构成的，则统计模型就代表着与某一种对应的属性状态、概率集或者是概率密度函数。**

当模式的重要信息并不是体现在具体数字的存在与否上，而是体现在特征的相互连接上，也就是产生了结构信息时，就可以使用句法模式识别。可以使用形式上定义号的语句的句法来抽取结构信息，从而评价是否具有相同的模式。一般句法模式能够对复杂模式使用简单子模式或原子模式进行等级描述。

而神经网络计算，则是模仿生物神经系统对模式进行分类。

模式识别方法主要应用于高分辨率、多像素图像技术中，例如$FLIR$及卫星上的高分辨率扫描仪。从$FLIR$图像上提取出的特征值可能包括温度的梯度、 长/宽比、中心矩、在较大土体内的小物体的相对尺寸等。$LANDSAT$图像的特征可以从传感器的每个波段的每个像素点中抽取。$MMW$信号的频域分布可以为统计模式识别算法提供需要的特征，在这种情况下，特征是从$Fourier$变换后的数据中抽取的。下图为模式统计识别法、句法模式识别法及神经网络模式算法之间的比较。

![image-20200924104450067](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vulepuj312c0qytdd.jpg)

###### 2.8 相关测量

**相关测量来源于品质因数的加权组合。当有大量的品质因数时，该方法允许把各品质因数的相互比较和联系加入到计算中。**这样，对于两个完全相同的实体来说，相关测量就代表了两者之间的全部似然性。

##### 3. 基于感知的模型

基于感知的模型——包含**逻辑模版、基于知识的系统及模糊集理论。**基于感知的模型时图通过模拟人的处理过程来自动实现决策的制定。

###### 3.1 逻辑模版

**模版，是指那些事先确定或存储的模式，将观测数据与模版进行匹配，从而对物体的身份进行确认或者进行态势评估。**可以使用前面提到的[参数模版](#参数模版匹配)实现观测模式与存储模式的实时匹配，但是参数模版之间也可以使用逻辑模版来组合，比如使用布尔关系。模糊逻辑也可用于模式匹配技术中，引入模糊逻辑主要是为了考虑到观测数据和用来定义模式的逻辑关系的不确定性。

###### 3.2 基于知识的系统

**基于知识的系统是将规则或知名的专家知识结合起来实现自动对目标的识别。当人工推理由于某种原因不能进行时，专家系统可以运用专家的知识进行辅助推理**。基于计算机的专家系统一般包括以下四个逻辑部分：1⃣️一个知识库，包括基本事实、算法和启发式规则等；2⃣️一个大型的包含动态数据的全局数据库；3⃣️一个控制结构或推理机制；4⃣️人机界面

由推理机制运用数据、事实和规则在知识库中进行搜索，最后得出推理结果。

###### 3.3 模糊集理论

模糊集理论将不精确知识或不确定性边界的定义引入到数学运算中，**它可以方便地将系统状态变量映射成控制量、分类或其他类型的输出数据。运用模糊关联记忆，能够对命题是否属于某一个集合赋予一个0（确定不属于）到1（确定属于）之间的隶属度。**模糊集理论从直观上就非常吸引人，这是因为它允许知识或者身份边界的不确定性，因而它具有十分广泛的应用，例如**身份识别、目标跟踪、工业控制和过程控制**等。**与神经网络不同，模糊系统不累计所有输入输出，而是只类集输出。在第8章将用实例详细介绍模糊集理论和模糊逻辑****。

#### 3.2.2 数据融合中的状态估计和跟踪算法

在下图列出了处理层1中的状态估计和跟踪算法的分类结果。最顶层的状态估计和跟踪算法由以下两个部分组成：1⃣️确定搜索方向；2⃣️将测量数据与航迹进行关联。而第2⃣️步的关联处理将进一步分成三部分，即**数据配准、数据和目标的关联以及位置、动态性能和属性的估计。**

![image-20200924112234542](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vvdljwj317w0jk0zb.jpg)

##### 1. 搜索方向

搜索方向——方向跟踪系统可以是传感器（数据）驱动的，也可以是目标驱动的。

在传感器驱动系统中，用目标报表（包括径向距离、方位角、高低角及径向变化率测量数据）初始化与报表数据相关联的航迹文件，从而实现跟踪。

在目标驱动系统中，使用一个主传感器进行跟踪，然后使用该传感器的航迹来指导其他传感器，从而获取报表数据，或者搜索整个数据库，找出与该主传感器的航迹最为匹配的报表数据。

##### 2. 测量数据与航迹的关联

对来自多个传感器的测量数据与航迹进行合适的关联，最终求得最优的跟踪航迹文件，每个航迹文件其实就代表了一个独立的实际目标或实体。**关联实质上要求其他算法能够进行配准数据，预测门限，确定关联尺度，关联数据与航迹以及估计目标位置，动态特性及属性等。**

###### 2.1 数据配准 - 时-空坐标系

通过对空间与时间的参照系的调整、坐标系的选择与变换，建立起一个通用的时-空参数坐标系，我们需要对数据进行配准。在数据的配准过程中，我们需要考虑由于测量精度所限，坐标系的转换以及目标的机动等因素所带来的误差。

###### 2.2 数据与目标的关联

数据与目标的关联又包括建立**预测跟踪门、定义关联尺度、实施数据关联以及进行航迹对航迹的关联。**

-   **2.2.1 预测跟踪门：**建立预测跟踪门时为了把数据集分成两大类，**即一类是更新旧航迹的数据，另一类是初始化新航迹的数据。**如果最初那些用来更新旧航迹的数据没有被分配给一条已有的旧航迹，那么这些数据还有可能被用来初始化一条新航迹。跟踪门的大小反映了我们计算出来的或预测的目标位置的速度的误差，**该误差与计算方法，传感器测量误差以及我们想要的到的正确关联的概率有关。**

-   **2.2.2 数据关联尺度：数据关联尺度是对观测数据相似性的一种定量表示。**关联尺度的定义可以依赖于一些我们可以测量的动态参数（径距、径距变化率、角度和位置）和一些目标属性（温度、尺寸、形象和边缘结构等）。关联尺度可以是空间距离（例如欧式距离）或观测值与预测值之间的相关统计度量（例如马氏距离）；关联尺度也可以是基于某启发式函数，如品质因数，该品质因数使用了目标的动态特性和属性新戏；关联尺度还可以根据事先的假设，如航迹的长度、目标群的密度或者航迹的行为特性来为观测和航迹进行关联度量。

-   **2.2.3 数据关联：在多目标多传感器系统中，数据关联指的是一个统计决策过程。**在这决策过程中，要将各数据报表进行关联，这些数据报表的来源情况可能非常复杂，如来源于多个重叠的跟踪门内，来源于具有多回波或密集回波的跟踪门内，或在跟踪门内还会出现新目标及数据报表来源于连续几个扫描周期的情况等。数据关联技术通常使用**单级跟踪系统或两级跟踪系统**来融合来自多个传感器的数据，从而形成航迹。

    -   在单级跟踪系统中，被多传感器获得的测量数据集中传输到一个处理中心（中央层融合）。在那里这些数据被用来初始化一条新规计或者是对原有的航迹进行更新估计。数据关联就发生在每个传感器的新数据和中央航迹文件之间。
    -   两级跟踪系统有四种不同的形式。**第一种（被称为自治的或分布式的跟踪系统）**把传感器级跟踪与中央级跟踪完全分离开。每个传感器级跟踪器独立地获取数据，然后基于自身的数据初始化，更新及删除航迹。而在处理中心，**把来自各传感器的航迹进行关联而形成中央级的航迹文件。第二种**形式是使用传感器数据或传感器航迹来初始化和维持中央航迹文件。首先由各传感器航迹之间进行关联以形成中央级航迹，这样就为中央级的航迹与航迹关联进行了初始化。**传感器还可以直接传输数据而不是航迹给中央处理中心。第三种**形式是使用传感器数据直接在中央处理中心形成航迹，然后中央处理中心给各传感器提供预测跟踪门以限制各传感器的搜索范围。**第四种**形式是在中央处理中心使用航迹与航迹的关联方法来融合各传感器的航迹，然后删除多余航迹，并且根据提供的航迹的好坏（例如航迹的好欢时基于方差的计算和航迹质量的估计）确定传感器各自的能力。**被融合的数据不仅可能来自于普通的传感器，也可能来自于一境融合过一次的节点处理器。**

    -   数据融合（关联）的方法包括**最近邻技术、全局优化技术及全邻技术。**
        -   在最近邻居方法中，使用硬判断方法将输入数据与一条最佳航迹相配对。**当出现多个紧密排列的入选者或当目标进行机动时，这种方法的性能将急速下降。**
        -   **为了服这种方法的这个缺陷，又产生了许多新的方法。其中之一就是使用$Munkres$或称为快速$JVC$（$Jonker-Volgenant-Castanon$）算法实现所有新数据与任何一条已由航迹进行全局最优关联。**关于$JVC$算法在方向角测量融合中的应用将在第9章详细介绍。**
        -   使用全邻关联算法能克服最近邻算法所存在的一些不足。其中在全邻关联算法类中，有一种算法被称为**延迟决策多假设跟踪**。**在该算法中，每一个候选关联看作是一种假设，这些假设一直保持候选状态，直到有某个判决确认或删除这些假设为止。因为需要未来扫描周期提供足够多的信息来增加对假设判断的正确性，因此这种数据关联方法是延迟的逻辑。**由于逻辑是延迟的，所以只有经过几个扫描周期，算法才能发现被推荐的航迹，那么在此期间，算法可能潜在地人为有多条航迹，这样对态势估计就产生困难。这一不足已经通过一些新的技术加以克服，如只显示最高信任级别的航迹。
        -   **航迹分裂法是多假设跟踪算法的一种变形。**这种方法把跟踪门内的每个数据报表与一个航迹进行关联，但并不特别产生“新”航迹，也不计算它们正确关联的概率，航迹分裂技术通常应用于目标有激动嫌疑是的情况。
        -   与其他全邻关联技术不同，**极大似然法是选择最可能的单个目标报表与某条航迹相关联。**此方法中我们需要假设目标数据，目标航迹及由于噪声、密集回波或假目标所引起的假测量的**概率密度函数**。该算法还需要**定义一个似然函数，即真目标和假目标概率密度函数的乘积，**当该似然函数大于某个我们预先设定的阈值时，我们就认为出现目标。
        -   另外一种形式的全邻关联算法是贝叶斯方法，它被称为联合概率数据关联 ($JPDA$)。$JPDA$方法常用于稀疏回波或密集回波时对多目标的跟踪。与此技术有关的另一项技术是概率数据关联 ($PDA$)，此方法只用于跟踪单个目标。此方法只用于跟踪单个目标。在这些方法中**，每个候选匹配都被用来对航迹的更新，但是它们各自权值是不同的**，而这些权值就是这些候选匹配正确关联的概率。从该算法可以看出，因为所有的测量都作用于航迹的更新，所以就不需要进行延迟的逻辑判决。当我们可以得到准确的先验概率时，贝叶斯技术能提供最优的判决函数。

###### 2.3 航迹-航迹关联

**航迹关联是将传感器层的航迹融合后形成一中样处理层的航迹文件。**目标的航迹可以由位置、速度、方差及其他特征值表示。**为了关联这些传感器层上的航迹，首先要将这些航迹转换到同一个坐标系中，并进行时间配准。**接着在航迹之间的关联时就需要确定门限和度量尺度。**在数据关联部分内容中介绍的各种方法也可以用于这里航迹之间的关联，同样也包括最近邻法，全局优化法和延迟判决法等**，延迟判决法同样是在若干个扫描周期以后对航迹进行操作。航迹关联以后，各输入航迹的位置及其方差进行融合最后形成一条融合后的航迹。**从这一过程可以看出，如果各不同的传感器观测到的状态并不完全一致时，那么在关联过程中指采用它们共同的那部分状态。**剩余的状态附加到航迹中并一致加以携带。随后航迹间的关联其实就是简单存储相互关联的传感器航迹号。因为更新后的航迹来源于各传感器，所以在全局航迹文件更新之前，只要对建立的航迹关联进行确认就可以了。

跟踪问题不仅复杂多样，具体可以分为**单目标单传感器跟踪，单目标多传感器跟踪，多目标单传感器跟踪以及多目标多传感器跟踪问题等。**所设计到的数据与航迹关联技术如下表所示。我们一般根据特定的跟踪复杂度情况加以选用合适的相关方法。当然，也可以用复杂的相关技术去解决相关技术简单的跟踪问题。**还有一种情况需要说明，即当传感器的分辨率不能区分跟踪门内的多个目标时，可以采用群跟踪的方法，而不是对每个单个目标进行跟踪。**

![image-20200924172115540](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vx1e5hj317c0sigrp.jpg)

###### 2.4 对目标位置、动态性能及属性的估计

**对目标位置、动态性能和属性的估计其实就是最优地组合多个观测信息以获得更好的目标的位置、速度和属性（例如尺寸、温度和形状等）的估计值。**对于当前目标的一些参数可以由跟踪滤波器完成。该跟踪滤波器使用某种基于时间序列和相关测量的算法来预测目标的状态和属性。在估计过程中，**我们可以使用动态的或自适应的目标模型**，其算法可以是动态的或批处理的（也就是所有数据同时处理）。一个估计器常常包含有一个先验的关于目标动态与观测的模型，利用此模型来修正状态估计，并在下一个观测值到来之前对目标的未来状态进行观测，从而确定跟踪门的位置和大小。

**当目标发生机动时，有些先验知识就失去了作用，因此就需要修正跟踪滤波器的状态来适应目标机动情况下的要求，**可以采用下述两种方法：第一种是使用航迹分裂法，增加母航迹的状态，从而包含机动的情形；第二种方法称为多机动模型方法，就是为各种不同程度的机动建立不同的模型，并且为每个模型建立相应的跟踪滤波器。可以假设各个不同模型中存在一转移概率，通过该转移概率可以把各跟踪滤波器结合起来，从而可以形成一个总的跟踪滤波器。**我们必须注意：跟踪滤波器的输入状态必须与传感器的观测数据相对应。例如：如果跟踪滤波器的状态是位置、速度和姿态（俯仰、横滚及偏航），但由传感器的到的观测数据只有方位角、高低角和径向距离，没有关于姿态的测量信息，则关于姿态的状态变量是不能被估计的。**

###### 2.5 航迹的初始化

捕获目标，并开始进行跟踪的过程称为航迹的初始化，航迹初始化的方法有很多，最简单的方法是使用单次扫描关联，然后基于期望目标的最小和最大速度建立一个目标检测门。一旦我们检测到有某个点未与任何航迹相关联，那么就要为其建立检测门，然后在随后的扫描中，在检测门的所有点与刚开始的那个点进行关联，任何可以关联上的点都可以为对应的航迹进行初始化。

通常我们需要联系关联两个点才可以初始化$Kalman$滤波器的位置、速度及估计的方差。所以我们可以通过限定只需要连续关联两个点就可以初始化航迹，则第二次的检测门可以达到最小，这样就大大减少了虚假航迹的产生。

**判断初始化后的航迹是否是系统的航迹可以采用"$m$次扫描中有$n$次检测到“的法则来进行，**当然这里的$n$次是指$n$次初始化后的航迹是系统航迹。$n$和$m$值的确定主要依赖于能容许的虚假航迹数、目标检测率、回波密度以及容许延迟判别航迹的时间等。

另一种航迹初始化的方法时对存储好的若干扫描周期内的数据应用最大似然法，求出最大可能的检测关联，从而初始化新的航迹。在这种情况下，处理器的容量往往限制了扫描周期数。

### 3.3 处理层2，3和4 - 预测&规划&修正

当处理层1（感知）或更低的处理层完成任务后，目标的身份及航迹价将被输入到更高层融合，即进行态势评价（处理层2）或威胁估计（处理层3）。对整个融合过程的调整（处理层4）一直对整个融合过程进行评价和控制，这一层还指导传感器这样获取新的数据。

>   根据美国数据融合发展战略小组的定义，在军事角度上，处理层2主要用来分析可能的态势，这些态势是由观测数据和一系列事件来体现的，**因此处理层2应该能描述和解释当前的情况下，固定物理和运动物体之间以及各事件之间的联系。**经过处理层1分析的到的数据被处理层2使用，从而可以对指定事件、兵力部署及战争环境的综合因素有更加深入的认识。
>
>   处理层2在军事方面的应用以下几点：
>
>   -   目标聚类——建立起各目标之间的关系，这些关系包括目标间的时间和空间上的联系，相互通讯方式以及功能依赖关系等；
>   -   事件聚类——建立各不同实体在时间上的相互关系，从而识别出有意义的时间；
>   -   总体考虑和融合——分析在各种态势下的数据，包括天气、地形、海况、水下情况、迪庆或社会政治因素等。
>
>   处理层3主要用于威胁判断、包括估计敌方实力、辨识瘦威胁的机会大小、估计敌方意图和确定威胁等级等。威胁估计不同于态势估计，因为威胁估计要多方面且定量地对地方火力进行分析，从而估计出敌人行动的进程和火力的杀伤力。威胁估计的主要功能有：
>
>   -   实力估计——对敌方火力的大小、位置及作战能力进行预测；
>   -   预测敌方意图——根据地方的行动、通信、教义、文化、历史、教育及政治结构来预测敌方的意图；
>   -   威胁识别——通过对敌方的行动的预测，我方要害部门的实际备战状态分析以及对环境条件的分析、识别出潜在的威胁机会；
>   -   多方面估计——对敌方、我方一集中立方上的数据进行分析，包括兵力部署在时间及空间上的效果以及对敌方作战计划的估计；
>   -   进攻与防御分析——根据交战的规则、敌方的教义以及武器类型模型进行敌方交战，并预测交战的最后的结果。
>
>   处理层4（修正）主要完成对融合过程的监控和评价，并且知道如何获取数据，从而可以达到最佳的融合效果。**该处理层与其与各层、系统外部及系统操作人员都要发生联系。**处理层4主要功能包括：
>
>   -   评价——对融合过程的性能和效果进行评价，以建立融合的实时控制及实现长远性能的改善；
>   -   融合控制——在数据融合中，识别出各功能处理模块的变化和自身的调整，以便促进起性能改善；
>   -   对特殊信息源要求的处理——确定对特殊信息源数据的（特殊的传感器、特殊传感器数据、良好的数据及参考数据等）要求，改善多层融合效果；
>   -   任务管理——合理部署各种资源（传感器、平台及通信等）以实现全局目标。

在高层融合处理构成中，常常用到大型数据库，并且要求这些大型数据库能实现数据的快速CURD、数据库管理系统对数据库进行维护、并且具有监视、幅值、添加、更新、检索、合并及删除数据的功能。数据库中记录的时间标签技术、可以用来帮助建立从数据库中抽取的相关推理。

>   下图显示了一种能应用于军事中的指挥与控制结构，该结构把传感器数据与其他不同来源的信息融合在一起。图中左表圆环内的内容说明了该粒子的工作环境，其中包括在处理层1、2、3中的到的关于态势和威胁的估计以及能帮助识别目标身份并进行级跟踪的数据。支持融合处理的信息来自陆地、空中、海上及位于空间的各个传感器给出的探测和跟踪数据，包括来自GPS的的我方导弹引导数据、致命性打击估计、火力/武器组合、瞄准能力、战斗命令和敌方及我方火力的警备状态等。还需附加的信息包括气象数据、外交指令、政治与经济因素的分析以及其他情报。中间部分描述了处理层1的实时传感器数据融合及用来帮助目标识别与跟踪的数据库记录。**来自同类和非同类传感器的数据分别进行处理，这就说明了对于每种类型的信息需要各自不同的处理过程。**在图的右方显示了需要使用另一个数据库来为处理层2和3提供信息，从而实现对态势和威胁的估计。数据库管理系统（DBMS）具有对数据库进行日常维护的功能。**节点互联框表示处理过程可以在节点内进行，也可以在节点之间进行。**最后，**图中“动态的，综合（集成）的形势”这句话代表了军事环境不断变化的特性，说明了融合结果是依赖于综合考虑来自多个不同级别上的传感器信息的。**
>
>   ![image-20200925095317438](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1vz5egyj317m0qswmi.jpg)



### 3.4 结构的定义

结构是指一种由多个单元组成的系统，该系统内的各单元按一定的结构组合起来，从而能达到任何个体单元所不能达到的功能。

一种结构往往能给我们指出概念上的设计信息，从而使我们能够进行成本效益分析、风险分析以及进行技术转变等，这里的设计信息包括具体的单元不见及它们的相互联系、数据和信息流、系统的工作方式、各子结构的功能分配以及当某子结构发生故障时替代子结构的功能分配等。**一种结构实际上已经确定了系统在运行、测试及技术支持上的要求、并且也确定了对结构组件（也就是指系统内部单元，或者内部一些单元的组合，它们能实现各自的功能并常常被用来进行结构控制）的约束。**随着一种结构的不断成熟，它将能给出底层的详细的设计信息，利用这些设计信息进行系统单元的设计，最后进行组合以形成产品或某一处理过程。通过以下章节的介绍可知数据融合结构的定义也属于这个广义结构定义的范围。

### 3.5 数据融合处理过程

我们有必要在勘查各种数据融合结构之前，先对融合处理器中出现的几种处理方式作一正式定义。融合处理器分析来自所有传感器的输出，并对其进行配准、关联、相关、估计、分类与信息反馈等。各部分的定义如下：

-   **配准**——将传感器数据统一到同一参考时间和空间中；
-   **关联**——使用某种度量尺度将来自不同传感器的航迹与景测数据（数据报表）进行比较，以确定要进行相关处理的候选配对。
-   **相关**——对关联后的航迹和报表进行处理以确定它们是否属于同一个目标，从而帮助对感兴趣的物体进行检测、分类和跟踪。**感知是一种关联和相关性的研究。**
-   **估计**——使用相关处理后的结果通过对目标的状态变量与孤寂误差方差阵进行更新，从而实现对目标未来位置的预测；
-   **分类**——通过对航迹与目标的特征数据的分析，确定目标的类型，杀伤力以及威胁优先级；
-   **信息反馈**——将各阈值，处理时间及其他处理参数或信息进行反馈，例如这些信息可以是根据融合后的结果，需要对某一区域进行更详细的搜索等。举个例子来说，如果发现某个区域的回波比较密集，系统就应该给某个合适的传感器发送一信号，使相应的阈值抬高。同样地，当融合处理过程识别出一假目标时，系统就应该发送一描述该假目标位置的指令，以减少在该区域内对目标搜索所需要的信号的时间。信息反馈的另一个应用就是初始化如对一个小范围，但是我们所感兴趣区域的搜索，主要是使用具有高分辨率但视野有限的传感器，如激光雷达｜高精地图。

### 3.6 数据融合的结构

数据融合的结构有多种不同的分类方法。**其中一种分类标准是根据传感器数据在送入融合处理中心之前已经处理的程度进行分类。**在这种分类标准下，融合结构被分为：

-   
-   **传感器数据融合**（也被称为自主式融合，分布式融合或后传感器处理融合等）
-   **中央级数据融合**（也被称为集中式融合或前传感器处理融合等）
-   **混合式融合**，混合式融合是指既有传感器级融合也有中央级融合。

也可以根据数据和处理的分辨率对融合结构进行分类。在这种情况下，融合结构的术语为**像素级融合、特征级融合和决策级融合等。**

#### 3.6.1 传感器级融合

传感器级是指对各传感器独立的不同物理信息进行单独的数据感知处理（特征抽取、目标分类、目标识别和跟踪）在将处理后的目标数据报表放入融合处理器进行分析，传感器级融合的特点在于在进入融合处理器之前，各传感器数据已经进行了低级别层处理，**如果各传感器使用独立的不同物理信号来产生信息，也就是说它们接受到的是物体不同物理特性方面的信号，并且对一个目标，不容易产生虚警时，采用传感器级融合结构是对目标进行检测和分类的最好方法。**传感器级的融合框架如下图：

![image-20200925110736775](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1w07tzpj30vq0lun0a.jpg)

传感器接收到的信号不仅与目标和背景有关，而且还与传感器的参数有关，如下表所示。主动式传感器获得的信号主要体现于发射频率、极化形式、波形形状及功率等，这与被动式传感器是不一样的。当用主动式传感器时，目标的形状、尺寸、材料、小范围内的结构、方位以及相关的一些运动状态都会影响到信号的检测；而目标的辐射情况、粗糙度、入射角、表面温度以及接收器的极化情况都会影响到被动式传感器接收到的信号。背景情况则对主动式和被动式传感器的信号接收都会产生影响。这里的背景主要包括回波情况、天气和其他大气影响以及是否存在反测量。背景对信号的影响主要是通过吸收和散射与真实目标相关的能量或直接产生虚假目标信号。

![image-20200925124108077](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1w1h1tkj31740n2aev.jpg)

在一个多传感器系统中，许多物理现象可以被我们研究。被动式传感器可以根据在传感器视野范围内的温度和辐射量不同将目标和背景加以区分。传感器接收到的辐射依赖于特定物体的表面特性和其工作的带宽。

而激光雷达则靠自身的特点，对多种现象均能感应，它能接受一部分来组目标物体散射的能量，还能接受背景中的能量。背景中的能量与目标的反射率及散射形状和尺寸成正比。从激光雷达还能的到径向数据，从该数据可以计算出雷达到目标的距离。

毫米波和微波雷达也能接收到由目标与背景散射出来的能量信号，这时背景中的能量与目标散射横截面的大小成正比。在大面积搜索时，雷达的扫描能力要强于红外波长类传感器，但分辨率要低一些，而微波和毫米波雷达在雨、雾、云、烟等天气下，与红外传感器比吸收损耗较低。

一旦传感器设计者确定了传感器所提供的信号时来源于独立现象时，各传感器的输出就可以采用传感器级融合结构进行融合处理。接受到的信号首先经过该传感器的优化处理，然后再输入到融合处理中。**在传感器处理其接收到的信号时，依据每个传感器的分辨率、频率、扫描视野，扫描速度及其他属性进行优化处理。有些传感器可以采用时域处理方法，有些传感器可以采用频域处理方法，还有的传感器可以采用像素级的图像处理方法等。**

在融合处理器的检测、分类和识别融合中，每个传感器的输出中必须包含以下两条信息输入到融合处理器中：1⃣️检测、分类和识别的判决结果；2⃣️在视野范围内，传感器以多大的**置信度**来进行检测、分类和辨识。当要进行目标跟踪时，还需要提供3⃣️目标及其航迹的定位信息。有了这三类信息，就可以设计一个融合算法，将每个传感器的输入信息综合起来，作出比单个传感器更加准确的融合结果。事实上可以证明，当各传感器的到的数据来源于独立物理信号时，传感器级的数据融合与中央级的数据融合在检测、分类和辨识目标方面具有相同的最优性（基于贝叶斯决策逻辑而言），基于传感器级数据融合的方法有（将在后续详细介绍）：**贝叶斯推理，D-S 推理为基于布尔代数的表决融合算法。**

#### 3.6.2 中央级融合

对于中央级融合结构，每个传感器都将经过**最小程度处理的测量数据**输入给融合处理器，所谓最小程度处理时指如滤波处理和基线估计等。

一般来说，中央级融合方法比传感器级融合方法要复杂一些，处理数据的速度要求也高一些，这时因为集中式结构要处理的数据只由各传感器作了最小程度的处理。中央级融合算法需要对输入的数据进行处理，以获得目标的特征与属性，从而能在对目标的跟踪和识别中起到辅助的作用。**在估计与预测目标的位置方面，中央级处理比传感器处理器更加有效，也是最优意义上的对目标的跟踪。**$Blackman$给出了中央级处理可以提高跟踪精度的几个原因：1⃣️在某个地方统一处理所有的数据；2⃣️依靠多个传感器获得的数据对航迹进行初始化，从而可以避免由那些单个传感器的部分数据而进行的航迹初始化；3⃣️直接处理由各个传感器得来的报表数据，从而可以消除由于要融合来自各传感器的航迹而带来的困难；4⃣️通过将所有数据输入到一个中央处理器中处理，可以方便地实现多假设跟踪，减少了跟踪法中的多重假设。

而这种中央融合处理的不足之处则是需要实时传输大量数据到融合处理器中，并在此实现实时处理。运用中央级数据融合而进行目标跟踪与识别可以允许个别传感器的数据丢失或缺省等情况的发生。关于中央级融合与传感器级数据融合的有点在下表做了总结比较。

![image-20200925142605433](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1w2joqdj317s0l0dox.jpg)

#### 3.6.3 混合式融合结构

混合融合算法如下图所示，**在此结构中，增加各传感器信号处理算法作为中央级数据融合的补充，反过来，中央级数据融合又作为传感器数据融合的输入。**混合融合的这种结构可以实现使用传感器的测量数据达到中央数据融合的跟踪效果，另外它也可以融合多条航迹，这些航迹就类似于传感器级数据融合结构中各传感器所提供的航迹。最终航迹是在中央处理器中形成的，它融合了各传感器级的航迹和中央级的航迹。如果各传感器的测量信号不能做到完全独立时，可以使用混合融合结构来进行目标属性的分类。这种情况下，经过最低程度处理过的数据直接送到中央处理器中使用某种算法进行融合，实现对传感器视野里的目标进行检测和分类。混合融合结构的不足之处就是加大了数据处理的复杂程度，并且需要提高数据的传输速率。

![image-20200925143224140](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1w3fwfij30sc0n876x.jpg)

#### 3.6.4 像素级融合（基于中央级融合结构）

像素级融合是指使用中央级融合结构，把经过各传感器最低程度处理的**像素数据或一块为单位的数据**进行融合。来自各传感器或同一传感器的不同信道的数据在融合前一般不进行很多处理。

>   像素级融合在$LANDSAT$图像处理中的应用主要是为了检测农作物是否大片的病，还可以用来辨识是否存在某一种特定的作物。在识别过程不是运用单个频段的数据，而是使用所有频段的数据，将这些数据以像素级进行融合，然后进行融合识别。

下图给出了一个运用$CO_2$激光雷达进行像素级融合的例子。用来自处于前景和背景中的物体的距离数据图像（左上）与反映该物体发射特性的灰度数据图像（右上）进行融合。尽管物体在这两种数据图像中都不是很清晰，但是在像素级融合后的数据图像中却显得非常清晰。此时我们就可以采用人工或自动目标分类算法进行**目标分类**等后续处理。如果要融合的数据分别来自不同的传感器，还会遇到一个数据配准的问题，但在这个激光雷达例子中，由于距离图像和灰度图像的像素都来自同一个传感器，故而数据之间相互配准已经得到了保证。

![image-20200925145549878](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1w9t6h9j30u00wykfy.jpg)

#### 3.6.5 特征级融合（基于传感器级｜中央级数据融合）

特征级融合即可以用于中央级数据融合结构，也可以用于传感器级数据融合结构。**从每个传感器数据中提取出的传感器视野中目标的特征数据，然后各目标的特征数据又融合成一个综合特征。**一个特征融合的例子就是把来自单个传感器的特征向量头尾连起来（串联），形成一个“更长”的特征向量，然后输入给某个分类器。

另外一种特征级融合的例子如下图所示**的多层人工神经网络。**目标的特征向量丛毫米波雷达、被动式红外传感器和激光雷达数据中抽取，然后把这些特征向量连接起来形成一个综合特征向量输入到神经网络中。神经网络经过离线训练，可以识别出我们感兴趣的目标，并且把他们从虚假目标中分离出来，这样当我们输入一个新的特征向量时，网络就可以以一定的概率，置信度或优先级指出该特征向量属于哪一类。因为训练网络的时候使用了所有传感器的数据，所以如果某一个传感器由其他类型的传感器所代替，就要重新开始收集数据并进行重新训练。

![image-20200925150225939](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1wcmztzj30sg0fwadh.jpg)

#### 3.6.6 决策级融合

**决策级融合与传感器级融合有关系，每个传感器处理自己接受到的数据，实现对目标的检测与分离，然后再把各自的结果输入给一个融合算法进行决策。**当各传感器接收的信号不是相互独立时，决策级融合的分类性能相比于特征级融合的分类性能来说是次优的。

### 3.7 各传感器有效覆盖区域的配准和对覆盖区域大小的考虑 - 配准问题

当多个传感器分布在不同地点，或者分布在同一个平台的不同位置时，我们希望各传感器对目标检测空间的有效覆盖是相互重叠的，不仅如此，来自于每个传感器的数据需要在**时间和空间上相互对齐和配准**。传感器有效区域之间的彼此覆盖就能保证一些时间相关的信号（例如回波的解相关或目标的运动）在同一时间能被多个传感器观测到。**在传感器有效覆盖重叠的区域进行可以融合最优化设计。如果某种融合算法需要来自重叠区域内所有传感器的数据，那么要求在该重叠区域内的所有传感器必须都能工作在此范围内。**

通常我们所选择的传感器的覆盖范围是不一样的，这样的话就有一个问题，即来自多个传感器的目标报表数据是那个范围内进行比较得到的？最明显的一个选择是在覆盖范围最大区域进行比较。但是如果这样选择的话，数据实际上是在有限或是最小分辨率（比如，所有覆盖区域只用一个像素表示）的情况下进行比较的。那么，对于分辨率高的传感器，如红外传感器等，在把最后数据输入到传感器融合处理器之前，还必须获取和处理在更大覆盖区域内的图像数据。

如果传感器位于不同的地域，就需要使用某种算法和定义一些参数对来自多个传感器的数据进行时间和空间上配准。**在空间配准过程中，还需要考虑测量目标位置所在的坐标系和由于把测量坐标系转换成其他坐标系所带来的误差影响。**目标位置和速度的不确定性，往往反映在其误差值上，一般我们也把他们包括在坐标系的转换所带来的误差上。在实现不同传感器数据关联或在时间、空间上相关数据的关联过程中，往往需要建立跟踪门。**跟踪门尺寸的选择实际上一个在高检测率（使用大尺寸的跟踪门）和低误差关联率（使用小尺寸的跟踪门）之间的平衡折衷过程。**

许多科研人员研究了毫米波雷达和红外传感器的数据配准问题。红外传感器可以提供高分辨率的高低角和方位角的图像数据，而毫米波传感器可以提供的是径向距离和方位角。当这两种传感器的测量范围在设计、操作与成本约束条件方面是完全一致时，其图像配准就比较容易。这两种传感器的数据融合效果还受到其他一些工作条件的限制，例如空间的拓扑结构和潜在虚假目标等。对于传感器的一些检测因素，如传感器的安装、瞄准轴的对准以及对数据的分析等，我们必须也要加以考虑。在毫米波传感器与红外传感器进行像素级融合这个例子中，在进行数据分析的过程中，我们必须要考虑地面的平坦与起伏，只有这样，我们才能得到有效的数据融合结果。

### 总结

本章介绍了由低层融合到高层融合的数据融合方法。低层融合包括目标检测、分类、辨识和跟踪，高层融合则包括态势与威胁估计。用于目标检测、分类与辨识的各类算法大都是基于物理模型、特征推理以及知识推理等。如卡尔曼滤波、贝叶斯推理、D-S 推理、广义证据推理、人工神经网络、聚类算法、表决逻辑、模式识别以及模糊集理论等。

有许多不同的算法可以应用于航迹估计。在**航迹估计算法中需要考虑的问题包括数据配准、数据与目标的相互关联以及对目标位置、动态性能和数据的估计等。**数据配准为融合过程提供了同一的时空参考标准。通过使用预测跟踪门，动态性能和时间关联尺度以及数据与航迹的关联技术可以实现航迹的相关。**预测跟踪门把测量数据分成更新就航迹的候选数据和建立新航迹的初始化数据。**多个数据报表可以来自于重叠跟踪门，跟踪门内的多个回波、杂波，跟踪门内的新目标以及多个扫描周期内所接受到的多个回波等。使用某种度量可以定量地描述这些观测值之间的相似程度。**在多目标传感器融合系统中，数据关联就是使用某种度量来比较航迹和来自多个传感器的数据（报表），以确定最后的候选配对，然后使用相关技术就可以确定关联后得到的配对是否属于同一个目标。航迹关联则将多个传感器中的航迹数据进行合并，以形成一个中央航迹文件。如果把来自多个传感器对目标的位置、动态性能以及属性的估计进行融合，就可以得到更加精确的目标位置、速度和目标身份的信息。**

>   包括了态势估计的数据融合可以解释当前环境下各物体和事件之间的关系。态势估计的重要功能为各物体、各事件和各响应的汇集、解释与融合，包括了威胁估计的数据融合被设计成可以对敌方实力、威胁机会、敌方意图以及危险级别进行估计，还包括对敌方的威胁种类的识别，多层面估计以及对敌我双方作战能力的分析等。

数据融合结构的分类有很多不同的方法，第一种分类方法是基于各传感器数据在输入到融合处理器进行融合之前被处理的程度，在这种分类标准下，融合结构被分为：

-   **传感器数据融合**（也被称为自主式融合，分布式融合或后传感器处理融合等）
-   **中央级数据融合**（也被称为集中式融合或前传感器处理融合等）
-   **混合式融合**，混合式融合是指既有传感器级融合也有中央级融合。

第二种分类方法是基于数据和处理的分辨率对融合结构进行分类。在这种情况下，融合结构的术语为**像素级融合、特征级融合和决策级融合等。**

传感器级融合允许对每单个传感器的信号进行最优化处理，而中央级融合则是在所有的传感器数据到达融合后再进行最优化处理，**在进行选择一个合适的数据融合机构时还需要考虑其他一些因素，例如数据处理和通信资源以及融合后结果的存放位置等。**

## 4. 贝叶斯推理

贝叶斯推理是一种**统计融合算法**，主要基于**贝叶斯法则**来进行推理，和其他需要先验只是算法一样，该方法也需要根据观测空间的先验知识，从而实现对观测空间里的物体的识别。**在给定证据的条件下，贝叶斯推理能提供一种计算条件概率即后验概率的方法。**

### 4.1 贝叶斯法则 - 条件概率

假设在某一事件$H$发生的条件下，求任意另一事件$E$发生的概率。这个概率由以下公式给出：
$$
P(E|H) = \frac{P(EH)}{P(H)}
$$
这里假定事件$H$为正的概率值。	$P(Ε|H)$辨识在事件$H$发生的条件下事件$Ε$发生的概率。注意：当$H$发生的概率为零时，上述定义无意义。

我们可以将上式改写成概率的乘法公式：
$$
P(EH) = P(E|H)P(H)
$$
如果事件$H$是由一系列**互斥且穷尽（独立有限）**的**假设事件**构成，并且条件概率比非条件概率容易获取时，通过下面的推导，可以得到**贝叶斯推理法则。**这里假设事件的**穷尽性是指事件$E$发生时，至少有一个假设事件$H_j$发生的概率不等与零**，也就是说假设事件$H_1,...H_n$的并是整个样本空间。

推导过程：

在这些假设条件下，**任一事件$E$可以表示为与所有假设事件$H_j$交集$\cap$的并集$\cup$。**（也可以写成所有假设事件的并集与$Ε$的交集）即：
$$
E = EH_i\cup EH_2\cup...\cup EH_n = E \cap(H_1 \cup H_2...\cup H_n)
$$


>   在计算机逻辑上，数学上的交集$\cap$对应与$\and$，并集$\cup$对应或$\or$，可以这么理解，对于集$a_1, a_2,a_3$，交集代表相交的空间$a$，所以必须满足$a \in a_1, a\in a_2 , a\in a_3$，这和计算机逻辑上的与（表示同时满足$a_1, a_2, a_3$）意义相同，而并集则表示只需上面三个条件的其中一个，这与或逻辑相同

因为各$EH_j$是互斥（独立）的，所以把各$EH_j$对应事件的概率求和可得到$P(E)$：
$$
P(E) = \sum^n_{j = 1}P(EH_j)
$$
解释式$(19)$，可得：
$$
P(E) = \sum^n_{j=1}[P(E|H_j)P(H_j)]
$$
在贝叶斯推理中，我们主要关心的是在给定证据$Ε$的情况喜爱，假设事件$H_j$发生的概率，可用如下的数学式子表示：
$$
P(H_j|E) = \frac{P(EH_j)}{P(E)}
$$
结合公式$(19)$和$(22)$，即可得到贝叶斯推理法则：
$$
P(H_j|E) = \frac{P(E|H_j)P(H_j)}{\sum^n_{j=1}[P(E|H_j)P(H_j)]}
$$
式$(24)$中：

$P(H_j|Ε)$——在给定证据$Ε$的情况下，假设事件$H_j$发生的**后验概率**；

$P(Ε|H_j)$——在假设事件$H_j$发生的条件下，证据$E$出现的概率，**有时也被称为假设事件$H_j$的似然函数**。

$P(H_j)$——假设事件$H_j$发生的**先验概率**，且有$\sum_jP(H_j) = 1$

$\sum^n_{j=1}[P(E|H_j)P(H_j)]$——出现证据$Ε$的全概率，即在各假设事件$H_j$都可能发生的情况下，证据$Ε$出现的概率和。

公式中的似然函数$P(Ε|H_j)$代表了后验概率$P(H_j|Ε)$相对于先验概率$P(H_j)$的变化程度。**（可以理解为，本身作为独立事件的$H_j$发生的概率在加上了$Ε$事件这个证据（条件），概率变换的程度，这个概率变化程度可以用似然函数$P(Ε|H_j)$来描述，比较抽象，先记着）**。这些似然函数可以通过离线实验获得，也可以通过分析一些有用的信息来获取。

### 4.2 贝叶斯推理和经典概率推理的比较

运用贝叶斯推理中的条件概率公式来进行推理，结果还是令人满意的。首先，当出现某一证据$E$时，贝叶斯推理能确定地给出假设事件在此证据发生的条件下发生的概率，而经典概率推理能给出的只是在发生某一假设事件的条件下，某一观测能够对某一目标或事件有贡献的概率；其次，贝叶斯公式能够潜入一些先验知识$P(H_j)$，如假设事件的似然函数等；**最后，当没有经验数据可以利用时，可以用主观概率来代替假设事件的先验概率和似然函数。**贝叶斯推理的最后这个特性使它可应用于多传感器的数据融合，因为它不需要各传感器的概率密度函数，但这种处理if昂事得到输出性能智能接近于采用先验知识输入时的性能。

贝叶斯推理解决了经典概率推理遇到的一些困难问题，但是贝叶斯首先需要定义先验概率和似然函数。**当出现多个假设事件和各事件条件相关时，贝叶斯推理也变得复杂起来。同时这宗推理方法还要求各假设事件互斥，而且不能处理带有不确定性的问题。**

![image-20200927110643835](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1wk6ve0j30x00u0app.jpg)

#### 4.2.1 贝叶斯法则计算例子

下面通过例子说明使用贝叶斯法则计算后验概率时，作为先验知识的似然函数是如何影响后概率值的。

>   假设一病人到一医生那看病，医生用一低廉的检测方法来判断他是否得了癌症，该方法有95%的检测率（也就是说，如果这个病人得的是癌症的话，那么该检测方法在100次检查中，将有95次显示阳性）以及4%的误诊率。并且还假设在人群中，每1000个人就有5个人患癌症 ，如果现在该病人用这种方法被检测出是阳性，则他实际患癌症的概率是多少？

-   假设检测获得阳性的事件概率为$P(A)$

-   患癌症的事件概率为

    $P(B)$

根据题目，我们通过贝叶斯法则需要求的检测出阳性情况下患癌症的概率为：
$$
P(B|A) = \frac{P(BA)}{P(A)}
$$
根据题目有以下已知事件概率：

-   患癌症情况下，用低廉检测方法检测到阳性的概率：$P(A|B) = 0.95$
-   误诊率：即病人无癌症情况下，被诊断为阳性的概率：$P(A｜\bar{B}) = 0.04$ 

-   一般人群中患癌症的概率：$P(B) = 0.005$

根据贝叶斯法则，有：
$$
\left\{
\begin{array}{**lr**}
P(BA) = P(B|A)P(A) = P(A|B)P(B)\\
P(A) = P(A|B)P(B) + P(A|\bar{B})P(\bar{B})
\end{array}
\right.
$$
结合$(25)(26)$，有
$$
P(B|A) = \frac{P(A|B)P(B)}{P(A|B)P(B) + P(A|\bar{B})P(\bar{B})} = \frac{0.95 \times 0.005}{0.95\times0.005+0.4\times0.995} = 0.107
$$
也就是说，在使用低廉检测试剂的情况下，患者这检测结果呈阳性条件下实际得癌症的概率只有10.7%，从直觉上看，这个结果比我们预期要小，即根据检测结果为阳性而判断患者有癌症的准确率只有10.7%，这种情况下我们需要做进一步检查。虽然这种检测方法在已得癌症的病人中有95%的检测率（$P(A|B) = 0.95$），从这一点上可以说它是可靠的，但它的第二类错误率还是达到了$0.05$（接受了“检测不为癌症”($H_0$)这个结果，但实际上$H_0$是错误的），这意味着每20个癌症病人中，就有一个漏诊。

所以当检测结果为阳性时，为了能在更高程度上确认患癌症的概率，同时要减少检测漏诊（第二类错误）的概率，我们则只能采用一种更高准确度的方法（这里可以说是检测率更高的检测方法）。一种能有效地提高后验概率（$P{B|A}$）的方法是减少误诊率，例如，如果该检查方法的检测率达99.9%，并且它的误诊率减少到1%，那么，在病人检查为阳性的条件下，他确实患癌症的概率达33.4%，此时反映误诊的第二类错误为$\frac{1}{1000}$。如果进一步提高检测率到99.99%，此时对后验概率的影响就比较小了，但是也能减少误测率一个数量级。

有时候，第一类错误（不接受$H_0$，但实际上$H_0$是正确的）变得更严重。比如这种错误的发生：根据某一现象把一个清白的人宣判称一个罪犯并且还判了刑。如果反映某个人清白的假设被拒绝承认，那么这个无辜人就被认为有罪，这就发生了第一类错误，另一方面，如果这个人本身有罪（$H_0$是错误的），但是反映这个人清白的假设被承认（接受$H_0$），那么这个罪犯将被释放，这时就出现了第二类错误。

当贝叶斯推理应用于身份信息的融合时，采用采用下图所示的处理流程。

![image-20200927140536275](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1wmla06j312c0u0te0.jpg)

这里用多步部雷达对某一身份不明的物体的参数数据（比如红外信号、雷达波束的横截面、重复脉冲的时间间隔以及敌-友识别信息等（IFF））进行观测，每部雷达利用自身的观测数据和算法来对时间间隔目标作一身份识别$D_i$，也就是对该目标的身份作用一假设。**每个传感器以前建立的（也就是先验知识）一些分类算法的特性（可以是理论上的也可以是通过实验获取的）能提供给我们一个条件概率（似然函数），即已知目标为第$j$类型的条件下，传感器能判别该目标属于$D$的概率，这个概率被记为$P(D|O_j)$**，然后对每种目标类型$O_j$使用式$(18)$的推广形式来结合所有传感器的判决结果，最后形成对每个物体类型$O_j$更新了的联合判别概率。

这样，在传感器1的判决为$D_1$，传感器2的判决为$D_2$等的条件下，从$M$种物体类型中判决的第$j$种物体的概率可以表示为（**这里用交集$\cap$表示各传感器分别观测到了各种识别特性$D_i$，是在一次观测中得到的，说明他们有时间&空间上的一致性）：**
$$
P(O_j|D_1\cap D_2 \cap...\cap D_n), j = 1,...,M
$$
通过上式计算出来的最大值所对应的目标类型作为最后的判决结果。这种判决法称为最大后验概率（$MAP$）。在这里，贝叶斯公式提供了一种把来自于各传感器对某一种物体的身份判决结合起来的方法，最后形成一个新的并且能够改善判决精度的联合身份判决。

在使用贝叶斯方式时，需要我们事先能计算每个传感器对每个假设时间的似然函数$P(Ε|H_j)$，以及各假设事件$H_i$的先验概率$P(H_i)$。当先验知识里缺少各假设事件$H_i$发生的可能性时，我们可以采用无差别对待原则，即可以为各$P(H_i)$设置相同的值。

贝叶斯法则应用经常和现代概率论中的置信区间的应用相比较。**尽管贝叶斯法则对某些数据融合的应用提供了一种合适的推理方法，但是当我们想要以某一概率来确定表征某一分部的参数（如均值和方差）落在某一区间时，采用置信区间理论的推理方法将会变得更合适。**

### 4.3 用来自两个传感器的不同类型的测量数据提矿物的检测率

>   通过融合来自多个传感器的数据可以提高对地雷的检测率，这些传感器能够响应独立物理现象所产生的信号，在这个例子中使用**金属探测器**和**地下探测雷达**这两种传感器就能达到此目的。金属检测器$MD$能检测出大于$1cm$且只有几$g$重的金属碎片的存在，地下探测雷达$GPR$能利用电磁波的差异从土壤和其他背景中发现大于$10cm$的物体。尽管金属检测器只能够简单地区分物体是否含有金属，但是$GPR$却具有物体的的分类功能，因为他们对物体的多个属性有所响应，如尺寸、形状、物质类型和内部结构等。

在$Brusmark$等人的实验中，把一金属含量低的地雷、金属条、塑料、蜂蜡（一种能引爆的物质）和石头埋在沙下$5cm$深处。金属检测器信号的幅度和物体的金属含量成正比。$GPR$发射频率为$300~3000MHz$的电磁波。用一个训练完的神经网络对$GPR$探测到的物体进行分类，神经网络的输入时对$GPR$输出信号的以下四种分析得到的特征量，即傅立叶变换分析、双谱变换分析、小波分析、小波变换分析和局部频率分析。

可以用贝叶斯推理来计算被测物体是属于哪类的后验概率，这里的类别限定在地雷（$MINE$）、非地雷（$\bar{MINE}$）和背景物（$BACK$）。**用贝叶斯方法来进行数据融合主要是对概率的不断更新。**

![image-20200927151534283](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1wntx4jj31840jwdiv.jpg)

在这个例子中，当我们知道前一时间段的后验概率时，贝叶斯法则可以采用如下的形式：
$$
P(C_j|AB) = \frac{P(B|C_iA)P(C_i|A)}{\sum_j[P(B|C_jA)P(C_j|A)]}
$$
式中：

-   $P(C_j|AB)$——已知前一时间段状态A和当前数据B的条件下，被测物体属于某一类$C_j$的**后验概率**。
-   $P(B|C_jA)$——已知前一时间段状态$A$和给定物体类型$C_j$的条件下，能观测到数据$B$的概率（**也就是$C_j$的似然函数**）。
-   $P(C_j|A)$——已知前一时间段状态$A$的$C_j$的**先验概率**；
-   $\sum_j[P(B|C_jA)P(C_j|A)]$——观测数据$B$的全概率，即一致前一时间段状态$A$和各假设事件$C_j$都可能出现时，观测到的数据为$B$的概率和。

**传感器在已知物体类型的条件下能观测到的该数据的概率（单个传感器的似然函数）由下式给出：**
$$
P_{MD}(数据|O_j) = P_{MD}(数据|MINE)P(MINE|O_j) \\+ P_{MD}(数据｜\bar{MINE})P_{MD}(\bar{MINE}|O_j)+P_{MD}(数据｜BACK)P(BACK|O_j)
$$

$$
P_{GPR}(数据|O_j) = P_{GPR}(数据|MINE)P(MINE|O_j) \\+ P_{GPR}(数据｜\bar{MINE})P_{GPR}(\bar{MINE}|O_j)+P_{GPR}(数据｜BACK)P(BACK|O_j)
$$

这里$MD$代表金属探测器，$GPR$代表地下探测雷达，$O_j$代表第$j$种类型的物体（雷达｜非雷达｜背景）。在上图中的“传感器报表”和“给定报表下的类型识别”之间的箭头代表了用式$(30)(31)$所定义的概率计算。

-   金属检测器的似然函数值，即$P_{MD}(数据｜MINE)$、$P_{MD}(数据｜\bar{MINE})$和$P_{MD}(数据｜BACK)$以及地下探测雷达的似然函数值，即$P_{GPR}(数据|MINE)$、$ P_{GPR}(数据｜\bar{MINE})$和$P_{GPR}(数据｜BACK)$ **可以通过先验测量获得**。
-   而我们可以让金属检测器接受到的“数据”变换到某些预先设定的信号幅值上，此时在给定某一物体类型$O_j$的条件下，$P_{MD}(数据｜O_j)$就等于金属检测器能接受到对应幅值信号的概率，这个概率可以通过做大量实验获取。例如：在实验中可以埋入一些由不同物质组成的，尺寸各异的类似于地雷的物体。在扫描区域里被地下探测雷达捕捉到的信号输入到人工神经网络来识别一些具有杀伤性的地雷，通过多次实验得到的神经网络输出可以用来计算$P_{GPR}(数据｜O_j)$。
-   而$P(MINE|O_j)$、$P(\bar{MINE}|O_j)$和$P(BACK|O_j)$的定量值则依赖于地雷区类似于地雷的物体的数量和与地雷的相似度。

而计算在某一时间间隔内的联合传感器报表概率（**联合似然函数**），可以通过将$(30)(31)$两式相乘获得，能这样做是因为这两个传感器分别响应了独立物理现象产生的信号，也就是说这两个传感器测量的是不同类型的信号。此时联合报表概率为：
$$
P(数据|O_j) = \prod_iP_i(数据｜O_j)
$$
其中$i$是传感器的下标，这里$i = 1,2$

**最后使用贝叶斯法则基于前一时间段的后验概率$P_{t-1}(O_j|数据)$和先验概率来计算当前时间物体是第$j$类的后验概率$P_t(O_j|数据)$。**结合式$(29)$，可得：
$$
P_t(O_j|数据) = \frac{P_t(数据｜O_j)P_{t}(O_j) - 似然函数（左）和先验概率（右）}{P_{t-1}(数据) = \sum_jP(数据|O_j)P(O_j) - 全概率}
$$
这里：

-   $P_t(数据｜O_j)$为当前时间的**似然函数**

-   $P_{t}(O_j)$是**先验概率**，也就是上一个时间段的后验概率值，即有：$P_t(O_j) = P_{t-1}(O_j|数据)$

-   $P_{t-1}(数据)$是上一个时间段观测到的某数据的全概率。**即在上个时间段，在各物体类型$O_j$都有可能出现的条件下，观测到的该数据的概率和。大的$P(数据)$值意味着前一时间段的这些数据更具有预测性**

$$
P_{t-1}(数据) = \sum_jP(数据|O_j)P(O_j)
$$

当各个传感器在当前时间段不能对物体的类型进行判断时，概率的更新就不能进行，此时当前时间段的后验概率$P(O_j|数据)$被设置成与上一个时间段的后验概率$P(O_j|数据)$相同。

因为在这个例子中的主要任务是发现地雷，所以式$(30)(31)$的第二、三项可以合并成一简单判决$\bar{MINE}$，即没有地雷的意思。这样，**这个问题就进一步简化成从$O_1 = MINE$（有地雷，可以泛化成有威胁的意思）和$O_2 = \bar{O_1}$（没地雷，泛化成没威胁的意思）。因此，我们需要的概率仅仅依赖于$P(数据｜O_1)$，**因为有：
$$
P(O_2) =P(\bar{O_1}) =  1- P(O_1) \\ P(数据|O_2) = 1 - P(数据|O_1)
$$
在计算式$(33)$时，**需要给先验概率$P(O_1)$一个初始值，并且还要给后验概率$P(O_1|数据)$一个可行的上下限（$[0,1]$之间）**。而这个例子中，共埋了5种不同类型的物体，所以给$P(O_1)$的初始值为$0.2$，而$P(O_1|数据)$的上下界被限制在$(0.01,0.99)$，这样做是为了防止在计算后验概率时到达0或1而过早地终止计算。然后把式$(33)$运用于$MD$和$GPR$这两传感器的联合报表概率从而得到更新的联合后验检测率，这里的联合报表数据是以由扫描数据所形成的一个矩阵形式来给出的。我们可以把$GPR$接受到的信号通过一个匹配滤波器来消除由于天线方向性带来的畸变，从而改善这一处理过程。

知道了物体类型的后验概率$P(O_j|数据)$后和整个地区的形势后（整个地区的形势用$P(MINE|O_j)$等来定义），我们就可以计算这个物体是属于地雷、非地雷或某一背景的后验概率，即：
$$
P(MINE|数据) = \sum_j[P(O_j|数据)P(MINE|O_j)] \\ P(\bar{MINE}|数据) = \sum_j[P(O_j|数据)P(\bar{MINE}|O_j)] \\ P(BACK|数据) = \sum_j[P(O_j|数据)P(BACK|O_j)]
$$
因此，确实是否是地雷的概率是一些单个概率的和，这些单个概率反应了各个不同特征在身份识别上的贡献。$P(MINE|O_j)$反映了已知物体属于$j$种类型的条件下是地雷的先验概率。在这个用金属探测器和地下探测雷达融检测的例子中，其实架设了金属探测器能单独检测出金属含量很低的地雷。然而， 有两点应注意的事项：1⃣️是数据融合算法必须具有鲁棒性，使系统能识别出一些没有被预料到的物体，2⃣️是如果金属检测器不能检测出金属时，这个系统必须要设计成能依赖于多个地下探测雷达来识别物体。

### 总结

可以从传统的条件概率，即假设某一证据发生时另一时间发生的概率来推导贝叶斯法则。贝叶斯的条件概率公式由于以下几个优点：首先当给定某一证据时，它能提供一种计算某一假设事件概率的方法；其次，贝叶斯公式允许嵌入一些关于假设事件的先验知识；最后，贝叶斯推理允许使用主观概率，这些主观概率包括假设事件发生的**先验概率**，以及在假定事件发生的条件下出现证据的概率（**似然函数**）。

贝叶斯推理的最后一个特性使它能使用于多传感器的融合，因为它不需要各传感器的概率密度函数。然而，此时的处理结果只能接近输入时先验概率数据时的结果。

## 5. $Dempster-Shafer$算法

>   当个传感器对它们各自的判决不能百分之百确信时，可以采用一种基于统计方法的数据融合分类算法。即$Dempster-Shafer$算法，该算法能捕捉、融合来自多传感器的信息，这些信息在模式分类中具有确定某些因素的能力。**使用$Dempster$规则来融合各传感事件时（也称之为命题）的知识，最后找到个命题的交集$\cap$（也叫命题的合取）及与之对应的概率分配值。**

### 5.1 算法概述

下图给出了$Dempster-Shafer$数据融合构成的框图。在此框图中每个传感器都有一组可观察量，这些可观察量都体现了物体及他们所在环境的某些信息。**各传感器对这些可观察量再利用各分类算法（传感器级融合）进行分类，这里对每个传感器$k(k = 1,...,N)$所能得到的知识，也就是对物体类型的判别（用$a_i$表示，$i = 1,...,n$）赋予一个$0$到$1$之间的概率分配值$m_k(a_i) \in [0,1]$**，这个概率分配值反应了对该判决的**确信程度**，概率分配值越接近于$1$，说明该判决越有明确的证据支持，从而对物体类型的不确定程度就越低。然后**各传感器的各概率分配通过$Dempster$规则融合，从而再选出某种假设，使该假设能被在各传感器上已经得到的绝大多数证据所支持。**

**除了使用传感器实时的得到的数据之外，我们还可以在信息库里存储一些其他信息或规则来提高判决或目标识别的能力**，如“在某一已知航道里航行的船只能是货船“及“在某一预定标定的地球轨道上运行的是侦察或气象卫星”等等。

我们把每个传感器对目标的相关信息都存储在一计算机中，也可以说，如果任何一传感器的输出都不支持某些目标时，这些目标就不被存储在计算机中。**数据融合的过程就是要找出两个或更多个传感器输出的交集$\cap$及可用的规则。**

![image-20200928104442397](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1wou56ij312a0pmdkz.jpg)

### 5.2 算法的实现

假设有$n$个互斥且穷尽的原始子命题存在，比**如目标的类型是$a_1 \or a_2 \or...\or a_n$。这个命题集组成了整个假设事件的空间，我们称之为识别框架，用$\Theta$表示**。对该命题集里的每个子命题都可以赋予一个概率分配值$m(a_i)$。不仅如此，**我们还可以根据传感器提供的信息为某些子命题的并赋予分配值**，如目标类型$a_1$和$a_2$的并$\cup$（也叫**析取**，记为$a_1 \cup a_2$）赋予概率分配值$m(a_1 \cup a_2)$。**所有的命题数（包括对子命题所有可能的并，但空集除外）称作该命题集的幂集数等于$2^n -1$**。（这点就是相比起贝叶斯法则的优点）

**如果碰到不是所有的概率分配值都直接赋给各子命题或他们的并时，我们把剩下的概率分配值全部分配给识别框架$\Theta$ (它代表了由未知情况引起的不确定**，以后该概率分配至可以进一步的细化），即$m(\Theta) = m(a_1 \cup a_2 \cup,...\cup a_n)$。

>   《**如果碰到不是所有的概率分配值都直接赋给各子命题或他们的并时**》这句话可以理解为实际情况中，某一子命题是：目标是一个行人。而传感器所得到的知识是：目标的温度在$30^{\circ}C ～ 36^{\circ}C$。这里知识于子命题没有明确直接的关联。**这个理解不太准确，先记着，后续尝试假设解释**

对于某些子命题的并可以表示为某个命题的反命题，如$m(\bar{a_1}) = m(a_2\cup a_3 \cup...\cup a_n)$，这里子命题上面的横线即代表该命题的反命题，**把概率分配至赋给识别框架$\Theta$实际上就代表了传感器对所关心的证据的精确性，或对证据的诠释还存在不确定性。**

**赋给各子命题，子命题的一些并命题，整个识别框架以及某些反命题的所有概率分配值的和应该等于1。**

为了进一步解释这些概念，假设有两个传感器检测一个由三个目标存在的场景。**传感器$k_1$识别出某一目标可能是属于三种类型$a_1\or a_2 \or a_3$中的某一种：传感器$k_2$由80%的确信度判决该目标属于类型$a_1$**，在这种情况下，两传感器命题的交集可以写为：
$$
(a1 \cup a_2 \cup a_3)\cap (a_1) = (a_1)
$$
这时，只能给这两个传感器的交集赋予$0.8$的概率分配值，$0.8$这个值是从传感器$k_2$的80%的确信度中推出的。剩下的$0.2$的概率分配值赋予了代表不确定的并命题（析取命题），即$a1 \cup a_2 \cup a_3$。

### 5.3 支持度、似然度以及不确定区间

>   $Shafer$曾经说过：“一个证据对某一命题$a_1$的影响**至少**应包括两个方面的信息：证据是如何有效地证明命题$a_1$，以及证据是如果有效地证明其反命题$\bar{a_1}$。这两个方面的信息可以分别通过对命题的**支持度**和**似然度**进行描述。

#### 5.3.1 支持度 $S(a_i)$

一个给定命题的支持度是这样定义的：“**传感器直接分配给该命题证据所对应的概率分配值的和**”。这里传感器直接分配给该命题的**证据**是指：该命题及组成该命题的子命题的某些并$\cup$命题的集合，这些并命题是指被传感器赋予一定概率分配值的并命题。按照这个定义，某个传感器判决目标类型为$a_1$的支持度$S(a_1)$等于：
$$
S(a_1) = m(a_1)
$$
进一步泛化，多个传感器（$k_1,k_2,k_3,...,k_n$）判决目标类型为$a_i$的支持度$S(a_n)$等于：
$$
S(a_i) = \sum_km_k(a_i)
$$
某个传感器对目标类型属于$a_1 \or a_2 \or a_3$的支持度为：
$$
S(a1 \cup a_2 \cup a_3) = m(a_1)+m(a_2)+m(a_3)+m(a_1 \cup a_2)+ \\m(a_1 \cup a_3)+m(a_2 \cup a_3)+ m(a_1 \cup a_2 \cup a_3)
$$

#### 5.3.2 似然度 $Pl(a_i)$

一个给定命题的似然度是这样定义的：“所有没有分配给这个命题的反命题的概率分配值的和。”换句话说，**一个命题的似然度等于只要能在某方面支持该命题的所有概率分配值的和**，$a_i$的似然度可以写为：
$$
Pl(a_i) = 1- S(\bar{a_i})
$$
这里$S(\bar{a_i})$称为$a_i$的疑惑度，它代表了**证据反驳命题的程度**，也就是说，证据支持原命题对应的反命题的程度。**也就是说，似然度就是所有不能说明原命题错误的证据的概率分配值的和（1 - 所有说明原名题错误的证据的配率分配值的和）**

似然度也可以这样来计算，把和$a_i$及与$a_i$有关的并命题（包括识别框架$\Theta$）的所有概率分配值相加起来，即：
$$
Pl(a_i) = m(a_i) + m(a_i \cup a_1) + m(a_i \cup a_2) + ...+m(\Theta)
$$
不确定区间定义为$[S(a_i),Pl(a_i)]$,这里显然有：
$$
S(a_i) \le Pl(a_i) 
$$
下图直观显示了不确定区间这个概念。

<img src="/Users/RunshengWU/SensorFusion/Images/intervaleNotSure.png" alt="image-20200928114304148" style="zoom: 50%;" />

不确定区间的下界也就是命题的支持度，应等于基于传感器的直接证据而得到的命题发生的最小概率；不确定区间的上界也就是命题的似然度，应等于命题的支持度再加上命题潜在可能发生的概率。因此，这两个边界能说明某个证据中有多大比例是真正支持某个命题的，有多大比例是我们对该证据的不了解，以及有多大比例是为了概率分配函数的归一化。

从传感器（一个知识源）信息中得到的支持度和概率分配值代表了两个不同的概念（但对于直接证据，他们的值相同）。

-   支持度是直接分配给某一命题和由组成该命题的子命题的某些并命题所对应的所有概率分配值的求和。
-   而命题的概率分配值是由传感器根据一些证据，把一定的确信度分配给某一命题的能力所决定的。

下表进一步解释了不确定区间的这个概念。

![image-20200928120200568](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1wpayymj317y0m6jvl.jpg)

#### 5.3.3 例子 - 从传感器提供的信息计算不确定区间

考虑再某一时刻一共有三种类型的目标$a_1,a_2,a_3$被单传感器$k_1$所探测到，假设传感器$k$的识别框架为：
$$
\Theta= {a_1, a_2, a_3}
$$
则$a_1$的反命题为（子命题之间互斥）：
$$
\bar{a_1} = a_2,a_3
$$
假设传感器$k$分配给各命题$a_1,\bar{a_1},a_1\cup a_2 $和$\Theta$的概率分配值为
$$
m_k(a_1, \bar{a_1}, a_1 \cup a_2, \Theta) = (0.4, 0.2, 0.3, 0.1)
$$
使用这些值可以计算出各命题$a_1,\bar{a_1},a_1 \cup a_2$和$\Theta$的不确定区间（见下表）

![image-20200928133046565](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1wqbrs9j31820lyjw4.jpg)

命题$a_1$和$\bar{a_1}$的不确定区间是可以直接看出来的，因为他们就来自传感器的直接证据。

命题$a_1 \cup a_2$的不确定区间要使用传感器$k$支持命题$a_1$和$a_1 \cup a_2$的直接证据。

分配给识别框架$\Theta$的概率分配值$m_k(\Theta)$表示其不能再分给更小的子命题，这个值不应包括在命题$a_1 \cup a_2$的支持或反驳证据所对应的概率分配值之中，因为$m_k(\Theta)$就代表了在把概率分配值直接赋予命题或他们的一些并命题时 ，对由于不知道所引起的不确定部分的概率分配值。也就是说，传感器可以把概率分配值赋予命题$a_1,\bar{a_1},a_1 \cup a_2$，而把剩下的概率分配值赋予$\Theta$，这就说明了在赋予各命题概率分配值时存在由于不知道的情况而引起不确定性。

命题$\Theta$的不确定区间可以这样得到：命题$\Theta$的支持度为1，因为它是所有命题的并，同时它的似然度也等于1，这是因为在分配概率分配值时没有超出$\Theta$的范围，因此$m_k(\Theta) = 0$，似然度$ Pl(\Theta) = 1 - S(\bar{\Theta} = 1- 0 = 1)$，这与“命题$\Theta$是所有命题的并，它包含有所有不知道情况所引起的不确定部分概率分配值”对应

>   关于证据对命题的影响，在文献中有两套术语同时在使用过，即主观系统术语和证据系统术语，$Shafer$使用证据系统术语中的支持度来描述主观系统术语中的信任度，在下表列出了其他主观系统术语和证据系统术语之间的对应关系。
>
>   ![image-20200928133330707](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1wrmtrcj31ae0cu77d.jpg)

### 5.4 用$Dempster $规则融合多传感器数据

$Dempster$规则可以用来融合来自多个传感器或信号源的相容命题对应的概率分配值，从而得到这些相容命题交集（**也称合取**）命题所对应的概率分配值。所谓相容命题是指命题之间有交集存在。下面用一个四目标两传感器的例子来说明如何运用该法则进行融合。

假设存在四个目标：$a_1,a_2,a_3,a_4$

| $a_1$ | 我方类型为1的目标 |
| ----- | ----------------- |
| $a_2$ | 我方类型为2的目标 |
| $a_3$ | 敌方类型为1的目标 |
| $a_4$ | 敌方类型为2的目标 |

传感器$A$对目标类型的直接概率分配为：
$$
m_A = \begin{bmatrix}m_A(a_1 \cup a_3) = 0.6 \\ m_A(\Theta) = 0.4 \end{bmatrix}
$$
这里：

-   $m_A(a_1 \cup a_3)$——表示识别到目标为$a_1$或$a_3$（类型1）的概率为$0.6$

-   $m_A(\Theta)$——对应传感器$A$在判断目标属于类型1时由于不知道的情况引起的不确定性概率为$0.4$

传感器$B$对目标类型的直接概率分配为：
$$
m_B = \begin{bmatrix}m_B(a_3 \cup a_4) = 0.7 \\ m_B(\Theta) = 0.3 \end{bmatrix}
$$

-   $m_B(a_3 \cup a_4)$——表示识别到目标为$a_3$或$a_4$（敌人）的概率为$0.7$

-   $m_B(\Theta)$——对应传感器$B$在判断目标属于敌人时由于不知道的情况引起的不确定性概率为$0.3$

使用$Dempster$融合规则时，首先形成一个矩阵，矩阵中的**每个元素是相应命题的概率分配值**，矩阵的**第一列和最后一行**就是要被融合的那些相应命题。如下表所示：

| 第一列 - 传感器$A$的相应命题（目标） | 中间元素的结果都是相应命题两两相并（相乘）的结果 |                          |                                            |
| ------------------------------------ | ------------------------------------------------ | ------------------------ | ------------------------------------------ |
| $m_A(\Theta) = 0.4$                  | $m(a_3 \cup a_4) = 0.28$                         | $m(\Theta) = 0.12$       |                                            |
| $m_A(a_1 \cup a_3) = 0.6$            | $m(a_3) = 0.42$                                  | $m(a_1 \cup a_3) = 0.18$ |                                            |
|                                      | $m_B(a_3 \cup a_4) = 0.7$                        | $m_B(\Theta) = 0.3$      | **最后一行 - 传感器$B$的相应命题（目标）** |

矩阵（行、列）所在的元素值是两个元素的乘积，这两个元素分别为第一列相同行的元素，以及与最后一行相同列的元素，与这个乘积值对应的命题则是被乘的这两个概率分配值所对应命题的交集。

在融合后的矩阵中，命题$a_3$所对应的概率分配值$m(a_3)$最高，**所以我们也常常把这类最高值作为来自传感器$A$和传感器$B$的证据融合输出结果。**

如果碰到交命题是空集的情况，那么该交命题所对应的概率分配值就应设为$0$，其他非空的交命题所对应的概率分配值应同乘以一个因子$K$，使得他们的和为1。即如果交命题$c$的概率分配值以下形式：
$$
m(c) = K \sum_{a_i \cap b_j = c}[m_A(a_i)m_B(b_j)]
$$
那么：
$$
K^{-1} = 1 - \sum_{a_i \cap b_j = \empty}[m_A(a_i)m_B(b_j)]
$$
这里$\empty$定义为空集。**如果$K^{-1}$为$0$，则说明$m_A$和$m_B$是完全矛盾的（即完全不相交），此时用$Dempster$规则来融合两个得到完全矛盾信息的传感器是不可能的。**

为了说明所有非空交命题是怎样被一个因子$K$线性放大的，假设传感器$B$能识别目标$2$和目标$4$,而不是上一个例子中的目标$3$和目标$4$，并且对应的概率分配值$m^`_B$假设为：
$$
m^`_B = \begin{bmatrix}m^`_B(a_2 \cup a_4) = 0.5 \\ m^`_B(\Theta) = 0.5 \end{bmatrix}
$$
同样运用$Dempster$规则，给出矩阵结果，我们发现$m_A(a_1\cup a_3)$和$m_B(a_2 \cup a_4)$相交为空$\empty$（两者矛盾），如果要将交命题的概率分配至设为$0$，应该找到一个因子$K$来重新分配非空集的概率分配值。

| $m_A(\Theta) = 0.4$       | $m_A(a_2 \cup a_4) = 0.20$ | $m(\Theta) = 0.20$       |
| ------------------------- | -------------------------- | ------------------------ |
| $m_A(a_1 \cup a_3) = 0.6$ | $m(\empty) = 0.30$         | $m(a_1 \cup a_3) = 0.30$ |
|                           | $m_B(a_2 \cup a_4) = 0.5$  | $m^`_B(\Theta) = 0.5$    |

同式$(50)$来计算$K^{-1}$，**即用$1$减去一些概率分配值的乘积和，这些概率分配值应使他们所对应的命题交集是空集**，在这个例子中，$K^{-1}$的值为：
$$
K^{-1} = 1- 0.30 = 0.70
$$
则$K$的值为：$\frac{1}{K^{-1}} = 1.429$

之后，我们将对应交命题为空集的概率分配至设为0，对应交命题为非空集的概率分配值都乘以一个因子$K$，使得他们的和为$1$.

| $m_A(\Theta) = 0.4$       | $m_A(a_2 \cup a_4) = 0.286$ | $m(\Theta) = 0.286$       |
| ------------------------- | --------------------------- | ------------------------- |
| $m_A(a_1 \cup a_3) = 0.6$ | 0                           | $m(a_1 \cup a_3) = 0.429$ |
|                           | $m_B(a_2 \cup a_4) = 0.5$   | $m^`_B(\Theta) = 0.5$     |

当有三个或更多个传感器信息需要融合时，可以再一次使用$Dempster$规则，方法是把枪两个传感器融合后的交命题及对应的概率分配值作为新矩阵的第一列，而第三个传感器的命题及对应的概率分配值作为新矩阵的最后一行（反过来也可行），然后用与前面讨论的类似方法进行融合。

### 5.5 $Dempster-Shafer$与贝叶斯判决理论的比较

**在$Dempster-Shafer$理论中，可以把表示不确定概念的概率直接分配给不知道事件，也就是能分配给识别框架$\Theta$里的任何命题。**从这一点来说，$Dempster-Shafer$理论比贝叶斯理论要来得更一般。而且，在$Dempster-Shafer$理论中，可以把传感器的分类错误直接分配给表示由不知道所引起的不确定的识别框架$\Theta$一定量的概率分配值来表示。在此理论中，还可以把概率分配值赋予识别框架中各命题的并命题。而在贝叶斯理论中，只能把概率分配给原始的子命题，这一点用数学公式表示就是：
$$
P(a+b) = P(a) + P(b)
$$
这是因为在贝叶斯理论中，$a$和$b$假设是互斥的，但在$Dempster-Shafer$理论中有：
$$
P(a+b) = P(a) + P(b) + P(a\cup b)
$$

>   $Shafer$曾经用一种更一般的说法描述了贝叶斯理论的局限性：“贝叶斯理论不能区分缺乏信任和不信任这两个概念，当我们对某一命题的反命题增加信任时，贝叶斯理论确不允许我们对原命题减少信任。”

**贝叶斯理论对不知道和不确定这两个概念没有方便的表示方法。**在使用贝叶斯理论时，我们必须知道或者假设好先验概率分布。贝叶斯**支持函数**把识别框架$\Theta$中的每个子命题对应的概率分配值都固定住，是他们没有自由移动的空间，也就是说没有了命题的不确定区间。要想使用贝叶斯支持函数，必须要想办法把支持度分配在**单个不能分割**的命题上，有些时候是比较容易做到这一点的，比如我们在玩掷均匀骰子游戏时的情形。如果我们知道骰子的点数是偶数，则我们可以把支持度平均分成3部分，即$2,4,6$上，但是如果骰子不是均匀的，此时贝叶斯理论就不能提供解了。

可以看到，贝叶斯理论的困难在于当我们不能知道想要的信息时，我们无法准确（定量）表示那些想要知道但是不确定的信息（或者说对于不确定的信息，我们不知道应该说是缺乏证据支持（缺乏信任）还是应该不信任），而对于这些不确定的信息，我们也不知道如何表示才不至于对他们进行不合理的过度使用。

在$Dempster-Shafer$理论中，我们利用传感器（知识源）的信息来为每个命题赋予一个**支持度**。比如在掷骰子的例子中，无论骰子是否均匀，$Dempster-Shafer$理论都能给掷偶数点的命题提供合适的概率分配值$m_k(i), i = 2,4,6$，并求出他们的支持度和似然度（不确定区间）。

因此，当我们想要的信息都能得到时，使用贝叶斯统计理论是没有任何困难的，但是当我们的知识不充分时，也就是说我们对识别框架里各命题的先验概率是由不知道的情况引起的不确定时，$Dempster-Shafer$理论提供了一种可以选择的方法。但是当每个命题的的不确定区间的宽度等于$0$时，并且概率不分配给子命题的交命题是，$Dempster-Shafer$理论就退化为贝叶斯理论了。

最新研究的广义证据处理（$GEP$）理论允许贝叶斯巨册推广到多个假设事件的组合这样的一个识别框架内，之所以能这样做，是因为该理论把假设事件（命题）从决策事件中分离出来。在$GEP$理论中，使用贝叶斯公式把术语多个不互斥的命题的证据结合起来，从而得到最后的决策。对来自多个传感器的证据使用$GEP$时，也可以用类似$Dempster-Shafer$理论中的融合规划把他们结合起来。

### 总结

$Dempster-Shafer$理论允许各传感器提供各自所能提供的信息来进行目标检测、分类和识别。**当识别框架里的命题信息不完整时，该理论通过把一部分概率跟配置赋予整个识别框架来解决问题，整个识别框架能表示由于不知道而引起的不确定，而整个识别框架里的命题表示传感器对其视野里的目标信息。如果有证据支持是把框架里有些命题的并情况，$Dempster-Shafer$理论特对其分配相应的概率分配值。**正是由于这两方面的原因是的$Dempster-Shafer$理论和贝叶斯理论有所区别，因**为贝叶斯理论不能表示由于不知道而引起的不确定性，而且贝叶斯理论只能把概率分配给识别框架里原始命题本身。**

可以用概率分配至来定义一个不确定区间，并用不确定区间来表示一个命题的支持度和似然度。**支持度是指该命题的传感器直接证据所对应概率分配至的和，而似然度机制支持该命题反命题的不是传感器直接证据所对应的概率分配至的和。**

## 6. 人工神经网络

>   对于人类来说，对模式进行识别主要是通过大量相互连接的神经元实现的。大量神经元之间的相互并行连接，使得人类对信息处理的过程表现为自适应性、上下内容相关性、容错性、大容量性以及实时性等。人类大脑处理信息的这些特性相对我们通常的信息处理方式，即串行、单处理器结果来说，提供了另一种可以选择的方式。虽然人类的每个神经元处理信息的速度相对来说比较慢($ms$级)，但是在人类大脑里对信息的整体的处理，通常只要几百$ms$就可以完成。人类大脑处理信息的这个速度显示了在生物计算中，以串行方式进行计算只占一部分，而大量存在的是每个串行记斯安中所包含的并行计算。**人工神经网络就是试图使用并行处理方式来模拟人类的感知能力。**下表比较了人工神经网络和传统的$Von \ Neumann$（冯-诺曼机）串行信息处理方式的不同之处。
>
>   ![image-20200929084124950](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1wwt3hyj318g0g6q92.jpg)

### 6.1 人工神经网络的应用

人工神经网络的应用主要包括：1⃣️在变化的环境下，对物体视觉图像、形状及位置的识别；2⃣️在声音的声调、语速及音量不同的条件下的语音识别；3⃣️在自适应控制方面的应用。这些应用主要涉及到**特征识别、图像处理以及匹配及搜索算法的直接和并行实现等内容。**

人工神经网络可以堪称是一种**可以学习的、黑箱性质的非传统算法类**的方法，这种方法比较适合于解决那些**不易定义**的问题，并且这些问题往往需要大量的**并行处理**。这些问题一般具有如下的特征：

-   属于高维问题
-   问题的变量间有复杂的相互关系
-   问题的解可能没有、可能惟一，也可能（大多数情况）有很多可用的解。

**而人工神经网络的计算方式有以下特征：**

-   两个简单元素或单元之间的**连接强度是可以变化**的；
-   基于**改变连接强度的学习算法**是训练集数据的函数；
-   通过**学习**，可以把信息存储在网络的内部结构中，这样网络对相似的模式就具有正确的分类能力，所以网络就表现为我们所想要的关联和推广能力；
-   网络是一个**动态**的系统，它的状态（如各单元的输出及各连接权值）随时间变化而变化，这主要是为了响应外部输入或初始的不稳定状态。

### 6.2 自适应线性组合器

几乎所有神经网络的基本组成部分都是如**下图**所示的自适应线性组合器。它的输出$s_k$是所有输入的**线性组合**。当离散实现时，给出在$k$时刻的输入信号矢量，或者称为输入模式矢量$X_k = [x_{0k},x_{1k},x_{2k},...,x_{nk}]^T$及相应的理想响应值$d_k$（假设用于训练的输入模式其对应理想响应是已知的）（这里$T$表示转置操作）。输入矢量的每个分量被一组称为权值矢量的系数$W_k = [w_{0k},w_{1k},w_{2k},...w_{nk}]^T$进行加权，**网络的输出即为输入矢量各分量的加权和**，可以记为**内积**的形式$s_k = X_k^TW_k$，**$X_k$的各分量可以是模拟量也可以是数字量，而各权值是连续可变的任意实数。**

![image-20200929092424120](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1wy457vj30xa0nq41a.jpg)

在自适应线性组合器训练过程中，将一定数量的输入模式$X_k$及相应的理想输出响应$p_k$送入组合器中，然后使用一种自适应算法**自动调整权值$W_k$**，使得各输入模式的相应尽可能地接近理想输出相应。在线性神经网络中我们通常采用简单的**最小均方误差$(LMS)$来调整权值**，该算法计算在训练模式集上的各线性误差$\epsilon_k$的和并且对其进行最小处理化。**这里线性误差$\epsilon_k$定在为在$k$时刻，理想相应$d_k$和线性输出$s_k$之间的差。**

### 6.3 线性分类器 - $Adaline$

>   到目前为止，不管是线性还是非线性的神经网络都得到了很大的发展。而非线性分类器可以对大量输入模式进行正确的分类，并且并不局限于各模式为线性可分的情形。对这类分类器的讨论将在本章的后面进行。

在许多人工神经网络中，有一种线性分类器被称为**自适应线性元件或简称$Adaline(Adaptive \ Liner \ element)$**，它最早是由$Widrow$和$Hoff$提出的。这种**自适应阈值逻辑装置是由一个线性自适应组合器，其后紧跟着一个硬限幅（非线性）二值量化器构成的**，其结构如下图所示（$Adalines$也可以没有这个非线性的二值量化器）。这个量化器的输出为$\pm1$，即$y_k = sgn(s_k)$，这里$sgn$表示符号函数$\frac{s_k}{|s_k|}$。**偏移阈值权$w_{0k}$**连接在一个常数输入$x_0 = \pm1$，以便控制量化器的阈值。

对$Adaline$的自适应算法也就是对其**权值**进行调整，以便对训练集上模式样本的分类达到尽可能多的正确，当然这里对输入模式的响应是**二值响应**。一旦权值调整结束后，就可以用不在训练集中的新的输入模式来测试训练后的$Adaline$。如果此时这个$Adaline$的响应有比较高的正确率，那么就可以说这个网络有比较好的推广能力。

![image-20200929095803159](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1x16ktqj30wy0mitcc.jpg)

### 6.4 线性分类器的容量

一个$Adaline$能够正确分类的具有任意随机理想二值响应的**平均模式数**大约等于其权值数的两倍。这个数值被称为$Adaline$的统计模式容量$C_s$。**一个训练集是线性可分的概率（训练集能被$Adaline$正确分类的概率）是该训练集中的输入模式数$N_p$及包括偏移权在内的权值数$N_w$的函数。**下图显示了线性可分概率与$N_p$和$N_w$的比$\frac{N_p}{N_w}$在$N_w$取几个离散值时的关系曲线。可以证明随着权值数的增加，$Adaline$的统计模式容量$C_s = 2N_w$将成为学习的响应数量的精确估值。

![image-20200929102319476](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1x8vvxaj30qe0kstbh.jpg)

上图也显示了如果训练集中的模式数等于或少于统计模式容量的一半时，即如果训练集中的模式等于或少于权值数时$N_p \leq N_w$或$\frac{N_p}{N_c}\leq 1$，就能保证对训练集中的模式进行分类的问题一定有一个解，这个**模式数**被称为$Adaline$的**确定模式容量$C_d$**。

这些统计容量的结论是在训练模式是随机选择的情况下得出的，但事实上，大多数实际我们感兴趣问题的训练集中的模式不是随机抽取的，**他们表现出某一统计规律，所以学习到的统计模式数要远大于理论统计容量。正是由于样本服从某一统计规律，才使得网络的推广能力成为可能，也就增加了网络学习到的模式容量，即在对训练集的所有样本训练结束之前，$Adaline$网就已经学习到了训练集中的很多模式样本。**

### 6.5 非线性分类器 - $Madaline$

非线性分类器具有更大的容量及更高的模式分类能力，它能分开具有非线性边界的各模式类。下面要讨论两种类型的非线性分类器，他们是多层自适应线性元件$(Madaline)$以及多层前向神经网络。

#### 6.5.1 $Madaline$

$Madaline$最初应用于分析视网膜刺激反应。该网络把输入矢量连接到一个自适应的$Adalines$层，然后把各$Adalines$的输出连接到一个固定逻辑装置中产生输出。下图显示了一个使用了两个$Adalines$，且把它们的输出连到一个$AND$阈值逻辑输出装置的$Madaline$网络结构。

![image-20200929105021688](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1xgwaw4j30v40l2goe.jpg)

$Madalines$的其他类型可能具有更多的输入，第一层中具有更多的$Adalines$以及在第二层中具有不同的逻辑装置。尽管在原始的$Madalines$自适应元件中使用硬限幅符号量化器（符号函数），但是其他非线性神经网络，包括在本章以后要讨论的$BP$网络，都可以使用可微的非线性函数，比如$sigmoid$（软限幅）函数（及下图中的$S$形函数）。

<img src="/Users/RunshengWU/SensorFusion/Images/functionModel.png" alt="image-20200929110023952" style="zoom: 33%;" />

符号函数输入-输出之间的关系为：
$$
y_k = sgn(s_k) \ \ \ \ \ sgn(s_k) = \frac{s_k}{|s_k|}
$$
$s_k$和$y_k$分别为网络的**线性输出**和**二值输出**。

对于$sigmoid$函数，其输入-输出关系为：
$$
y_k = sgm(s_k)
$$
**一个典型的$sigmoid$函数就是双曲正切函数**，即：
$$
y_k= tang(s_k) = \frac{(1-e^{-2s_k})}{(1+e^{-2s_k})} \ \ s_k = X_k^TW_k
$$
其实，应用于神经网络的$sigmoid$函数可以推广到任何光滑的非线性函数，他们都可以与线性自适应元件相连。

下图显示了三种阈值逻辑输出函数，即$AND,OR,MAJORITY$表决。在图中权值一旦确定就实现了这三个函数，但这些权值的曲直却并不是惟一的。

![image-20200929110422655](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1xnff0dj31700ku41p.jpg)

#### 6.5.2 前向网络

**典型的前向网络具有很多层，每一层都具有自适应性，**下图显示了一个全连接的、三层前向网络。在这个例子中，用$Adalines$来表示人工神经元处理元件，它把各输入连接到一个求和节点，而各输入又被各可调的权值进行作用。求和节点的输出又传递给硬或软的限幅器。在一个全连接的网络中，处于某一层的每个处理元件接受来自上一层所有处理元件的输出。在训练阶段，我们希望网络每个元件的实际输出与以其对应的理想输出做比较。对和输出层相联系的元件的误差可以很容易地计算出来，然后就可以考虑使用直接自适应方法来训练最后输出层，但是对应隐层处理元件误差的获取，也就是对不是最后输出层元件误差的获取，需要更复杂的学习算法，比如$BP$后向算法。

![image-20200929115013869](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1xuqblvj31480j2wla.jpg)

通常，前向网络的各处理元件具有层次的结构形式。各处理元件被组织成两层或更多层的形式，而每层之间的元件不互相连接。

输入层元件的作用是接受作用在网络上的输入值，**这些元件并没有实现对输入数据的映射，和他们相连的权值也不是很重要**；

最后一层，即输出层，能解读网络的最后状态，**产生用户能读懂的输出结果**。

在这两个极端层的中间可能没有也可能有中间隐层元件的存在。**中间隐层能够把输入或者是上一层的输出在一次进行映射，从而产生更容易分离或更容易分类的数据。**

在上图所示的体系结构中，**连接每个处理元件的权值仅仅在本层和它上一层之间的元件之间进行。**这意味着在各层的处理元件之间存在着一种方向性，即某一个处理元件的输出，被权值作用后，作为下一层处理元件的一部分集里输入。前向网络的形式，除了上图的结构之外，还发展了其他形式，如有一种形式的前向网络，它的各处理元件直接接受每个输入部分的值及来自前面每个处理元件的输出值。

### 6.6 非线性分类器的容量

$Madaline$网络能学习到的正确分类的平均随机模式数（这些模式当然对应随机的二值响应）等于每个$Adaline$，即**每个处理元件的容量乘以网络所拥有的$Adaline$数，**因此，$Madaline$的随机统计容量$C_s$大约等于自适应权值数的两倍。尽管$Madaline$和$Adaline$平均每个自适应权值所对应的容量相同，但是$Madaline$却能分开具有非线性边界的训练集。

**具有任意层的前向$signum$网络的容量依赖于权值数$N_w$和输出数$N_y$**。对一个具有$N_x$个输入分量（包括偏移输入）和$N_y$各输出分量，两隐层且全连接的前向$signum \ Adamines$网络来说，当要求网络能将任何$N_p$个处于==一般位置==的输入模式映射到具有$N_y$个输出分量的任意理想二值矢量上时，**最小权值数$N_w$应满足以下不等式：**
$$
\frac{N_yN_p}{1+\log_2N_p} \leq N_w \leq N_y(\frac{N_p}{N_x}+1)(N_x+N_y+1)+N_y
$$

>   对于不包含阈值权的$Adaline$来说，模式处于**一般位置**是指，包含不超过$N_x$个元素的模式矢量集的任何子集都是一个线性可分的集合。也可以这样说，模式处于一般位置是指，在$N_w$-维空间中不存在一个具有$N_w$个点或者更多点的集合处于同一超平面内。对于包含阈值权的$Adaline$来说，模式处于一般位置是指，在$N_w-1$-维空间中不存在一个具有$N_w$个点或更多点的集合处于同一个不经过原点的超平面内。

以前在线性分类器中提到的**统计容量和确定容量其实也依赖于输入模式的一般位置**。如果模式不处于一般位置，理论分析得到的容量是实际能得到的容量的一个上界（最大值）。

对于两层前向$signum$网络，**当输入分量数$N_x$和隐层处理元件数的和是输出分量数的至少5倍时，网络的确定模式容量少为低于$N_w/N_y$这个界。当任何前向网络的权值数与输出分量的比很大时（至少是好几千），网络确定模式容量稍微高于$N_w/N_ylog_2(N_w/N_y)$这个界。**因此，两层网络的确定模式容量$C_d$的界为：
$$
\frac{N_w}{N_y} - K_1 \leq C_d \leq \frac{N_w}{N_y}log_2(\frac{N_w}{N_y}) + K_2
$$


如果网络的输出分量数与输入分量数和隐层元件数的和相比比较小时，式(6-6)中的$K_1$和$K_2$都是比较小的正数。式（6-6）也是两层$signum$（硬限幅）网络统计模式容量的界。

对于估计网络的模式容量，有几点简明而有用的规则：

-   用单层网络的容量作为多层网络容量的估计
-   $sigmoid$（软限幅）网络的容量**不会低于**同等规模的$signum$（硬限幅）网络的容量；
-   为了得到更好的推广能力，**即对没有在训练集上出现的模式也能正确分类，要求训练集中的模式数目应该是该网络容量的若干倍**，如$N_p \geq N_w/N_y$.

对于一个前向网络要找出一个最优层的隐层元件数会涉及到问题的很多方面，对这个问题的解决我们主要**采用工程的判断方法**。尽管从直觉上说越多的隐层元件数将会带来更好的推广能力，但是过多的隐层元件数反而可能在其他方面带来更坏的结果。下图就说明了如果隐层元件过多带来的问题。

![image-20200929144915395](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1y05mzlj30ye0jumz4.jpg)

从上图可以看出，输出决策的精度很快接近于一个极限值。对于某个具体问题，当隐层元件数低于某一值时，随着隐层元件数的增加，训练时间很快下降。但当隐层元件数超过某一值时，再增加隐层元件数反而会使得训练时间快速上升，而输出决策的精度却增长得很缓慢。**上图所示的那些特殊值虽然不是普遍结果，但是这个结果并不是只适用于某个特性的神经网络。**

### 6.7 有监督和无监督学习 Supervised | No supervised learning

有监督和无监督学习算法最初来源于模式识别理论。有监督学习使用**模式所属类**的信息，而无监督学习没有这些可用的信息。学习算法就是要准确地估计$p(X)$，**$p(X)$就是在模式空间中描述模式连续分布的概率密度函数。**有监督的学习算法提供有关$p(X)$的部分**先验信息**，但可能并不准确，但无监督学习算法对$p(X)$不作任何假设，它使用的是**最小信息量**。

-   有监督学习算法依赖于每个训练样本$x$所属哪类的信息。样本所属类别信息能够使有监督学习算法发现模式的误分类，并且计算信号或矢量的误差，然后通过计算出来的误差改善学习过程。
-   无监督学习算法使用没有标记的样本来“盲目”地处理。无监督学习算法比起有监督学习算法通常具有较小的计算复杂度和较低的精度。对问题中所能提供的时间、信息有限且计算精度的要求不是很高。

有监督学习算法主要包括**最快速下降法**和**误差修正法**，他们分别要对**未知均方误差及其梯度**进行计算或估计。而未知均方误差依赖于未知的概率密度函数$p(X)$。

对于无监督学习已经提出好几种算法，他们可以自适应地形成**模式聚类**或者**决策类**，这些类可以用所聚集的模式中心来描述。除此之外，其他类型的神经网络可以在模式空间中形成吸引子，各吸引子对应着不同的模式类别，这些吸引子可以由他们的宽度，所在的位置和吸引样本的数目来加以描述。

### 6.8 有监督学习规则

下图显示了由$Widrow$和$Lehr$总结的对使用自适应线性元件的人工神经网络进行训练所采用的有监督算法的分类情况。训练规则首先分成了最快速下降法和误差修正法这两类，然后按照多层网络和单层网络再进行分类，最后按照非线性激励和线性激励进行分类。

![image-20200929151632779](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1y1indbj30xg0im77h.jpg)

-   **最快速下降法或梯度法**在每次训练模式样本输入时通过改变**网络的权值**来**减小训练样本的均方误差$(MSE)$。**尽管还可以使用机遇其他梯度的算法，但是基于$MSE$梯度的算法仍然是最流行的。
-   **误差修正法**是通过改变**网络权值**来保证前后两次对同一训练模式所对应的输出误差下降指定的程度。

这两种训练法使用类似的训练步骤。然而，因为他们基于的目标不一样，所以他们具有明显不同的学习特性。**误差修正法通常用于训练的误差函数不容易定量化或者适用于不容易定量分析的问题。**

#### 6.8.1 $\mu-LMS$最快速下降算法 -> 单层网络（线性）

 $\mu-LMS$最快速下降法能估计出位于权值空间的$MSE$曲面在当前各权值点处形成的最快速下降方向。因为这个误差曲面是各权值的二次函数，所以它的形状是凸的，因此有惟一的极小点。最快速下降法通过计算或估计网络实际输出和理想输出的误差来调整各权值。权值的调整量正比于梯度值，但与梯度的方向相反，而**梯度是由该误差曲面对各权值求偏倒而形成的矢量。**

权值更新的数学表达式为：
$$
W_{k+1} = W_k + 2\mu\epsilon_kX_k
$$
我们可以通过**学习常数$\mu$**来控制算法的稳定性和收敛速度。如果$\mu$太小，$\mu-LMS$算法向均方误差曲面最低点移动速度会太慢，因此算法的收敛速度可能慢得进人，如果$\mu$太大，算法可能“不计后果地跳”向均方误差的曲面最低点，从而导致算法不收敛，在这种情况下，权值矢量可能会随机地使均方误差忽大忽小。

**学习常数的取值应该和系统的不确定性成反比**，即采样和训练的环境越不确定，学习常数$\mu$应越小以避免训练过程的发散，繁殖采样和训练的环境越稳定，可以适当选择大的学习常数以加快训练的收敛速度。

如果**输入模式独立于时间**，那么当$\mu$满足如下不等式时，权值矢量的均值和方法将收敛：
$$
0 < \mu < \frac{1}{trace[R_k]}
$$
这里，$trace[R_k]$表示$R_k$的迹，它等于矩阵$R_k$对角线上的元素和，这个值也等于$X_k$矢量的平均功率即$E[X_k^TX_k]$。同时$R_k$也可以看成输入矢量$X_k$在输入各模式独立时的自相关矩阵。

#### 6.8.2 $\alpha-LMS$误差修正算法 -> 单层网络（线性）

**对于某个固定训练样本来说，$\alpha-LMS$算法能迭代求出网络的各权值，使前后两次迭代的误差（网络实际输出和理想响应输出之间的差）的变化，被一因子$\alpha$所控制。**该算法的权矢量按如下形式进行更新：
$$
W_{k+1} = W_k + \alpha\epsilon_k\frac{X_k}{|X_k|^2}
$$
此时误差的下降幅度为：
$$
\Delta\epsilon_k = -\alpha\epsilon_k
$$
**这里的负号表示误差改变方向和误差本身的方向是相反的**。该算法的稳定性和收敛速度由$\alpha$的值来控制。当输入模式矢量在时间上独立，并且当$0<\alpha<2$时，对大多数实际问题，其稳定性是能保证的。当$\alpha > 1$时，说明对误差过分进行修正；而当$\alpha =1$时，说明对误差进行全修正。通常在实际应用中，$\alpha$的值在$0.1$和$1$之间进行选择。当所有的输入模式长度相等时，$\alpha-LMS$算法也就极小化了均方误差，而此时的许多性质我们大家都是很熟悉的。

#### 6.8.3 $\mu-LMS$算法和$\alpha-LMS$算法的比较

不管是$\mu-LMS$算法还是$\alpha-LMS$算法的实现都依赖于**均方误差的瞬时梯度**。在$\alpha-LMS$算法中对样本模式进行了归一化，并且在美不迭代中都对误差进行了确定量的修正（对应着$\alpha$这个因子），而$\mu-LMS$算法属于一种常系数线性算法（$\mu$一旦确定就不会变），这种算法比较容易分析。$\alpha-LMS$算法类似于学习常数连续可变的$\mu-LMS$算法。尽管$\alpha-LMS$算法在实现和分析两方面的难度比较大，但实验表明，当输入模式的自相关函数矩阵$R$的各特征值差异很大时，$\alpha-LMS$算法的性能要比$\mu-LMS$算法的性能好。在这种情况下，估计的梯度值和真实的梯度值之间往往有差异，这种差异会传播到权值的估计上，我们称之为“梯度噪声”。但在同样的“梯度噪声”条件下，$\alpha-LMS$算法往往表现出更好的收敛速度。$\mu-LMS$算法的优点是该算法在均值意义上一定收敛于求$MSE$最小值的最优解，但由$\alpha-LMS$算法所提供的解可能有偏差。

#### 6.8.4 $Madaline\ I$和$II$误差修正法 - 多层网络（非线性）

$Madaline \ I $误差修正训练算法适用于两层的$Madaline$网络。网络的第一层包含了一些由符号函数构成硬限幅的$Adaline$元件，这些元件的输出连接到第二层，而第二层只由一个固定的逻辑元件构成，该逻辑元件可能是$AND$或$OR$或$MAJORITY$。$Adalines$的初始权值被设置为一些小的随机数。**$Madaline \ I$规则通过调整第一层的权值使得逻辑元件的输出与训练模式的理想响应达到一致。在调整权值过程中我们只需调整必要的$Adalines$元件的权值来修正输出决策的误差。我们首先选择对应元件的线性输出最接近零的权值进行调整，因为我们只需对这些权值作最小的改变就有可能使系统的输出和原来相反。**不管是对哪个$Adaline$的权值进行调整，权值的变化方向总是和输入矢量的方向一样，因为这样就能保证用最小的权值变化来达到误差修正的目的。

$Madaline \ II$误差修正训练算法适用于**使用$signum$（硬限幅）阈值的多层二值网络**。训练过程类似于$Madaline \ I$算法。各初始权值同样被设置成一些小的随机数。训练模式按照随机顺序依次进行训练。**如果网络在训练中产生误差，那么首先调整在第一层中产生最小线性输出的$Adaline$的权值，使它的输出和原来的相反。**如果作这样的调整后，训练模式的输出错误数能有所减少的话，那么刚才的那个权值可以采用$\alpha-LMS$误差修正算法来改变原来的权值，这种方法可以做到对权值的改变最小，同时能更进一步使对应的输出和原来的相反。如果作这样的调整后，训练模式的输出错误数不能有所减少的话，那么该$Adaline$所对应的权将不作任何变化。当对第一个$Adaline$元件作如此处理后，再调整其他产生足够小的线性输出的$Adalines$所对应的权。当第一层可能要调整的权调整完后，再来调整第二层的权，等等。当达到最后一层，且所有该调整的权都使用$\alpha-LMS$算法调整完毕后，再从训练模式中挑选另一个新的模式进行同样步骤的训练。

#### 6.8.5 感知器规则 - 单层网络（非线性）（不流行）

在有些情况下，使用$\alpha-LMS$算法可能不能对训练集中线性可分的样本进行正确分类。在这种情况喜爱，非线性规则如$Rosenblatt$的$\alpha$-感知器规则可能更为适用。

下图所示的**感知器是只有一个输出神经元的前向网络，**该网络可以在模式空间中学习到某个分类超平面。网络的第一层是各固定阈值逻辑装置。这些装置用来随机且稀疏连接各输入模式。第一层的输出连接到第二层中，第二层是由单个的自适应线性阈值元件神经元构成，这个自适应元件类似于$Adaline$，但有两个方面不同，一是它的输入信号只能是二值$[0，1]$，二是没有使用偏移权。

<img src="/Users/RunshengWU/SensorFusion/Images/preceptionRule.png" alt="image-20200929174207696" style="zoom:50%;" />

感知器的自适应阈值元件如下图所示。当输出决策$y_k$与理想二值响应$d_k$不一致时，如果误差是正数，则自适应阈值元件权值的调整为本身值加上输入矢量值，如果误差是负数，则自适应阈值元件权值的调整为本身减去输入矢量值，如果误差是负数，则自适应阈值元件权值的调整为本身值减去输入矢量值。图中误差$\widetilde{\epsilon_k}$为：
$$
\widetilde{\epsilon_k} = d_k-y_k
$$
感知器规则与$\alpha-LMS$算法几乎一样，但是感知器规则只使用误差的一般，即$\widetilde{\epsilon_k}/2$，而在$\alpha-LMS$算法中使用归一化的线性误差$\epsilon_k/|x_k|^2$。所以，感知器规则给出的权值矢量更新方程位：
$$
W_{k+1} = w_k + \alpha(\widetilde{\epsilon_k}/2)X_k
$$
通常$alpha$的值设为$1$。**和$\alpha-LMS$算法不同的是，这里的$\alpha$值不影响感知器规则的稳定性**。只有当初始权值为非零时，$\alpha$的值影响会其收敛时间。**$\alpha-LMS$算法既适用于模拟理想响应，也适用于二值理想响应，但感知器规则只能使用于二值理想响应。**尽管这种感知器规则早在20世纪50年代就已经提出来了，但是却没有被广泛应用，原因就在于其分类能力依赖于线性可分模式的训练，并且，对多层的情况也不存在一个对应的训练算法。多层前向网络后向传播算法正好能弥补这方面的缺陷。

<img src="/Users/RunshengWU/SensorFusion/Images/preceptionRule02.png" alt="image-20200929175954515" style="zoom: 50%;" />

#### 6.8.6 后向传播（$BP$）算法 - 一层｜多层非线性网络

$BP$算法是一种用来训练一层或**多层非线性网络**的随机最快速度下降法。该算法由于给出了计算隐层神经元权值的方法，所以它克服了感知规则的很多局限。算法之所以成为随机最快速下降，其随机性主要体现在**搜索的对象是随机一个最小均方误差曲面的极小点**，而不是确定某个均方误差的极小点。因此，如果我们对网络的初始值选择不合适的话，$BP$算法可能收敛于一个局部极小点或者根本不收敛。当所有神经元都是线性的且前向网络的输入和输出之间没有隐层神经元时，$BP$算法就退化为 $\mu-LMS$算法。

如果用生物语言表述的话，$BP$算法就是递归地修改各神经场之间（也就是输入、隐层和输出之间）突触的强度。该算法反向地首先修改输出层和倒数第二层即内部隐层之间的权值，然后算法利用这时已经得到的信息去修改倒数第二层和它前一层之间的权值，依次类推，一直到输入层和第一隐层之间的权值被修改为止。

训练时首先向网络输入一个训练模式矢量$X$，这个$X$**前向**扫过整个网络得到各隐层的输出和最后网络的输出$Y$，然后根据理想输出响应计算网络的误差，最后用这个误差反向扫过整个网络来修正各权值。在误差反向扫过网络的过程中要完成三件事：1⃣️在网络每一层的元件中**求取误差对其输入的导数$\delta$**；2⃣️通过上面定义的导数$\delta$求取误差对对应权值的梯度；3⃣️利用求得的梯度值对每一层元件的权值进行更新。当这个样本训练完后，使用同样的步骤再输入一个新的样本，开始新一轮的训练。

对该网络的训练一直持续到使用完训练集中所有的训练样本。$BP$算法的目的并不是为了减少网络每一层的输出误差，而是为了减少网络最后输出的**误差**（网络最后输出层各理想输出分量和实际输出分量之差的平方和）。

$BP$算法是一种迭代算法，所以通常首先要为各权值设置一个小的随机数作为初始值。多层前向网络对初始值的选择非常敏感，如果初始权值中有零或选择不恰当的话，算法就不能正常执行。事实上，网络有可能无法学习到整个训练集样本，这种情况下就应该重新设置网络的初始权值，然后重新开始学习。网络的收敛速度受学习常数$\alpha$的影响，这个常数在权值更新方程中会出现。当学习处在"平坦"的极小点附近时，此时由于梯度值很小，可以使用大的学习常数以取得快的收敛速度。当学习处于“陡峭”处或“狭窄”的极小点附近时，选择小的学习常数可以避免解的振荡。

所以，学习常数的徐安娥应根据推情况实验性地选择。学习常数被选为$10^{-3}～10$之间的情况在文献中都有报告。大的学习常数可以很明显地加快学习速度，但是它的解在最小误差附近可能由于出现震荡而变得不稳定。

在$BP$算法中，误差后向扫过整个网络来调整权值的计算复杂度和输入前向扫过整个网络的计算复杂度**大致相当**，**该算法对最后输出层权值更新的数学表达式和对中间隐层权值的更新的数学表达式并不一样。**

#### 6.8.7 $Madaline\ III$最快速下降法（非线性）

$Madaline \ III$最快速下降法适用于使用$sigmoid $（软限幅）的$Adalines$。该算法能避免在$BP$算法中因$sigmoid$函数和其导数的不精确实现而造成的一些问题。$Madaline \ III$规则类似于$Madaline \ II$规则。在$Madaline \ III$规则中，所有$Adamines$的权值都要调整，但是输出模拟值最接近零的$Adaline$权值调整的幅度最大（因为$sigmoid$函数在零点处的斜率最大，因此对地图的贡献也最大）。和$Madaline \ II$规则一样，**$Madaline \ III$规则的目的就是通过改变权值，使对给定的某个输入模式来说，在网络的输出端各分量的误差平方和最小。**各$Adalines$元件的权值矢量根据他们对减小最后输出误差的能力来调整他们的**权值**，调整方向当然是$LMS$方向。权值矢量的调整量正比于一个小的摄动信号$\Delta s$,这个信号被用来和权值矢量的线性输出和$s_k$相加，然后再来考察由此引出的网络输出$y_k$和误差$\widetilde{\epsilon_k}$的变化情况。

瞬时梯度的计算有两种方法，从而导致了$Madaline \ III$算法的权值更新方程有两种形式，他们是：
$$
W_{k-1} = W_k-\mu[\frac{\Delta(\widetilde{\epsilon_k})^2}{\Delta s}]X_k
$$

$$
W_{k-1} = W_k-2\mu\widetilde{\epsilon_k}[\frac{\Delta(\widetilde{\epsilon_k})^2}{\Delta s}]X_k
$$

这里学习常数$\mu$类似于在$\mu-LMS$算法中用过的学习常数$\mu$。当摄动常数$\Delta s$非常小时，这两种更新方法时等价的。

#### 6.6.8 死区算法 - 非线性单层网络

$Mays$提出了两种在训练过程中引入死区的算法。他们分别是**增强的适应算法和修改的松弛适应算法**。增强的适应算法在线性输出$s_k$中引入死区，死区的位置为零附近的$\pm{\gamma}$范围内，死区的存在减少了权值误差的敏感性。**如果网络的线性输出在死区范围之外，则权值的更新遵从感知规则的一个变体：**
$$
W_{k-1} = W_k+\alpha\widetilde{\epsilon_k}[\frac{X_k}{2|X_k|^2}], 如果 |s_k| \geq \gamma
$$
如果网络的线性输出位于死区范围之内，则权值的更新遵从感知规则的另一个变体：
$$
W_{k-1} = W_k+\alpha{d_k}[\frac{X_k}{|X_k|^2}], 如果 |s_k| < \gamma
$$
这里$\widetilde{\epsilon_k}$由式（$64$）给出，$d_k$为训练模式对应的理想响应。

$Mays$证明了**如果训练模式集是线性可分的，则增强的适应算法始终是收敛的，并且能在有限步内完成对训练模式集的正确分类。**如果训练模式集不是线性可分的，增强的适应算法的性能也要比感知规则好。这是因为如果权值矢量存在性能优越的解时，充分大的死区能保证权值矢量在调整时离开零值。

修改的松弛自适应算法主要使用$\epsilon_k$来更新权值。对于$\epsilon_k$，在$\alpha-LMS$算法中已经定义过。修改的松弛适应算法与$alpha-LMS$算法的不同之处就是前者引入死区。如果输出$y_k$的二值量化时正确的，并且线性输出$s_k$位于死区$\pm\gamma$之外，权值不作更新。在这种情况下，有：
$$
W_{k+1} = W_k, 如果\epsilon_k = 0 且 |s_k| \geq \gamma
$$
如果输出$y_k$的二值量化时错误的，后者如果线性输出$s_k$落在死区$\pm\gamma$之内，权值的更新将遵从$\alpha-LMS$算法的规则：
$$
W_{k+1} = W_k + \alpha\epsilon_k\frac{X_k}{|X_k|^2}
$$

### 6.9 其他人工神经网络

除了前面介绍的自适应线性元件$Adaline$、多层自适应线性元件$Madaline$、感知和由自适应线性元件构成的多层前向网络外，还有很多其他形式的人工神经网络，如多层感知器、$Kohonen$自组织网络、$Grossberg$自适应谐振网络、反向传播网络以及$Hopfield$网络等、**其中$Kohonen$自组织网络，$Grossberg$自适应谐振网络和反向传播网络使用非监督学习算法。**这些网络的特点总结于下表

![image-20201001141524548](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1y3l1i4j315a0tc47z.jpg)

![image-20201001141550391](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1y8ei2wj30u01007mc.jpg)

### 总结

人工神经网络通常同来解决一些**输入变量之间有复杂相互关系**的问题，它的应用领域包括**目标分类、语音合成、语音识别、模式映射和识别、数据压缩、数据关联、视觉特征识别和系统优化等。**

**自适应线性组合是线性和非线性人工神经网路的基本组成部分。**非线性分类器相比于线性分类器具有更好的对大量输入模式的分类能力。

线性分类器的统计容量，即线性分类器能够学习到的分类随机模式样本数，大致等于该网络处理元件数的两倍。非线性$Madaline$网络的统计容量也大致等于该网络处理元件权值数的两倍。然而由于$Mdaline$包含不止一个处理元件，因此，它的分类能力要比线性分类器的分类能力大。

对于更复杂的非线性分类器的分类能力，如**多层前向网络**、他的容量的界在本章进行了大致的估计。

本章还讨论了对单处理元件和多层线性和非线性网络的学习规则及算法。对于有监督学习算法，调整权值时为了最小化对某一训练样本的训练误差，训练误差定义为理想响应与网络的实际输出之差($d_k - s_k$)。

线性分类器的学习算法包括$\mu-LMS$算法和$\alpha-LMS$算法等。非线性分类器的学习算法包括感知器规则、$BP$算法、$Madaline$规则及死区算法等，**其中$BP$算法不仅能求出输出层权值的最优解，还能求出隐层权值的最优解。**

本章还简单介绍了多层感知器、$Kohonen$自组织网络、$Grossberg$自适应谐振网络、反向传播网络以及$Hopfield$网络等的学习算法和应用、其中$Kohonen$自组织网络，$Grossberg$自适应谐振网络和反向传播网络是使用非监督学习算法的是三个例子，非监督学习是基于**没有理想输出标志训练样本**的学习算法。这些网络能自适应地把相似模式聚集在一起，从而形成最后一个个**决策类。**

## 7. 表决融合

基于传感器输出结果的融合结构分为三类，即串联融合、并联融合和串并联混合结构，三种融合结构各有自己的优缺点。如下图所示。

![image-20201009093743515](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1y9v359j310m0ruah3.jpg)

-   **并联结构的融合形式可以在信号被抑制的情况下获得更好的检测率。**因为在这种融合结构下，只需多个传感器中的一个传感器把目标检测出来即可认为**目标存在。**
-   **当多个传感器对目标不同的物理属性产生不同的响应时，可以考虑采用串联融合结构**，因为该结构能表现出比较好的克服传感器虚警的能力。

>   但当这种融合结构的优点不适应其所在的环境时，它们的缺陷也是显而易见的。并联融合结构很容易导致检测的虚警，即对假目标比较敏感，因为在并联融合结构中有可能有某个传感器对来自某一非目标的信号很敏感。
>
>   而串联融合结构却需要所有探测目标的传感器都要产生输出信号。因此当一个或多个我们所期望的信号丢失或比较弱的时候，例如，当来自目标的信息被抑制时，串联融合结构的性能就比较差。

串、并联融合结构中可以用**表决融合**的方法进行信息融合，该方法结合了串、并联融合结构的优点。包括：

-   能排斥来自虚假目标的信号、密集杂波信号或非目标信号的干扰
-   当目标的某一或某些特征被抑制时，也能检测出该目标

**表决融合是基于特征推理进行融合并对目标进行分类的技术之一，允许传感器利用外部先验知识自动对目标进行检测和分类。**这个过程不需要根据各传感器输入到融合中心信号的精确度来进行传感器之间的切换，也不需要实时了解传感器所在的环境特征。在表决融合结构中，各传感器的输出始终与一个融合逻辑相连，而该融合逻辑器事先结合了各传感器的先验知识。在融合过程中有时还需要增加一个辅助决策单元，以便在一些事先能辨别的特殊环境下来优化这个传感器系统的运行性能。虽然表决融合结构也能胜任这些环境，但通过测试和仿真系统的性能来确定是否需要增加这个辅助单元也是必要的，以便满足整个系统所要求的性能指标。

本章以三个传感器组成的多传感器检测系统为例来说明表决融合的过程。在这个系统中，检测单元应包括2～3传感器。为了避免出现并行融合结构的缺点，在此不考虑只有单个传感器组成的检测单元的情况，并且假定所有传感器首先进行传感器级数据处理，然后把处理完的传感器数据以目标报表的形式传到融合中心，这些报表中通常一下内容：目标检测和分类决策信息，目标检测，分类所对应的信任级别以及目标的位置信息等内容。

通常情况下，一种融合算法需要结合各传感器传送过来的数据来评估潜在目标的身份、航迹及其当前的威胁程度等。本章仅讨论表决融合算法在目标分类上的应用。表决融合算法基于布尔代数，给出了在多传感器系统中对目标的检测率以及虚警率的解析表达式。

为了得到各传感器的信任级别与该传感器的检测率、虚警率的关系，必须实现充分了解传感器输入信号的特性（如频谱分布、带宽及最小可检测的信号等）以及已知目标的特征信息，这些通过信号处理算法获取的目标特征信息与已知目标的特征进行比较，可以对未知目标进行分类。

### 7.1. 传感器目标报表

**在传感器目标报表中，包括了对目标的检测信息。**这些信息反映了传感器输入信号与已知目标特征的相似程度，也就是反映我们感兴趣的物体或目标被检测到的**“信任”程度**。这些特征量与**目标的尺寸、传感器工作类型（主动｜被动）以及传感器的设计**等有关。这里提到的传感器的设计不仅指传感器采用何种信号处理方式，而且还只**传感器的中心频率、分辨率等其他参数（空间分辨率、发送及接收的频率、频率稳定性、极化情况、发射波形、发射功率、扫描机制、噪声、灵敏度、带宽、工作范围、数据配准）**。当信号在时间域里处理时，可以采用信号的**幅值、脉宽（峰值持续时间｜宽度）**以及**幅宽比**等时间域特征量；当信号在频率域处理时，则可以采用**频峰之间的分裂情况**、**特定频段的宽度**以及**散射中心的数量**等频率域特征量。

**这里把散射中心也作为特征量来提出是因为多个散射中心的叠加能产生超过某一自适应阈值的信号，从而影响对目标的检测。**多像素红外仪或FLIR （前视红外）传感器得到的图像通常采用判别函数的方法来识别目标，判别函数使用如下一些特征量：图像区域内超过一定阈值的像素点占原图总像素点的百分比、图像的长宽比、图像的中心运动以及物体边沿的温度梯度等。传感器目标报表中还可以包含目标的位置信息。当然这里的目标指广义的目标，包括可以识别的假目标、干扰信号以及任何在现有传感器软硬件设计限制范围内能被确认的感兴趣的物体。

### 7.2. 传感器的检测空间（分类空间）

多传感器系统检测概率融合了多个传感器检测的结果。每个传感器的检测结果反映了单个传感器输入信号与假定目标之间特征量匹配的数目及程度。**多个传感器检测结果的融合就形成了整个检测空间。**最后融合输出的结果取决于传感器的数目、分辨率、每个传感器所采用的算法以及各传感器输出融合的结构等。

#### 7.2.1. 检测空间的文氏图表示

下图用文氏图表示了一个由三个传感器$A，  B，  C$所组成的多传感器系统的检测空间（分类空间）。图中分别标出了单个传感器、两个传感器及三个传感器的输出结果融合的区域。

<img src="/Users/RunshengWU/SensorFusion/Images/wenshitu.png" alt="image-20201009132059497" style="zoom:50%;" />

#### 7.2.2 信任级别

**通常传感器检测空间和传感器的信任级别空间是不一样的。**因此必须建立起一个从一个空间到另一个空间的映射。一种简单的情况是各信任级别互不相交的情况，用文氏图表示如下图。对于单个传感器，圈越大表示信任级别越高）这种情况下，显然可以使用如下几项指标来定义信任级别：

-   信号处理算法及特征量的数目。
-   输入传感器的信号与被检测目标特征的匹配程度。
-   信号-干扰比

其中，信号-干扰比可以看成是信噪比的推广。在合适的情况下，回波也可以认为是一种有限的干扰。**在各信任级别互不相交的情况（即同一个传感器存在多个互不相交的信任级别）下，可以使多个传感器不同信任级别的虚警率达到最优。**之后通过[7.3.1节](7.3.1 在信任级别不相交的情况下推到系统检测率和虚警率)可以看出，若传感器的各信任级别不相交，则这种优化是可能的。在图中，传感器$A$的$A_3$信任级别大于$A_2$信任级别，而$A_2$信任级别又大于$A_1$信任级别。对于传感器$B$和$C$也有类似的定义。

<img src="/Users/RunshengWU/SensorFusion/Images/TrustLevel.png" alt="image-20201009133820414" style="zoom:50%;" />

对单个传感器信任级别数目的要求取决于两个因素：1⃣️是系统中传感器的数目；2⃣️是从传感器数据中抽取的特征量与特定信任级别的目标相关联的正确程度。传感器信任级别越高就越容易获得融合算法正确的输出结果，使在相当宽的工作条件下满足系统整体的检测率和虚警率的要求；同时如果传感器的信任级别数目越多，就越难定义一套特征量清晰地表示检测到的特征量和信任级别之间的关系。比如，在某些情况下处理雷达信号时，相对于仅仅一个输入信号而言，通过信号处理得到10多个特征量。在这种情况下，各信任级别可以通过特征量的匹配数以及输入信号与理想目标特征之间的匹配程度来定义。

#### 7.2.3 检测单元

**检测单元其实就是多个传感器输出结果的某种组合，**该组合基于传感器的硬件和信号判别函数，在真假目标之间或在敌方反测量干扰环境下来决定是否有感兴趣的目标。传感器输出结果的组合方式最终主要是基于设计者的经验和知识以及对传感器收集来的数据的分析基础之上的。

下表给出了三个传感器系统的检测单元组合模式。在检测单元组合模式中至少应包含两个传感器来避免单个传感器由于反量测干扰而引起的虚警。采用三传感器的检测单元${A,B,C}$融合了三个传感器低的信任级别，虽然它们各自的信任级别低，但也能满足要求，因为此时三个传感器都参与了决策，就能减少把虚假目标或把敌方反测量干扰认为是真目标的概率。这种检测单元特别适用于多个传感器对来源于不同物理属性的信号都有响应的情况。

下表列出了三种两个传感器的检测单元。${A,C}$和${B,C}$这两个检测单元都适用了两个传感器的中等信任级别。相对于三个传感器的检测单元来说，两传感器检测单元中各传感器的信任级别都有所提高，这是因为此时只有两个传感器参与了决策。对于检测单元${A,B}$来说，由于假定硬件及算法对信息的提供不如其他两种传感器检测单元组合的鲁棒性好，所以在使用这个检测单元时要求传感器$A$和$B$具有最高的信任级别。

![image-20201009135757149](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1ybfdb8j315y0cewfz.jpg)

另外，设计者可能也会考虑到，**某些检测单元组合罗列自决策表中，但要将其结果排出在外。**比如，已知某两个传感器对某几种相似的地形都容易产生虚警，这种情况下，对这两个传感器的输出结果组合而形成的检测单元对来自同一现象的信号并不能提供新的有力的信息，所以应加以去除。但是，当这两个传感器中有加入了第三个传感器时，就有可能提供非常强有力的目标判别能力，这时就应该保留这个三传感器组成的检测单元。

### 7.3. 系统检测概率

计算系统的检测概率基本步骤为：1⃣️基于已经确定的各信任级别之间的结构以及根据所选检测单元中各信任级别与其检测率、虚警率之间的关系来推导整个系统的**检测率公式**；2⃣️计算每个传感器**信号/噪声比或信号/回波比**；3⃣️识别被各传感器观测到的**目标机动属性**。

#### 7.3.1. 在信任级别不相交的情况下推到系统检测率和虚警率

一旦各检测单元确定后，就可以利用**布尔代数**来推导多传感器系统的检测率和虚警率的计算表达式。对于之前提到的多传感器系统（包含一个三传感器检测单元和三个二传感器检测单元），此时系统的检测率可以采用以下公式计算：
$$
P_d= P_d\left\{A_1B_1C_1 \ or \ A_2C_2 \ or \ B_2C_2 \ or \ A_3B_3\right\}
$$
反复利用如下布尔代数的展开式：
$$
P\left\{X \ or \ Y\right\}  = P\left\{X\right\} + P\left\{Y\right\} - P\left\{XY\right\}
$$
由于“各传感器自身信任级别之间时相互独立的（各信任级别互不相交）”这个假设，对于并和交的关系分别就有：
$$
P_d\left\{A_1 \cup A_2 \right\} = P_d\left\{A_1\right\} + P_d\left\{A_2\right\} \\ P_d\left\{A_1 \cap \ A_2\right\} = 0
$$
对传感器$B$和$C$也有类似描述（式72展开过程略），最后公式$72$简化为：
$$
系统P_d =  \ P_d\left\{A_1B_1C_1\right\} + P_d\left\{A_2C_2\right\} + P_d\left\{B_2C_2\right\} + P_d\left\{A_3C_3\right\} - P_d\left\{A_2B_2C_2\right\}
$$
式$76$中前四个正项反映了每个检测单元的检测率，最后一个负项清楚了重复计算项$\left\{A_2B_2C_2\right\}$，该项正好反映了检测单元$\left\{A_2C_2\right\}$和$\left\{B_2C_2\right\}$相交的部分。

**如果各传感器独立响应来自不同物理现象的信号**，则各传感器的检测率相互之间应该是独立的。这样，各个传感器的检测率可以直接相乘，由此得到整个系统的检测率为：
$$
系统P_{d} =  \ P_{d}\left\{A_1\right\}P_{d}\left\{B_1\right\}P_{d}\left\{C_1\right\} + P_{d}\left\{A_2\right\}P_{d}\left\{C_2\right\} + P_{d}\left\{B_2\right\}P_{d}\left\{C_2\right\} \\ + P_{d}\left\{A_3\right\}P_d\left\{B_3\right\} - P_{d}\left\{A_2\right\}P_{d}\left\{B_2\right\}P_{d}\left\{C_2\right\}
$$
上式也可以同来计算多传感器的虚警率（$False Alarm$），只需要把各传感器在相应信任级别上的检测率$P_d$换成虚警率$P_{fa}$即可：
$$
系统P_{fa} =  \ P_{fa}\left\{A_1\right\}P_{fa}\left\{B_1\right\}P_{fa}\left\{C_1\right\} + P_{fa}\left\{A_2\right\}P_{fa}\left\{C_2\right\} + P_{fa}\left\{B_2\right\}P_{fa}\left\{C_2\right\} \\ + P_{fa}\left\{A_3\right\}P_d\left\{B_3\right\} - P_{fa}\left\{A_2\right\}P_{fa}\left\{B_2\right\}P_{fa}\left\{C_2\right\}
$$

#### 7.3.2. 传感器各信任级别与对应的检测率和虚警率之间的关系

**从信任级别空间到对应的检测率（虚警率）空间的映射主要是通过传感器对传感器信任级别的固有检测率（虚警率）乘以一个条件概率来实现的。**这个条件概率是指目标在已经被检测到的条件下满足某个特定信任级别的概率。因为信号/干扰比在各个信任级别上是不同的，所以每个信任级别中传感器的固有检测率也应该是不同的。这样的传感器$A$在信任级别$A_n$的目标检测率为：
$$
P_d\left\{A_n\right\} = P_d\left\{A_n\right\}P\left\{A_n|已检测到目标\right\}
$$
式中：

-   $P_d\left\{A_n\right\}$——传感器$A$在信任级别为$A_n$的**固有检测率**。这个值与信号/干扰比、虚警率、目标激动情形以及信号采样点数有关；
-   $P\left\{A_n|已检测到目标\right\}$——在目标被传感器$A$检测到的条件下满足信任级别$A_n$的条件概率。

对于其他传感器的在其他信任级别下的检测率也有类似的定义。

在每个不同信任级别下，各传感器虚警率的计算也有类似的关系。如对传感器$A$在信任级别$A_n$下出现虚警的概率为：
$$
P_{fa}\left\{A_n\right\} = P_{fa}\left\{A_n\right\}P\left\{A_n|已检测到目标\right\}
$$
式中 $P_{fa}\left\{A_n\right\}$——传感器$A$在信任级别$A_n$下的固有虚警率；

从上面的公式可以看出，我们一直用一个相同的因子把信任级别空间转换到检测率和虚警率的概率空间，这个因子就是在已检测到目标的条件下，满足某一信任级别的条件概率。当然还可以发展其他一些模型（比如附录$B$中提出的各信任级别相交时的例子），在这些模型中结合了另一种概率，即已知传感器$A$出现虚警的条件下，这个虚警出现在该传感器信任级别为$A_n$的概率。多传感器系统的虚警率与信任级别之间的依赖关系主要是由计算虚警率是引入的阈值建立起来的。实际上整个系统的检测率也应该是虚警率的函数。是在虚警率的基础上乘以某个因子，该因子是在信号处理时得到的增益。此增益应正比于输入信号在多大程度上与在算法中事先设定好的目标特征相似，该增益应也与式$78$中的条件概率相关。

#### 7.3.3. 条件概率的估计

可以通过离线实验的方法来估计条件概率$P\left\{A_n|已检测到目标\right\}$，从而看出各种信号处理算法的性能。首先各种待测试算法运用[7.2.2节](7.2.2 信任级别)中讨论过的几条标准来定义各传感器的不同信任级别，然后使用目标和非目标数据进行具体测试。首先记录下通过每个信任级别的已被检测到的目标数，然后用这些数据来计算条件概率。举例来说，如果某传感器已经检测到$1000$个目标，他们全部通过信任级别$1$，那么在该传感器已检测目标的条件下，通过信任级别$1$的条件概率为$1$;如果某传感器已检测到$1000$个目标，但只有$600$个通过信任级别$2$，那么该传感器在已经检测到目标的条件下，通过信任级别$2$的条件概率为$0.6$。

如果条件概率已知，那么多传感器系统的检测率和虚警率就可以通过式$76,78｜77,79$来进行计算。对于虚警率，第一步是使用公式$79$计算各个传感器在某信任级别下的虚警率，然后根据检测单元组合结构将相关传感器在某一信任级别下的虚警率相乘。最后把负项的值代入。这样就妄称了一个检测单元的虚警率计算，当将所有检测单元的虚警率根据组合情况计算完毕后，就求出了整个系统的虚警率。检测率的计算步骤相同。

如果整个系统的虚警率满足要求，则寿命算法的信任级别判别是恰当的。如果整个系统的虚警率不满足要求，则需要重新选择条件概率，并且提出新的信任级别重新调整算法。还可以通过调整传感器固有的虚警率来满足系统的整体虚警率的要求。（见一节）

#### 7.3.4. 虚警率

每个传感器、每个信任级别对应的虚警率可能是互不相同的，因为从式$74$可以看出各个信任级别对应空间的交集为空。正是由于这个特性，可以认为在每个不同的信任级别上信号/干扰比也是不一样的。每个传感器在每个信任级别下固有的虚警率$P^{'}_{fa}\left\{\cdot\right\}$的选取应在满足整个系统的虚警率的条件下，尽可能的大，这样就能使每个检测单元的检测率达到最大。传感器发生虚警的概率$P^{'}_{fa}\left\{\cdot\right\}$也依赖于某一信任级别下的算法的性能，对于这一点也同样通过调整式$79$中的那个条件概率因子来体现。

为了得到传感器在每个信任级别下固有的虚警率，可以采用两种方法。

-   方法一：在每个信任级别下使用相同的检测门限，从而使在所有的信任级别下有相同的固有虚警率，而固有检测率又是该门限值的函数。尽管在各个信任级别上的检测门限是相同的，但是如果在各个信任级别中信号/干扰比不一样，则对应的检测率也应该是不一样的。同样，当检测门限在各信任级别中一样时，虚警数量在高信任级别中大大减少，这是信号处理算法所起的作用，这是虚警数量的减少主要因为在传感器固有虚警率上乘了一个表现此信任级别特点的条件概率。
-   方法二：在各个不同的信任级别上传感器固有虚警率用不同的门限来进行控制。高信任级别具有高的门限。最终的虚警数和上面一样也因随后的信号处理而有所降低。在这种情况下，检测率时各信任级别不同门限值的函数，因此也是个信任级别下对应的虚警率的函数。

>   门限值是建立检测系统时结合传感器性能，通过离线实验的结果人为设定的数值，该数值的规定直接影响了各信任级别下检测到的目标数量以及的条件概率，比如上述中传感器$A$分别有$A_1,A_2,A_3$三个信任级别，在一定的门限值下，通过离线实验，$1000$个目标数有$1000$个通过了信任级别$A_1$，则$P\left\{A_1|已检测到的目标\right\} =1.0$，同理，如果有$600$个目标数通过了$A_2$，则有$P\left\{A_2|已检测到的目标\right\} =0.6$

这两种方法都可以用来控制虚警数。当用来控制虚警的方法改变时，必须重复进行离线实验来找到上面提及的条件概率的新值。

**在各检测单元中都有一个如何把虚警分配给各传感器的问题。分配其实是基于各传感器预期通过信号处理来排出虚警的能力，最终体现在条件概率上的。**因为这个条件概率体现了两种概率之间的关系，这两种概率分布为传感器在某一信任级别下的固有虚警概率和已知在某一个信任级别下，在已检测到目标时，发生虚警的条件概率。从式$79$可以可以明显地看出条件概率低虚警率和检测率之间的折衷关系。从该式可以看出，在任何信任级别下，条件概率的降低会引起虚警的降低，但同时也会导致检测率的降低。

#### 7.3.5. 检测率

计算多传感器系统检测率的最后一步需要利用目标、背景以及传感器的特征来计算信号/干扰比或信噪比、除此之外，可能还需要用到综合分析的采样点数等信息。不考虑目标的机动属性，**传感器各信任级别的固有检测率可以通过查表或看图来获取**。对应主动式传感器（微波雷达、毫米波雷达或激光雷达）和被动式传感器（红外或毫米波辐射计、$FLIR$或$IRST$），以及直接检测标准（传感器不包含混频器来显示出所就接受的信号所具有的频率）或间接检测标准（传感器包含混频器），这些表和图也有所不同。传感器在某一信任级别下的检测率时该信任级别下的固有检测率与一个条件概率的乘积。这样每个检测率相乘在一起，最后把各检测单元的检测率以及式$76$中那个负项的值代入，就可以求出整个多传感器系统的检测率。

#### 7.3.6. 计算多传感器系统的检测率的小结

下图总结了计算多传感器系统检测率的框图。具体步骤概括如下：

1.  取定合适的多传感器输出组合（形成检测单元）；
2.  对每个传感器的各信任级别设定其固有的虚警率；
3.  通过一离线实验确定对应于传感器各信任级别下所检测到的目标数，然后根据式$78$的定义计算其条件概率；
4.  运用式$79$计算在给定的信任级别下，在已检测到目标的条件下的虚警概率；
5.  运用公式$77$计算多传感器系统的整体虚警率
6.  记录下每个传感器各信任级别下固有的虚警率；
7.  在可能的前提下，计算信号/回波比或信噪比或者两者都加以计算并记录下综合分析的采样点数。
8.  确定目标的机动属性，即目标时处于稳定状态还是处于慢机动或快机动状态；
9.  计算传感器在每个信任级别下的固有检测率；
10.  运用式$78$计算每个传感器在各信任级别下的目标检测率；
11.  运用式$76$计算多传感器系统的检测率并且确定是否满足事先要求的指标。

![image-20201009160421938](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1ydezblj30u20jaq6k.jpg)

### 7.4. 应用实例

考虑设计一个三传感器检测系统吗，要求如下指标：

-   虚警率$\le10^{-6}$而检测率$\ge0.8$

本例中，传感器$A$假设是一个毫米波雷达。相对于传感器$A$，目标有三型转弯机动属性；假设传感器$B$是激光雷达，相当于传感器$B$，目标表现为二型转弯机动属性；假设传感器$C$为红外图像仪，相对于传感器$C$，目标没有出现机动属性。最后假定各传感器各信任级别间具有不同的门限值。

假设通过离线实验确定每一传感器在各信任级别下检测到的目标数目如下表。**各传感器能检测到的数目取决于门限值的大小、信号处理的方法以及各传感器的目标特征判别函数等**。根据各信任级别下检测到的目标数，我们可以计算出对应的条件概率。

![image-20201010095921543](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1ygjwefj316m08aac9.jpg)

#### 7.4.1. 满足虚警率的要求

为了使多传感器系统的检测率达到最大，系统的虚警率应在所给的指标要求下尽可能的大（**从实验可以看到，检测率大往往伴随着虚警率大）**。根据上表提供的条件概率以及下表提供的$P^{'}_{fa}\left\{\cdot\right\}$（固有虚警率），整个系统的虚警率可以运用式$77,79$计算如下：
$$
P_{fa} =  \ P_{fa}\left\{A_1\right\}P_{fa}\left\{B_1\right\}P_{fa}\left\{C_1\right\} + P_{fa}\left\{A_2\right\}P_{fa}\left\{C_2\right\} + P_{fa}\left\{B_2\right\}P_{fa}\left\{C_2\right\} \\ + P_{fa}\left\{A_3\right\}P_d\left\{B_3\right\} - P_{fa}\left\{A_2\right\}P_{fa}\left\{B_2\right\}P_{fa}\left\{C_2\right\}  \\ = 2.6 \times10^{-7} + 2.5 \times10^{-7} + 2.4 \times10^{-7} + 2.4 \times10^{-7} - 2.4 \times10^{-10} = 9.9 \times 10^{-7}
$$
显然：$P_{fa} \le 10^{-6}$，系统满足虚警率要求。

![image-20201010101527625](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1yi0s7mj315m0dq77l.jpg)

#### 7.4.2 满足系统检测率的要求

传感器在各信任级别下的检测率可以通过各信任级别下的**固有虚警率、信号/噪声比、被分析信号的采样点数以及适当考虑目标机动属性等因素等**计算。在本例中，**在选定的信噪比和对应的虚警率只要求在一个采样间隔周期内满足整个系统的检测率要求的条件下。**可以将噪声当作有限干扰来处理以简化计算。每个传感器不同信任级别下的信噪比可以帮助我们定义传感器的信任级别。

各传感器及检测单元的检测率如下表，表中各信任级别的第一个数是各传感器的固有虚警率（在括号里）。通过这个固有虚警率来确定门限，从而得到各传感器固有检测率（第二个数）。

![image-20201010103514564](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1yjifawj315q0d8q62.jpg)

![image-20201010103533506](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1ym54gij315u09umzo.jpg)

结合式$76$,分别吧对应信任级别下的各传感器的检测率代入，得：
$$
P_d = 0.39 + 0.24 + 0.21 + 0.11 - 0.11 = 0.84
$$
这里假设各传感器的检测率是相互独立的。前思想代表了四个检测单元的检测率，而最后一项代表了对应$\left\{A_2B_2C_2 \right\}$的检测率。正如前面之处，这一相关在求和运算中被计算了两次，因此，必须冲求和中减去。

显然 $P_d \ge 0.8$，致辞，整个系统的检测率和虚警率都满足要求，如果这两项指标没有得到满足的话，就需要重新选择条件概率、传感器的固有虚警率以及需要综合分析采样点数。当系统的虚警率和检测率满足要求之后，传感器的硬件或信号处理算法也应该加以修改以满足新的要求。

#### 7.4.3. 从实例中观察到的现象

采用多个信任级别的组合能是我们的构造多个检测单元，他们具有不同的虚警率和检测率。检测单元$\left\{A_1B_1C_1\right\}$具有相对大的检测率，但同时也具有相对大的虚警率。而具有较小虚警率的的而传感器的检测单元其虚警率也更低，其这些检测单元在整体融合过程中却可以达到最优，并且可以使整个系统达到更高的检测率。但如果每个传感器只有一个信任级别可以利用，那么整个系统的检测率将不会得到更大的提高，整个系统的虚警率也不会进一步降低。

另外一个有趣的现象是式$76,77$所表示的系统检测率和虚警率之间的关系。各检测单元融合后的检测率要高于单个检测单元的检测率，而且这一点仅仅是通过整个系统的虚警率稍稍增加为代价。

### 7.5.5 传感器逻辑表决融合的硬件实现

下图显示了怎样用"与$AND$"（对应相乘）和“或$OR$”（对应相加）来给出系统检测的结果。该结果满足式$76$的检测率，同时这些"与"门和“或”门有与各信任级别下的对应传感器相连。当某个信号使传感器的某一信任级别满足要求时，则为该信任级别设置一个二进制位，当所有“与”门的二进制位都设定后，“与”门的输出就去触发“或”门，最后就可以得到一个有效的目标检测结果。

![image-20201010110306541](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1yorddnj30zc0nogpd.jpg)

>   PS：有图可以看出，在定义上，越高的信任级别意味着检测到的目标数越小，这是表层结果，但内在定义原因不明。

### 7.6 表决融合与$D-S$证据理论的比较

在表决融合中，运用各个传感器的量测信息来计算各自的检测率，然后根据布尔代数的表达式来融合各传感器的检测结果。**表决融合的内在规则是融合代表各传感器各信任级别的逻辑值**，这些信任级别是基于检测到某一物体的先验判定。因为天气、地形以及反测量干扰通常不会以同样的方式来影响各个传感器，所以各传感器对同一目标的检测率也是不一样的。

在$D-S$证据推理中，运用各传感器的输出信息计算其概率分配函数与某一命题相关联的目标是否属于某一特定目标。在这种情况下，各传感器将所获得的相互已知的目标类型的知识，运用$Dempster$规则，在量测空间中计算各命题下的概率非配函数值的交（或并）的值。

概率分配函数类似于表决融合方法中的信任级别信息，表决融合通过逻辑门来融合各传感器的信任级别，而$D-S$推理则是通过$Dempster$规则来融合概率分配函数的，

### 总结

运用布尔代数，我们得到了一个三传感器系统检测率的表达式，这三个传感器对来自独立信号源的信号度都比较敏感。各检测单元由两个或三个传感器组成，主要是为了系统的性能在多回波、恶劣天气以及由反量测干扰下，具有更强的鲁棒性。**我们不使用一个传感器来构成检测单元主要是为了减少系统对假目标或由于反测量干扰而产生的虚警**，这样做还可以保证当目标的某一域的信号被抑制时也能被检测出来的可能性大大增加。检测单元是通过组合多个传感器信任级别定义的。

**在传感器的各信任级别不相交的假设条件下**，可以独立地选择并实现各传感器在各信任级别下的检测率。在传感器各信任级别下的虚警率可以通过两种方法确定。第一种方式是在传感器的各信任级别下**定义相同的门限值**，从而得到相同的固有虚警率；第二种方法**允许检测门限值在不同的信任级别有所变化**，此时对应的固有虚警率也应该是变化的。从信任级别空间到检测空间的转化是通过两个因子相乘来实现的，第一个因子是传感器的固有检测率，它反映了传感器信任级别的特征；第二个因子是在给定信任级别下检测出目标的条件概率。同样，我们也可以从传感器的信任级别中计算出虚警率。最后给出了一个简单的表决融合的硬件实现，从中可以看出这种融合方法实现起来的成本是很低的。

## 8. 模糊逻辑和模糊神经网络

模糊逻辑是一种在数字框架下进行模拟处理的方法。这个模拟处理过程通常不能很简单地进行分段处理，并且也很难建立起基于传统的数字或规则的模型，因为传统的模型需要很明确的边界或决策，比如二值逻辑（需要说明任何一个元素要么属于某个集合，要么不属于这个集合）。因此，当各集合之间的边界不能被明确定义时，或者某个事件部分发生时，模糊逻辑就显得十分有用。在模糊逻辑理论中，元素的隶属度反映了这个元素属于该集合的程度。

>   相比去传统的模型，模糊逻辑的作用体现在：当某个事件不能被明确地使用二值逻辑（属于｜不属于某个集合）时，或者更准确的说，某个事件只有**部分特征**满足我们先验定义的某个集合，我们把这种“部分满足”用“属于的程度”来描述。

### 8.1. 模糊逻辑能提供合适解的条件

$Lotfi \ Zadeh$在1965年创建了模糊逻辑理论。他认为传统集合理论比较僵化，它没有考虑到**现实世界中广泛存在的含糊性、不精确性以及灰色性**。通过建立一些规则和模糊集，即使设计者对系统本身的数学模型不十分了解，也能用模糊逻辑对系统进行控制。模糊逻辑还允许在决策理论中嵌入一些表示“模糊”的概念。

>   比如：某人说一个人“矮”，但没有给出这个人身高的具体数值，有人可以推断对于一个成年人，矮的身材可能低于$5ft$，但可能还有人认为矮个子和普通人身高的分界线是$5ft\ 2in$或$5ft \ 3in$等。
>
>   再比如：我们可以说一个物体离你“近”或“远”，或者可以说汽车开得很“快”，已经超速了等。
>
>   在这些例子中，都是在某个范围里的数值满足引号里的词的意思。

一般来说，以下情况采用模糊逻辑对于优化控制来说是一个比较合适的方法：

-   一个或多个控制变量是连续的。
-   建立过程的数学模型尚不成熟，这种不成熟体现在：
    1.  模型根本不存在；
    2.  模型存在但很难建立；
    3.  模型过于复杂以至不能实时估计；
    4.  需要庞大的存储空间
-   需要考虑高强度的环境噪声；
-   只能使用廉价的传感器或**低精度**的微处理器；
-   具有可以利用的**专家知识**，使用专家知识可以建立一些规则与模糊集。规则能知道系统的运行而模糊逻辑反映了变量的一些模糊特性。

### 8.2. 模糊逻辑应用于汽车反锁刹车系统

我们可以通过一个汽车反锁刹车系统的例子来说明模糊控制的应用。首先需要对各控制变量之间建立规则，这些控制变量包括汽车的速度、刹车压力、刹车温度、两次刹车之间的时间间隔以及汽车侧向运动相对于前向运动的角度。因为这些变量都是连续量，因此，设计者可以用描述性的语言来反映这些变量所取值的范围（如速度可以描述为快、慢；压力可以描述为高、低；温度可以描述为冷、热；时间间隔可以描述为长、短等）。

可以对温度进行进一步细化的描述，如有冷、凉、微温、暖和热等，这样就能更全面地描述温度这个变量。在模糊逻辑中，温度**从一个状态变成另一个状态并不是精确定义的**，$280^{\circ}F$这个温度值可以属于暖和也可以属于热，这完全取决于设计者的解释。但是可以肯定的是，我们绝不可能因为温度升高了十分之一就说温度从暖和变成了热。因此冷热等的概念在所取值范围内对不同的专家拉说，在不同情况下所作的解释也是不一样的。

模糊逻辑允许使用一些包含不精确度量的控制语句。对于刹车温度来说，一条条件模糊规则可以这样描述："IF 刹车温度是暖和的，AND 汽车速度不是很快，THEN 刹车压力可以轻微放松。“刹车温度的度——暖，汽车速度的度——不是很快，就控制了刹车压力的度——轻微放松。从这个意思上说，一条模糊规则能够替代许多条传统的数学规则。

### 8.3. 模糊系统中的基本元素

在模糊系统中有三大基本元素，即**模糊集、隶属函数和产生式规则**。**每个模糊集都包含了表征系统的输入变量或输出变量的取值**，而这些取值又都是不精确的。例如上面的反馈刹车系统中，温度这个变量被分成了五个模糊集、即冷、凉、微温、暖和热。每个模糊集都有一个隶属函数，它的**几何形状**代表了这个模糊集的边界。每个变量的特定值在模糊集里都有自己的隶属度，这个隶属度被限制在$0$和$1$之间。$0$代表了这个变量的值不在这个模糊集中，而$1$代表了这个变量完全隶属于这个模糊集。中间的隶属度用$0$和$1$之间的数表示，**具体的值由定义这个模糊集的人给出**。一个变量值可以分属于多个不同的模糊集。在上面那个反锁刹车系统的例子中，对于一个给定的温度值有时属于暖和这个模糊集，而有时也可能属于热这个模糊集。这样模糊集里面的**每个元素都被一有序数对定义，数对的前一个数是这个变量的值，而后一个数表示这个变量的值属于这个模糊集的隶属度。**

>   钟形曲线最早被用来定义隶属函数，但是由于计算起来比较复杂，其最后效果却饿三角形或梯形函数相差无几，所以现在钟形隶属函数在大多数情况下被三角形或梯形隶属函数所替代。

三角形或梯形隶属函数的底边的宽作为设计的一个参数，需要小心选择来满足系统整体性能的要求。使用一些启发式的知识，$Kosko$提出了**相邻两个模糊集重叠米娜集通常应占总面积的$25\%$。过多重叠面积会导致模糊集里面的变量过于模糊，而太小的重叠面积会导致类似于二值控制、具有严重的震荡。**

产生式规则，即"$IF(AND|OR)-THEN$“。这种逻辑表达式反映了人类的一种知识形式。在人工智能领域中，"$IF(AND|OR）-THEN$“表达形式是整个专家系统中不可缺少的一部分。专家系统依赖于二值逻辑和概率论来进行推理，推理是主要使用产生式规则。而模糊逻辑把模糊性融入了产生式规则中，因为模糊集本身能反映语言的不精确性。多条产生式规则并行处理，共同以不同程度对控制系统的输出产生影响。使用模糊集的逻辑处理过程就是大家熟知的模糊逻辑。

### 8.4. 模糊逻辑处理过程

模糊逻辑的计算过程框图见下图

<img src="/Users/RunshengWU/SensorFusion/Images/furlogie.png" alt="image-20201012110634107" style="zoom: 50%;" />

模糊逻辑处理过程大致可以分为两大功能模块——**推理模块**和**解释模块**。要进行推理首先要开发一些产生式规则，这些规则以"$IF(AND|OR)-THEN$“的形式来描述，也被称为模糊关联存储。规则的前件或条件部分从$IF$开始：规则的后件或结论部分从$THEM$开始。**分配给后件的激励值等于前件中代表各输入变量隶属函数（也就是模糊集）的逻辑积**$AND|OR$。这里的模糊输入激励值等于输入变量在此时的值与其隶属函数的交。如果某条规则的前件是用$AND$连接的复合句，此时逻辑积等于各输入激励值中的最小值；如果某条规则的前件是用$OR$连接的复合句，此时逻辑积等于各输入激励值中的最大值。

当这些产生式规则应用于某个过程时，一般是同时处理的（这些规则好像是由$OR$连接起来的那样），通常每秒几百次。当规则前件的逻辑积为零时，分配给与之相连的规则的后件激励值也为零。

**解模糊是把模糊值转化为一个确定的离散输出**，这个确定输出就可用于系统的控制，而这个模糊值是用上面提到的逻辑积和规则后件的隶属函数来表示的。解模糊可以有很多种方法进行，**典型的一种方法是计算后件模糊集的质量中心即模糊质心**。对于模糊集的隶属函数是对成单峰时，计算模糊质心就等价于寻找输出分布的状态。**模糊质心集中了后件模糊中的所有的信息**。通常有两种方法来计算模糊质心，第一种方法称之为**最小相关推理**，这种方法在逻辑积处去掉了后件模糊集顶部；另一种可选择的方法称之为**相关积推理**，方法是对后件模糊集对应的隶属函数乘以一个因子，而这个因子就是逻辑积，两种方法的计算方式如下图。

![image-20201012114029651](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1yplrewj30p80g6ac0.jpg)

在这个意义上，相关积推理比最小相关推理保留了更多信息。有时还用其他方法来解模糊，最简单的一种方法是从后件模糊集汇中选择最大峰值作为输出值。这种方法只适用于输出分布是单峰的情形，而输出分布是由逻辑积、后件和隶属函数决定的。

### 8.5. 模糊质心的计算

>   计算模糊质心是解模糊的典型方法，即将前件的逻辑积（后件的激励值）与后件的隶属函数相结合，形成一个模糊值，再将这个模糊值转化成一个确定的离散输出。

根据$Kosko$的方法，模糊质心$C_k$为：
$$
C_k = \frac{\int{ym_o(y)dy}}{\int{m_o(y)dy}}
$$
式中，积分上下限是相对于输出变量的整个区间范围；而：

-   $y$——输出变量，事先定义在模糊集中

-   $m_o(y)$——在$k$时刻由**所有产生式规则**的联合估计所形成的输出模糊集合组合，即：

-   $$
    m_o(y) = \sum^N_{i=1}{m_{o_i}(y)}
    $$

-   $N$——产生式规则的数目；

-   $o_i$——第$i$条产生式规则输出（后件）的模糊集.

当输出变量值空间被离散成$P$个值时，式$82$变成：
$$
C_k = \frac{\sum^P_{j=1}y_jm_o(y_j)}{\sum^P_{j=1}m_o(y_j)}
$$
当输出变量模糊集是由相关积推理得到的，则总体输出模糊集质心$C_k$可以用过各条产生式规则输出变量模糊集的质心计算，具体公式如下：
$$
C_k = \frac{\sum^N_{i=1}w_ic_iA_i}{\sum^N_{i=1}w_iA_i}
$$
式中：

-   $w_i$——第$i$条产生式规则后件模糊集$L_i$的激励值；
-   $c_i$——第$i$条产生式规则后件模糊集$L_i$的质心；

$$
C_i = \frac{\int{ym_{L_i}(y)dy}}{\int{m_{L_i}(y)dy}}
$$

-   $A_i$——第$i$条产生式规则后件模糊集$L_i$的面积；

$$
A_i = \int{m_{L_i}{y}dy}
$$

-   $L$——所有产生式规则后件模糊集的集合；

更进一步，如果所有输出模糊集的隶属函数都是对称且单峰的（如三角形或梯形隶属函数），并且所有输出模糊集的数量不超过$7$个，那么总体输出模糊集质心可以通过**采样**总体模糊集$o$上7个点来计算即可，在这种情况下有：
$$
C_k = \frac{\sum^P_{j=1}y_jm_o(y_j)A_j}{\sum^P_{j=1}m_o(y_j)A_j}
$$
这里$A_j$是第$j$个输出模糊集的面积，和上面的$A_i$相同。这样如果所有模糊集都是对称且单峰的，并且如果使用相关积推理来形成了输出模糊集$o_i$，那么式$88$就提供了比式$82$简单得多但却等价的方法来计算总体输出模糊集的质心。

### 8.6. 用模糊逻辑来控制倒立摆的平衡

经常用来演示模糊逻辑的一个应用实例式倒立摆的平衡控制问题（等价于平衡一根立于手掌中的杆），这个例子的模型见于下图。

<img src="/Users/RunshengWU/SensorFusion/Images/handstandModel.png" alt="image-20201012133450247" style="zoom:50%;" />

#### 8.6.1. 常规数值解

我们可以认为倒立摆式一放置在一个可以随时间水平移动的底座上的杆，并为其建立一个数学模型，然后用常规的控制方法来解决这个摆的平衡问题。在这个模型中，长为$l$的杆的质量相对于在杆顶端的小球的质量来说可以忽略不计。小球的**位置**和**速度**坐标可以表示为：
$$
x,y = x_s + l\sin{\theta}, - l\cos\theta
$$

$$
\dot{x},\dot{y} = \dot{x_s} + l\dot{\theta}\sin\theta,l\dot{\theta}\cos\theta
$$

这里$\theta$是指摆偏离平衡位置的角度，在变量顶部加一点表示对这个变量的导数。使用系统拉格朗日变量$L$可以得到描述摆动运动规律的方程，这里：
$$
L = T-V
$$
其中**$T$表示摆相对于时间$t$的动能函数，而$V$表示摆相对于时间$t$的势能函数**。代入动能和势能公式的表达式，拉格朗日变量$L$变为：
$$
L = \frac{m}{2}(\dot{x^2_s}+ l^2\dot{\theta}^2 + 2l\dot{x_s}\dot{\theta}\cos\theta)+ mgl\cos\theta
$$
这里$\dot{\theta}$是指偏离平衡位置的角度变化率，$g$是指重力加速度。

倒立摆的运动方程可以通过拉格朗日方程表示出来，即：
$$
\frac{d}{dt}(\frac{\partial{L}}{\partial\dot{\theta}}) - \frac{\partial{L}}{\partial\theta} = 0
$$

把式$92$代入$93$，得：
$$
l\ddot{\theta} + \ddot{x_s}\cos\theta + g\sin\theta = 0
$$
式$94$的解的形式并不见大，因为这个微分方程设计到椭圆积分的问题。但是如果$\theta$比较小（$|\theta|<0.3rad$），那么$\sin\theta$与$\theta$接近相等，微分方程$94$就可以化简为以下公式：
$$
l\ddot{\theta} + \ddot{x_s}+g\theta = 0
$$
 当$x_s = x_0\cos{wt}$时，式$95$就变为：
$$
\ddot{\theta} = w_0^2\theta = \frac{x_0}{l}w^2\cos{wt}
$$
其中：$w_0 = \sqrt{\frac{g}{l}}$

微分方程$96$的一个特解是可以使用待定系数法得到：
$$
\theta_p(t) = \frac{x_ow^2\cos{wt}}{l(w_0^2-w^2)} \ \ \ (w_0 \ne w)
$$
其通解为：
$$
\theta(t) = \frac{x_0w^2\cos{wt}}{l(w_0^2 - w^2)} + A\cos{w_0t}+ B\sin{w_0t} \ \ \ (w \ne w_0)
$$
由此可以看出，只要$w \ne w_0$,倒立摆的摆动总是有界的；当$w = w_0$时，共振就出现了（即出现大幅度的角度偏离平衡位置）。在共振时，倒立摆的摆动方程为：
$$
\theta(t) = \frac{x_0w^2\cos{wt}}{2l} + A\cos{w_0t}+ B\sin{w_0t} 
$$
常数$A$和$B$可以通过$\theta$和$\dot{\theta}$在$t=0$时的状态约束得到。

#### 8.6.2. 模糊逻辑解

模糊逻辑可以产生一个描述倒立摆的近似解，这个近似解不需要描述倒立摆摆动的数学方程方面的知识，更不需要获得这个数学方程的解。相反，只需要下表中列出的7条**产生式规则**即可：

![image-20201012142543885](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1yqidabj311a0c6tcq.jpg)

这些产生式规则描述了输入变量是如何结合起来的。在这个例子中输入变量是指倒立摆与垂直方向所夹的角$\theta$以及与此同时角的变化率，这里用$\Delta\theta$表示，值得注意的是，这两个变量都可以取正值或负值。产生式规则前件隶属函数对应着规则前件的额一些模糊词语，如"中等"、"稍微“和"慢慢“等，这些词语用标在隶属函数上的**两个字母**作为标志，见下图。

<img src="/Users/RunshengWU/SensorFusion/Images/subjectFunction.png" alt="image-20201012143312717" style="zoom:50%;" />

在这$7$个标志中有三个表示正方向的取值范围，三个表示负方向的取值范围，还有一个表示接近零的位置。每个变量的隶属函数重叠大约$25\%$的面积，这样做是为了保证当输入级别不是很清楚或输入级别不断变化时，系统的响应比较平滑。各隶属函数描述了$\theta$和$\Delta\theta$属于各模糊集的程度。**每个三角形隶属函数底部所标的数据时用来计算每个模糊集的质心的。**

产生式规则后件的隶属函数指出了倒立摆底座时如何随着前件变量$\theta$和$\Delta\theta$的变化而变化的。当前件的各条件是由$AND$连接在一起时，选择前件隶属函数最小的激励值作为输出作用到后件模糊集上。最后， 同时对所有产生式规则所形成的输出模糊集进行解模糊。在本例中，计算输出模糊集的质心，从而得到一个确定的值来控制倒立摆的底座的速度。

下图显示了某一时刻，平衡倒立摆的一个模糊处理过程。模糊控制器的一个输入时由电位计测量的角度$\theta$，另一个输入$\Delta\theta$是由当前角度量减去上一次角度量测而得到的。控制系统的输出输入到伺服电机中，从而控制倒立摆底座以$\Delta V$的速度移动。如果倒立摆向左倾斜，它的底座也不许向左移动，反之亦然。

![ProcessOfFurLogie](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1yswek5j315g0u0qbx.jpg)

考察规则一的前件可以看出，此时的$\theta$值与代表"中等程度向左偏“的隶属函数相交于$0.7$，而此时的$\Delta \theta$与代表"几乎处于静止状态“的隶属函数相交于$0.8$。这两数的逻辑积$AND$为两数较小的一个，即$0.7$。然后把这个值与产生时规则一的后件"快速向左移动中等距离“相联系，在处理产生式规则二时，我们可以发现$\theta$值与代表“稍微向左偏”的隶属函数相交于$0.3$，而$\Delta \theta$值与代表“慢慢倒下”的隶属函数相交于点$0.2$，这时两个数的逻辑积$AND$（最小值）为$0.2$，这个值即与产生式规则的后件“稍微快速向左移动"相来逆袭。其余剩下的产生时规则的前件逻辑积均为零（$\theta$和$\Delta \theta$值在与前件隶属函数相交过程中，至少有一个为零）。

当所有产生时规则在采样时刻同时处理完以后，就可以进行解模糊。解模糊其实是计算输出魔术集隶属函数的质心，见上右下角，所有方法为最小相关推理，然后用这个解模糊值来控制平衡代理摆底座所需运动的方向和速度。根据结果，对倒立摆力作运动的要求是以相对应于质心值为$3.6$的速度向左运动。

$3.6$这个值（$\frac{3.6}{0.9}$）是通过式$84$计算得到的。下表列出了所需的参数值。式$84$的分子等于所有乘积$y_jm_o(y_j)$的和，分母等于所有$m_o(y_j)$的和。

因为规则后件模糊隶属函数的面积$Z_j$都相等，所以可以用$w_j$和$c_j$的乘积和来代替式$84$的分子，这里$w_j$的输入激励值，而$c_j$的第$j$条产生式规则后件模糊集隶属函数的质心。

![image-20201012152753000](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1yumc9sj311w0ekq4g.jpg)

尽管模糊系统的输出是一个确定值，但系统总的解仍然是近似的。这是因为这个解是由各条产生式规则和各个隶属函数的形状来决定的。通常认为模糊逻辑控制是鲁棒的，因为他能容许一定的不精确。模糊系统即使在数据丢失或隶属函数松散定义的情况下也能保持一个比较好的性能。

### 8.7. 模糊逻辑用于多目标跟踪

在本例中，基于模糊逻辑的多目标跟踪实际上是使用模糊卡尔曼滤波器，通过更新$k$时刻的状态来正确估计目标在$k+1$时刻的位置和速度等状态矢量。卡尔曼滤波在已知所有历史量测的条件下，对目标的位置、速度等状态的估计值与测量值之间误差的方差进行最小化。离散时间模糊卡尔曼滤波器相对于常规卡尔曼滤波，减少了计算时间，特别在多维及多目标的情形下，这种效果更为明显。

#### 8.7.1 常规卡尔曼滤波器

一个卡尔曼滤波器包含了一个**状态转移模型**和一个**量测模型**。

状态转移模型能基于在$k$时刻的可用信息预测$k+1$时刻的**目标状态矢量**，即**位置**和**速度坐标**。
$$
X_{k+1} = FX_k + JW_k
$$
这里
$$
X^T_k = [x_k,\dot{x_k},y_k,\dot{y_k}](两维的情况)
$$
式中

-   $T$——转置运算
-   $F$——系统或转移矩阵
-   $J$——输入矩阵
-   $W_k$——存在于目标运动模型中的干扰输入矢量或干扰噪声

**卡尔曼滤波器使用$k-1$时刻之前所有收集的数据来预测$k$时刻目标的状态矢量$X$和估计误差方差矩阵$P$。**因此，状态矢量一步预测值$\hat{X}_{k|k-1}$可以由卡尔曼滤波器中的恶一下公式给出：
$$
\hat{X}_{k|k-1} = F\hat{X}_{k-1|k-1}
$$
其一步预测误差方差$P_{k|k-1}$由以下公式给出
$$
P_{k|k-1} = FP_{k-1|k-1}F^T + J\sum_k{J^T}
$$
这里，符号$k|k-1$表示在$k-1$时刻，通过已有所有的数据来对$k$时刻值的预测；$\sum_k$为输入误差$W_k$的方差矩阵。

量测模型使用在**信息矢量**中包含的新信息来修正预测的状态。信息矢量$\tilde{Z}_k$式这样定义的：实际光测矢量与预测观测矢量之差，即
$$
\tilde{Z}_k = Z_k - Z_{k|k-1} = Z_k - H\hat{X}_{k|k-1} \\ Z_k = HX_k + n_k
$$
式中	

-   $H$——输出或观测矩阵
-   $n_k$——观测噪声向量，它通常包含一个固定但未知的偏移即随机分量。

最后，式$102$中的预测状态向量和式$103$中的预测误差方差矩阵被修正为：
$$
\hat{X}_{k|k} = \hat{X}_{k|k-1} + G_k\hat{Z}_k \\ P_{k|k} = [(P_{k|k-1})^{-1} + H^TR_k^{-1}H]^{-1}
$$
式中

-   $G_k$——滤波器增益，它是预测误差方差矩阵$P_{k|k-1}$的函数；

$$
G_k = P_{k|k-1}H^{-1}(HP_{k|k-1}H^T + R_k)^{-1}
$$

-   $R_k$——噪声矢量$n_k$的方差矩阵

修正的虚测误差方差矩阵也可以用滤波器的增益来表示：
$$
P_{k|k} = [I-G_kH]P_{k|k-1}
$$
这里$I$是单位矩阵，我们也可以用你矩阵引理把估计误差方差矩阵写成:
$$
P_{k|k} = P_{k|k-1}- P_{k|k-1}H^T[H^TP_{k|k-1}H+R_k]^{-1}HP_{k|k-1}
$$

#### 8.7.2. 模糊卡尔曼滤波器

在高阶系统中，使用常规卡尔曼滤波器，复杂的矩阵相乘是一个瓶颈，而使用模糊卡尔曼滤波器能减少复杂的矩阵相乘运算，从而节约运行时间。

假设只能获取不完全的信息，即只有位置信息可以量测到，然后用模糊逻辑方法来实现数据关联和更新预测的状态矢量。可以通过**定义如下两个矢量来进行数据与目标的互联**：

1.  基于欧氏距离的数据**有效性度量**
2.  基于物体尺寸及反射强度信息的相似性度量。

可以用一个**模糊返回信息处理器**来计算这两个量。这个处理器的输出就是平均信息矢量，它被用于输入到模糊状态关联器中，通过模糊状态关联器，在已知$k-1$时刻的信息条件下来更新$k$时刻目标位置和速度等状态量的预测估计。

在模糊卡尔曼滤波器中对状态矢量$X$的预测方程与式$102$完全相同。**同常规卡尔曼滤波器不同的是，这里使用模糊逻辑来产生修正矢量$C_k$，运用这一矢量通过如下公式来更新状态预测值。**
$$
\hat{X}_{k|k} = \hat{X}_{k|k-1} + G_kC_k
$$
这里$C_k$是等价于信息矢量$\hat{Z}_k$的修正矢量。

**步骤1⃣️：模糊返回信息处理器**——模糊返回信息处理器的作用就是要在目标识别中减少由于密集回波、噪声北京或由于图像处理而造成的某些不确定性。在本例中，被用来识别和跟踪目标的数据是由一系列前向红外图像仪$FLIR$产生的。被动式$FLIR$传感器只能量测到目标的位置，不能量测到目标的速度。模糊返回信息处理器能产生两个参数，运用这两个参数使由$FLIR$传感器得到的数据与某个目标互联。**第一个参数就是数据有效性度量；第二个参数就是与图像长方形尺寸有关及像素强度有关的数据相似性度量。**

**当在$k$时刻有多个回波来源于目标附近时，就需要数据有效性度量**。模糊有效性度量把每个回波的有效性都给予一个$[0,1]$之间的数。**第$i$个回波数据有效性$\beta_{valid,i}$与该回波对应信息矢量的欧氏范数成反比**，信息矢量的欧氏范数如下式：
$$
||\tilde{Z}_k|| = [(x_{k,i}-\hat{x}_k)^2 + (y_{k,i}-\hat{y}_k)^2]^{\frac{1}{2}}
$$
式中：$\tilde{Z}_{k,i}$——在$k$时刻的第$i$个回波的信息矢量。
$$
\tilde{Z}_{k,i} = Z_{k,i}-\tilde{Z}_{k|k-1} \ [类似于式104]
$$
式$110$括号里的参数各自代表$x$和$y$方向上的目标量测值和预测值（带帽子）

下图给出了有效性度量模糊集的隶属函数。当回波数目变化时，可以改变常数$d_1$和$d_2$的值，使得模糊卡尔曼滤波器的总体性能达到最优。**我们可以把有效性度量和相似性度量结合在一起来计算信息矢量，这个信息矢量最后要用到模糊状态关联器中。**

<img src="/Users/RunshengWU/SensorFusion/Images/validationSubject.png" alt="image-20201012165126344" style="zoom:50%;" />

**相似性度量被用来关联新的数据与以前被检测到的目标数据。**这种关联是通过尺寸差异与回波强度差异这两前件模糊集来实现的，他们的隶属函数如下图：

<img src="/Users/RunshengWU/SensorFusion/Images/ComparaSubject.png" alt="image-20201012165440429" style="zoom:50%;" />

关联新数据与目标相一致的所有可能的产生时规则列于下表：

![image-20201012165645460](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1yvxztlj31c80cidid.jpg)

一旦数据与先前检测到的某一目标相关联上，可以用如下图所示的相似性度量的隶属函数来找到产生时规则后件的激励值，然后基于这个相似性度量的激励值再用对规则后件模糊集解模糊的推理方法，通过计算质心来找到权$\beta_{similar,i}$。

最后使用所有回波$i$，$i = 1,...,n$，共$n$个回波的权$\beta_{valid,i}$和$\beta_{similar,i}$来计算加权平均信息矢量，计算式如下:
$$
\tilde{Z}_k = \begin{bmatrix}\tilde{x}_k \\ \tilde{y}_k \end{bmatrix} = \sum^n_{i=1}\beta_i\tilde{Z}_{k,i}
$$
这里$\beta_i$是一个$[0,1]$之间的数，他是分配给第$i$个信息矢量的权值，代表了第$i$个回波是某个目标的信任度。$\beta_i$的值是通过线性组合$\beta_{valid,i}$和$\beta_{similar,i}$而得到的：
$$
\beta_i = b_1\beta_{vaild,i}+ b_2\beta_{similar,i}
$$
这里常数$b_1$和$b_2$的和为$1$。通过改变这两个常数，可以这种考虑有效性度量与相似性度两的相对重要性，从而改变模糊返回信息处理器的工作新能。**用式$112$计算出来的加权平均信息矢量输入到模糊状态关联器中，进一步去修正某一感兴趣的目标状态。**

**步骤2⃣️：模糊状态关联器**——模糊状态关联器根据模糊返回信息处理器的输入，计算修正矢量$C_k$，然后根据式$109$来更新$k$时刻的目标位置、速度等状态预测值。

为了找到$C_k$，把平均加权信息矢量在$x$轴和$y$轴方向上的分解，分别记$e_x$和$e_y$。这样可以定义$e_k$为:
$$
e_k = \begin{bmatrix}e_x \\ e_y \end{bmatrix} = \tilde{Z}_k
$$
因为 $x$反向和$y$方向是互相独立，$Horton$和$Jone$首先发展了一种在$x$方向上的模糊状态关联器，然后再把结果推广到$y$方向。**决定模糊状态关联器输出的产生式规则有两个条件，即平均加权信息矢量中$x$方向上的$e_x$和$d\_e_x$。**假设知道当前时刻的误差值$e_x$及前一时刻的误差值$past\_e_x$，那么$d\_e_x$可以这样计算得到：
$$
d\_e_x = (e_x - past\_e_x)/时间步长
$$
定义前件模糊集$e_x$和$d\_e_x$的隶属函数见下图：

<img src="/Users/RunshengWU/SensorFusion/Images/NewInforSubjectFunction.png" alt="image-20201012172700625" style="zoom:50%;" />

使用$e_x$和$d\_e_x$这两个值，在模糊状态关联器中可以使用产生时规则，下表总结了实现模糊状态关联器所需的全部$49$条规则：

![image-20201012172950758](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1ywzgbsj315u0fyadg.jpg)

经过仔细比较输出的平均最小均方根误差$(RLSE)$，$Horton$和$Jone$提到了这些产生式规则后件输出模糊集所对应的隶属函数，见下图。在这个例子中，三角形和梯形的隶属函数的底部坐标已被调整好使系统获得预先希望的响应。

<img src="/Users/RunshengWU/SensorFusion/Images/CorrectVectorSubjectFunction.png" alt="image-20201012173425261" style="zoom:50%;" />

根据质心或模糊中心可以对修正向量$C_k$的激励值以及推理过程中的规则后件模糊集合进行解模糊计算。可以通过在$x$方向解模糊缓解的输入中乘以增益变量$T$来改善模糊跟踪器的性能，见下图。通过合适地选择增益$(T_1 = 1,T_2 = 1,T_3 = 1)$可以使平均最小均方根误差$(RLSE)$从$5$降到接近于$1$。

<img src="/Users/RunshengWU/SensorFusion/Images/ImprovePerformance.png" alt="image-20201012173711289" style="zoom:50%;" />

### 8.8. 模糊神经网络

**在每一时刻，自适应模糊神经网络使用样本数据和神经网络算法来定义一个模糊系统。连接权值和/或输入信号都可以是模糊集**，这样模糊神经网络可以实现以下几种情形：

1.  非模糊输入信号但模糊连接权；
2.  模糊输入信号但非模糊连接权；
3.  模糊输入信号和模糊连接权。

第一类模糊神经网络的一个例子见下图，他是由$Yamakawa$等发展起来的一种模糊神经元。每个神经元包含**非模糊输入信号**$x_i(i=1,...m)$和**固定的一些模糊集**$u_{ik}(k = 1,...,n)$。这些模糊集用来调整非模糊的权$w_{ik}$。这种模糊神经网络采用启发式学习算法来更新权值。这个算法所采用的公式类似于$BP$算法。**在各模糊集上还加有一个约束，即对某个$x_i$而言，只有相邻的值才能是非零值。**

这样，下图中如果$u_{ik}(x_i)$和$u_{i,k+1}(x_i)$为非零值，则：
$$
y_i = u_{ik}(x_i)w_{ik} + u_{i,k+1}(x_i)w_{i,k+1}
$$
神经元输出$Y$等于所有$y_i$的和，即：
$$
Y = y_1 + y_2 + ...+y_m
$$
<img src="/Users/RunshengWU/SensorFusion/Images/YamakawaFurNeurnal.png" alt="image-20201012175342306" style="zoom:50%;" />

$Nakamura$和$Tokunaga$等提出了另一类型的模糊神经元，有下图所示的结构。

<img src="/Users/RunshengWU/SensorFusion/Images/NakamuraFurNeurnal.png" alt="image-20201012175523748" style="zoom:50%;" />

在这种情况下，学习算法能优化每个模糊集$u_i（i=1,...,m）$的梯形隶属函数和非模糊权值$w_i$，此时神经元的输出$Y$等于：
$$
Y = \frac{\sum^m_{i=1}w_iu_i（x_i）}{\sum^m_{i=1}w_i}
$$
模糊神经网络的第二和第三类结构类似于多层前向神经网络，第二类模糊神经网络包含了一个模糊输入信号矢量和一个模糊输出信号矢量（非模糊权），对这类神经网络可以采用$BP$或其他学习算法。第三类模糊神经网络包含了模糊输入和模糊输出信号以及模糊权，这些模糊权作用与该层输入信号。$Buckly$和$Hayashi$讨论了第三类模糊神经网络的学习算法，他们推导出，在这类模糊神经网络中，学习算法可以采用一些特殊的运算作用到信号上而不仅仅是简单的相乘和相加。

### 总结

模糊逻辑，其实和它名字恰恰相反，是一些事先定义好的精确规则，**这些规则在两个集合之间的边界不能明确定义，事情只有部分发生时，或者直到某一个过程的函数方程不是很清楚时等许多场合下，可以得到方便的应用。**为了减少计算时间，模糊逻辑也常常用于复杂或高维的过程。

>   军事上，模糊逻辑在数据融合中已经运用到战场目标的识别上，能描述敌人部队的组合成份，并切能给出敌人兵力强度及作战动机的合理解释。

**应用模糊逻辑最困难的地方可能就是如何定义隶属函数。**这个隶属函数直接反映了输入变量是如何影响模糊系统输出的。

**一个模糊控制系统能非线性地把精确的或模糊的状态输入转换成一个模糊集输出。**模糊系统包含了各隶属函数及所有产生式规则，也叫模糊关联存储。隶属函数定义了模糊集的边界，这些模糊集构成了输入或输出变量的取值防伪。产生时规则能并行工作，并且根据隶属函数产生不同程度的响应。每条规则代表了模糊的专家知识或者有经验的输入与输出转换关系。一条产生式规则也能对某一数学模型作出很好的描述。通常使用计算质心的方法来对输出模糊集进行解模糊，以便得到一个确定的数值输出作用于控制系统。

本章主要用两个实例，即平衡倒立摆及科尔曼滤波器进行轨迹估计来说明模糊逻辑的广泛应用，并说明了模糊逻辑解相比于常规数学解的特点。对自适应模糊神经网络也提出了一些结构，这些模糊神经网络在每一时刻依靠样本数据和神经网络学习算法来定义或更新模糊系统。

## 9. 确定目标位置的被动数据关联 - 定位应用（对应第三章）

当获得几种不同类型的量测数据信息时，就可以进行数据的融合。例如获得的原始信号本身或者从原始信号抽取出来的各种类型的信息都可以输入到信息融合处理器中进行融合。各种信号、传感器数据以及可用的通信手段汇集在一个确定的控制系统中，要求一种最优的数据融合技术将其融合，本章主要介绍了**多传感器多目标场景中可以采用的多种数据融合的体系结构，在本章中不知道目标的径向距离信息，但是需要知道目标的方位角信息。**

通过应用数据融合技术，结合从多传感器**被动**得来的不同类型的数据，可以产生确定目标位置的航迹文件。在本章讨论的例子中，地面多个雷达装置用于对目标进行定位时，对三种不同类型的数据，分别在**三个不同层面上进行融合**。它们分别是：

1.  直接接收到的信号波形——集中式融合体系结构&像素级融合；
2.  信号波形经过信号处理获得的表征目标方向的角度信息——集中式融合体系结构&特征级融合；
3.  传感器输出的角度跟踪轨迹——分布式融合体系结构&决策级｜传感器级融合。

正因为有三种融合层面的选择，这就说明了在设计融合系统时有一定的困难，**因为在设计时应根据传感器被动接收到的数据类型选择具体的融合方法。**

这些数据融合技术可以使我们从多个被动传感器中获得径向距离信息及方向角信息、或者从主动传感器中获得角度信息及位置信息、再或者从两者的结合中得到目标的更全面的信息。

例如，融合多部电子支持（$ESM$）雷达的数据可以得到所感兴趣目标的径向距离信息；而多部预警雷达发生故障，不能提供目标的径向距离信息时，我们依然可以用和$ESM$同样的融合方法来得到径向距离信息；

在比如，可以融合来自$IRST$传感器的角度数据或者来自声音传感器等任何其他被动型传感器数据来计算目标的径向距离。

-   **当融合接受到的目标信号波形或者测量到的目标角度信号波形时，可以采用集中式融合体系结构；**
-   **当融合目标的角度跟踪轨迹时，可以采用分布式融合体系结构。**

下图给出了三种为估计目标位置而进行的被动时传感器数据融合技术。

![image-20201013095651264](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1yy9gq7j315k0qon3y.jpg)

第一种集中式数据融合体系结构融合了两个波形，这两个波形时分别来自处于接收状态的扫描预警雷达天线和另外一步被动型接收器。虽然两者搜索同样的空间，但第二部接收器时属于非扫描、多波束天线接收器。**从扫描和非扫描传感器中接收到的信号波形可以同来计算目标的径向距离。**集中式融合方法允许在更新目标的位置时与扫描预警雷达获取数据的速率保持同步，这样就可以及时生成预警空间和定位目标的确定位置。在这个融合体系结构中，多波束天线中的每个波束都需要一个处理器。为了更好地传输预警雷达波形给多波束被动接收器，常常需要宽的通信频带。被动接收器需要和各多波束处理器协调工作，然后在各处理器中完成它们之间的数据融合操作。

在第二种集中式数据融合例子中，多部处于只接收状态的预警雷达只测量角度数据，而这些角度数据描述了目标的方向。将这些角度测量传送到一个集中式处理器，运用数据互相关联技术来确定目标的径向距离。高低角和方位角或仅仅是方位角都可以作为融合处理过程的输入信号。痛殴计算所有可能的角度组合，并且找出最有可能的角度组合来消除虚警，这些虚警大多是由于多部雷达波束在没有目标的地方重叠而形成的。由于需要找到最优的量测/目标关联，由此需要进行大量搜索运算，所以就要求高性能的运算速度快处理器。当目标比较多时，高性能的处理器就成了确定这种融合体系结构是否可行的一个重要因素。**此时的数据关联处理可以建模为极大似然函数。**可以有两种方法来解这个极大似然函数问题。第一种方法是**把极大似然函数问题转化为等价的$0-1$整数规划问题来找到最优关联**；在第二种方法中，可以通过**松弛算法**来减少计算量，从而解决极大似然函数问题。尽管松弛算法所得到的是次优方向/目标关联解，但在多数情况下，这些关联大约落在最优解$1\%$的偏差范围内。

第三种分布是数据融合体系结构的对象是多条多扫描周期的角度轨迹，这些轨迹中包含了目标的方向角度信息。轨迹中包含的历史信息不仅能帮助我们计算目标的径向距离，并且还能消除由于需要去除虚警而进行的大量搜索信息。如果只知道一部传感器输出的目标角度航迹，在该传感器能够适应目标机动的情况下，也可以估计目标的径向距离。（将在本章最后加以解释，它需要iu状态的卡尔曼滤波器）。

所有这些融合结构都能计算出目标的确定位置，然而各种技术在对诸如处理器负担、传输数据的通信带宽以及实时性等方面的影响是不同的。各种处理被动接受到的数据的方法的优缺点在下表列出。下表还列出了[第三章](3. 数据融合算法与融合结构)中描述的各种融合体系结构的相互关系。每一种结构都需要在系统不同级别上进行折衷考虑。

![image-20201013102050697](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1z1697lj31620je7bl.jpg)

### 9.1 直接接收信号融合 - 像素级融合

第一种集中式融合体系结构称之为直接接收信号融合。它把来自于扫描预警雷达波形和来自于非扫描的（本章例子）具有多波束天线的被动接收器的波形结合起来，对感兴趣的范围进行搜索。将这两种传感器的波形传输到中央处理器，进行集中处理后产生用来定位信号来源的信息。

这种融合体系结构的优点是能确定目标的位置而不产生虚警。而如果采用后面将要介绍的角度数据融合时，往往会产生虚警。所谓虚警是指我们认为优有目标而实际却没有目标存在的情形**。直接接收信号融合需要传输大量相对高频的信号数据到中央处理器，因此该融合方法在通信信道上需要宽的带宽。**

下图显示了直接接收信号处理的处理技术，在这个处理过程中，扫描预警雷达波形和来自多波束天线的波形结合起来，**计算预警雷达和多波束天线信号之间的时间延迟和多普勒频移。**这些数据再加上与此同时预警雷达的指向，使用三角函数等方法就能估计出目标的位置和速度。

![image-20201013103333853](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1z2dd0hj31620je7bl.jpg)

假设处于接收信号状态的多波束天线包含有足够多的波束来搜索感兴趣的预警范围。在上图中，这个区域的目标用$"+"$来表示。**序列处理器联合处理来自预警雷达和多波束天线传来的波形，并实时监测在这两个波束的交集中是否存在目标。**由于是融合了两个波束的信息，所以可以比较准确地判断是否存在目标。多波束天线和与之配套的多个序列处理器的应用可以实现对目标位置的计算。如果后面将要介绍的角度数据融合也能计算目标位置的话，**直接接收数据融合方法的速度要比使用角度数据融合的方法的速度快。**事实上，运用这种融合方法，尽管预警雷达本身也进行径向距离的量测，但是目标的位置信息还是可以实时计算出来的。所以，当预警雷达发生故障，只能作为被动接收器时，序列处理器也能和此时的预警雷达协同工作并实时地估计出目标的位置。

#### 9.1.1. 序列处理技术

>   $Knapp$和$Carter$以及$Bendat$和$Piersol$提出了一种方法进行可靠的推理。这种方法假设多波束天线接收到的所有信号中某一信号和预警雷达接收到的信号是来源于同一目标源，并且和来源于其他目标源的信号互相独立。把来自多波束天线和预警雷达的信号都看作的是随机过程，并且用互相关统计法计算出信号对的相关性。在进行互相关统计量计算时，都需要用各自对应信号的能量去**归一化。**

在本文的应用中，$Knapp$和$Carter$的互相关统计量$\gamma(t)$由下式给出：
$$
\gamma(t) = \frac{|\int^t_{t-T}x(t)y(t-\tau)\exp(-2\pi jvt)dt|}{[\int^t_{t-T}|x(t)|^2dt\cdot\int^t_{t-T}|y(t-\tau)|^2dt]^2}
$$
这里$x(t)$和$y(t)$代表两个随机过程（信号）在前一时间间隔$T$处的**复数值**。这里时间间隔$T$等于信号的处理时间。变量$\tau$和$v$分别是**相对时间延迟**和**多普勒频移**的估计。“相对”是指来自多波束天线和预警雷达这两个信号之间的相对。

**当信号中的噪声部分互不相关时**，使用$\gamma(t)$这个统计量显得特别有效。在这种情况下，$Knapp$和$Carter$认为基于互相关统计量的假设检验（判断目标是否存在）的性能取决于：

1.  信噪比$SNR$。它是从多波束天线和预警雷达接收到的信号功率中计算出来的；
2.  时间/带宽的乘积，即信号处理时间$T$和系统的受限带宽之积。**系统的受限带宽是指以下带宽中的最小值：多波束天线接收器带宽、预警雷达带宽、序列处理器带宽以及通信信道带宽等。**在密集回波环境及相对低的信噪比情况下，互相关统计量还能提供比较高的正确判断目标是否产生某种信号的概率，同时也能给出比较低的错误判断目标存在的概率。

下图显示了对带宽序列信号用$Knapp$和$Carter$方法得到的典型结果。图左边显示了多波束天线接收到的信号的实部和虚部，图右边是对应预警雷达接收到的信号的实部和虚部。图呆萌的波形代表了序列处理器的输出结果。多普勒频移$v$和时间延迟$\tau$画在同一坐标系中。如果接收到的信号来源于同一目标，那么在某一$v$和$\tau$值处将会出现一个大幅度的尖峰值$\gamma$。如果这个尖峰值超过了预先设定的阈值，那么就认为某个目标存在。该目标的位置就可以通过三角形的正弦定义计算出来。此时的三角形是由预警雷达和多波束天线接收器以及它们所量测的方位角所确定。

![image-20201013111017012](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1z3ug9vj310q0mojw1.jpg)

下图给出了这种三角几何的计算方法。因为预警雷达是不断旋转的，所以用正弦定义计算径向距离时，可以用相对延迟时间$\tau$去修正预警雷达的方位角。对于目标的高度信息也可以从中计算出来。

![image-20201013111622663](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1z4ggqjj30qq0bmwgo.jpg)

#### 9.1.2 系统设计的几个主要方面

在基于直接接收信号的融合体系结构中，最主要的子系统是预警雷达、多波束天线包括它的波束所形成的网络、连接预警雷达和序列处理器之间的通信信道以及序列处理器本身。下表列出了影响设计序列接收器融合体系结构的几个主要方面。

![image-20201013112422115](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1z5na9gj315k0p8n4b.jpg)

该系统的复杂度和性能主要取决于设计参数之间的相互关系。复杂度主要受以下几个因素的影响：

-   对序列处理器处理能力的要求
-   被动多波束天线的设计
-   预警雷达与序列处理器之间的通信信道带宽和抗干扰能力。

而对序列处理器处理能力的要求又取决于以下几个因素：

-   波束的数目。取决于多波束天线的分辨率及它的视野角度。
-   时间延迟单元的数目以及多普勒频移单元的数目。这两者的数目直接影响到能否来自同一目标源的互相关信号搜索到一个峰值。
-   处理器的增益，这个参数主要用在假设检验中判断信号是否来自同一个源。它取决于信噪比（$SNR$），而信噪比反过来又取决于目标的空间及强度分布，而这些又与预警雷达以及多波束天线的角度分辨率有关。

在序列处理器中搜索的**时间延迟范围**直接取决于预警雷达以及多波束天线的**角度分辨率**，时间延迟单元数目**正比于**总延迟时间除以两次观测之间的间隔$T$。信号观测间隔的上限是由**预警雷达角度分辨率除以它的角度搜索速率得出的。**

**为了检测目标而进行搜索的多普勒频移范围屈居于系统的角度视野。在序列处理器中，多普勒频移单元的数目正比于总的多普勒频移除以信号的带宽。**对具有带宽回波的目标，信号带宽的上限是由雷达传递函数的带宽决定的。在雷达的限制范围内，可以独立地为观测时间间隔和信号带宽选择不同的值，使他们的乘积等于序列处理器所要求的时间-带宽积。我们在观测时机啊你间隔、时间延迟单元数目、带宽及多普勒频移单元数目之间进行折衷考虑，优化观测时间间隔和信号带宽，从而减少与序列处理器相关的计算量。

**密集回波或密集目标将对预警雷达和多波束天线输出信号的信噪比$SNR$产生不利影响。**定量的影响主要由以下几个因素决定：

-   预警雷达有效发射功率及其指向
-   多波束天线的指向
-   雷达视野中密集回波的强度分布等。

序列处理器的性能取决于输入序列处理器信号的幅值和相位。信号的带宽则取决于传输介质的时间、空间统计特性，预警雷达和多波束天线响应函数的非线性，以及预警雷达和多避暑天线之间通信信道的幅值和相位传递函数等。

**预警雷达和多波束天线之间的距离**在以下四个方面对融合系统的性能有重要影响：

1.  考虑预警雷达和多波束天线之间的通信要求，包括对于抗干扰的要求，对信号的放大和滤波要求；
2.  序列处理器搜索到目标的允许时间延迟范围；
3.  由预警雷达视野和多波束天线视野相重叠的共同的预警范围；
4.  目标定位的精度。预警雷达和多波束天线之间的典型分离距离为$50~100n \ mile(93 \ ～185km)$。另外，预警雷达和多波束天线之间的地形也要影响地对地微博通信连接的有效性。

### 9.2 角度数据融合

在被称之为角度数据融合的第二种集中式融合体系结构中，**多部预警雷达（只工作于接收信号状态）用于测量描述目标方向的方位角和高低角。**这些数据送到一个中央处理器中进行融合，进行检测到真实目标的数目并确定这些目标的径向距离。**在这种融合体系结构下，在某一时刻关联多传感器角度数据，类似于关联单传感器连续多个扫描的数据以形成航迹的情形。**

设计一个被动时预警雷达融合系统的主要内容是天线、目标检测和数据关联以及各预警雷达与中央处理单元之间的通信连接。$IRST$传感器也可以用于被动跟踪目标，各$IRST$之间的距离间隔可以减少为$10 ～ 15n \ mile(19 ～ 28km)$，因为$IRST$相比于微博雷达来说有较高的角度测量酒精度。

#### 9.2.1. 目标位置的解空间-潜在解

假设有$M$部雷达，并在其预警空间有$N$个目标，那么对每一个目标就应该有一组由$M$个雷达方向角测量组成的方向束（记为$M-$束）与之关联。当每部雷达的方向角度量测数等于目标数$N$时，那么就有$N^M$组不同的$M-$束因为真正目标的位置我们并不清楚，所以这些$M-$束都是代表潜在的目标位置。

不是所有的$M-$束都代表了一个真实的目标位置。例如，**当有$M-$束所代表的目标在同一个方向时，对某个雷达来说，量测到的目标数目将会减少。**下图就显示了这种情况。

<img src="/Users/RunshengWU/SensorFusion/Images/LocationOfErrorObject.png" alt="image-20201013130830415" style="zoom:50%;" />

假设有三个目标已被左边雷达检测到，并且用从点$M_1$发出的三条线代表对应的三个方向角度量测。再假设有两个目标已被右边雷达检测到，同样用从点$M_2$发出的两条线代表对应的两个方向角度量测。右边雷达之所以只检测到两个目标，可能是由于三个目标中有两个对右边雷达来说在同一方向上，或者是由于三个目标中有两个对右边雷达来说是在同一方向上，或者是由于右边雷达的分辨率不够而不能区分这两个目标。

在上图中，如果假设目标$1$和目标$2$对雷达$1$来说在最左边方向，而目标$3$对雷达$1$来说在中间方向，雷达$1$最右边的方向没有目标，那么这种组合就代表了一种错误的解必须加以排除，这是因为雷达$1$有三个方向量测（即雷达$1$认为有三个目标，在相对位置的三个方向（左中右））的前提没有被表现出来。我们可以通过限定所有可能解必须包含所有雷达测量数据，并且每个量测数据只能使用一次来消除错误的解。因为有$N$个目标，因此只应该识别出$N$个真正的位置，所以就有$N^M-N$组不确定的$M-$束被消除掉，因为这些$M-$束代表了在对应的位置没有真实的目标。

当每部雷达角度量测数并不相等时，潜在目标的位置必须用另一种方式来确定。对于这种情况叫下图所示的例子。

三个目标被两部雷达检测的6种潜在解在图中表示了出来。实际上只有一套由各方向角度量测的相交组合代表了一种实际的各目标的位置。在图中上半图显示了第一部雷达量测了3个目标的角度数据，用3条从点$M_1$发出的线来表示了3个量测方向，角度量测的数目用$N_1$表示，即$N_1 = 3$；第二部雷达由于它的分辨率比较差，或目标相对它而言在同一直线上，或两者的原因都具备，所以量测角度数据仅仅来源于两个目标的方向，用两条从点$M_2$发出的线来表示两个量测方向，其角度量测数目用$N_2$表示，即$N_2 = 2$。则所有相交的点数等于$N_1 \times N_2 = 6$。其余的$3$个潜在解在图的下半部分表示了出来。现在的问题是要从$6$个潜在解中找出一个解来最好地估计$3$个目标所在的位置。(图中的潜在解的点位置没有显示出来，但可以大概猜到)

![image-20201013134106310](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1z6yogkj30ws0qaaeo.jpg)

下图给出了在通常情况下由有$N$个目标和$3$部雷达时形成的不确定情形。顶部图形列出了每部雷达的角度量测数，即为$N_1,N_2$和$N_3$。左下图显示了在$N$哥目标情况下$3$部雷达波束的交织情形，此时所有交点的总数为$N_1\times N_2 \times N_3$。

图的右下方包含有四条曲线。最上方一条标有"所有可能解"的曲线代表了有$N^M$种不同的解,这些解对应着着所有雷达方向角量测组合。标有“局部可能解”的曲线代表了所有不同的受限制的解，**这个限制就是假设任何一个角度量测在定位一个目标的时候只能使用一次。**最下面的两条曲线来自于仿真结果，仿真时采用预清除技术消除了一些不可能的解。预去除的方法是：检查由各雷达方向角度量测形成的交空间，然后取出那些体积大于预先设定值的交空间，交集位置在任一雷达后面的情形也加以去除。很明显，采用预去除的方法减少了可能解的数目。对于预先处理后的解再用一些有效的搜索算法（有效是指在指定迭代步数种达到最优或接近最优解），比如用下一节将讨论的集合分裂法和松弛算法来进一步减少潜在解。右下方图中最底下的那条曲线所表示的潜在解就是这样得到的。然而即使在目标数目不是很多时，潜在解仍然保持相当大的数量（$10^4$数量级）。

![image-20201013135559744](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1z7oa9cj30wc0u043p.jpg)

如果方位角和高低角都可以由雷达测量得到，对搜索算法可以进行相当程度的简化。例如可以采用一种叫二维分配的算法，并且三雷达系统可以简化成二雷达系统。

**搜索算法的性能主要由目标的数目及雷达的分辨率决定。**在这种情况下，算法必须要做到：

1.  在最小化虚警和漏检的情况下，能一致地合理分配雷达的角度量测给各目标；
2.  能融合来自于三部或更多部雷达的方向角信息，这些雷达可能在某些情况下具有较差的分辨率，或者出现目标由分叉路径的情形；
3.  在搜索潜在解$M-$束给目标时能有效地大道实时或接近实时的应用要求。

对于三雷达系统要讨论的第一种数据关联技术是使用$0-1$整数规划来找到最优解。主要是在所有潜在$M-$束中有效地进行极大似然搜索。来自于雷达的方位角方向量测被分配给$N$个目标所在位置时由一个约束，即每个角度量测在决定目标位置时只允许使用一次，并且使用预先去除技术来减少方向角度数目，即目标的关联空间（$M-$束空间）。

第二种技术时使用松弛算法来加速数据关联过程，最后形成合适的$M-$束。采用松弛算法最后只能得到次优解，但通过这种方法得到的关联解能落在最优解$1\%$的偏差范围内。

#### 9.2.2. 0-1 整数规划算法研究

考虑一个平面区域里有$N$个目标，他们在直角坐标系下的坐标为$(x,y)$。假设这些目标位于所有雷达的预警区域内，并且能被三部独立工作的雷达（已知起位置和排列）检测到。这些雷达只检测目标相对于**正北的方向角$\theta$**。每部雷达方向量测的统计误差被认为是零均值，已知方差的高斯分布。另外，由于目标具有分叉路径等，虚假方向量测数据被认为在每个传感器视野范围内具有均匀分布。如果所有三部雷达都能检测到目标方向角（即方位角），我们就称这个目标的位置是可估计的。仅仅对可估计目标计算其位置，对那些不能被雷达分布的目标将不计算其位置。

解这一问题时，**首先把角度量测分裂成两个集合。一个集合包含了可估计目标的量测，另一集合包含了所有虚假量测，**虚假量测主要是由于量测的方位角分叉所引起的，共有$N_3-N$组$M-$束由于不正确方位角互联而产生的错误位置信息。

通过极大似然函数来分裂集合从而找到目标的最大概率位置。极大似然函数$L$是各目标位置的联合概率密度函数，它由以下公式给出：
$$
L = \prod_{\gamma = \Gamma}\frac{1}{(2\pi)^{3/2}}|\Sigma|^{-1/2}[\exp(-\frac{1}{2}\theta^T_\gamma\Sigma^{-1}\theta_{\gamma})](\frac{1}{\Phi_1})^{m_1-N}(\frac{1}{\Phi_2})^{m_2-N}(\frac{1}{\Phi_3})^{m_3-N}
$$
式中

-   $\Gamma$——代表所有真实或不确定目标位置的$3-$束集合
-   $\gamma$——对应某一目标的$3-$束雷达角度信号
-   $\Sigma$——$diag[\sigma^2_1,\sigma^2_2,\sigma^2_3]$，即有三个雷达角度量测方差构成的对角矩阵
-   $\sigma^2_r$——第$r$部（$r$在这个例子中等于$1,2$或$3$）雷达角度量测方差；
-   $\Phi_r$——第$r$部雷达的视野范围，$0 \le \Phi_r\le2\pi$；
-   $m_r$——第$r$部雷达在单位分辨率下与之相关联的方向量测数；
-   $N$——目标数
-   $\theta_r$——来自于雷达$1$、雷达$2$和雷达$3$的某一$3-$束方向角度量测矢量，$\theta_r = [\theta_{1i},\theta_{2j},\theta_{3k}]^T$，这里$i,j,k$分别表示来自雷达$1$，雷达$2$和雷达$3$的某个方向角度量测值序号。 
-   $T$——转置操作符

为了更方便搜索所有可能的$3-$束，把极大似然函数问题用与之等价的$0-1$整数规划问题来替代。**$0$代表没有把某一方向角度量测组合分配给某一$3-$束，而$1$代表把某一方向角度量测组合分配给某一$3-$束。**每个雷达提供一个方向角度作为方向角度量测组合的一个分量。

极大似然函数等价于最小化某一损失函数，这个损失函数是有式$120$的极大似然函数**取负对数**而得到的。使用损失函数并且用一系列的约束规则就能使原问题运用$0-1$整数规则算法得以解决。

当3部雷达的视野范围相同，即$\Phi_1 = \Phi_2 =\Phi_3 =\Phi$时，损失函数$C$可以被写成如下形式
$$
C = （m_1 + m_2 + m_3）ln\Phi + \sum^{m_1}_{i=1}\sum^{m_2}_{j=1}\sum^{m_3}_{k=1}(C_{ijk}-3ln\Phi)\delta_{ijk}
$$
其中：
$$
C_{ijk} = \theta^T_\gamma\Sigma^{-1}\theta_{\gamma}
$$
约束为：
$$
\sum_{i}\sum_{j}\delta_{ijk} \le 1， 对所有k \\ \sum_{i}\sum_{k}\delta_{ijk} \le 1， 对所有j  \\\sum_{j}\sum_{k}\delta_{ijk} \le 1， 对所有i 
							
$$
当选择雷达$1$和第$i$个方向角度，雷达$2$的第$j$个方向角度，雷达$3$的第$k$个方向角度时 $\delta_{ijk} = 1$

否则 $\delta_{ijk} = 0$。

约束来源于一部雷达得到的角度量测数据在形成$3-$束时只能使用一次。使用这样的约束可能会丢失某些目标的位置信息，如当雷达分辨率不是很高时就不能对每个目标提哦那个量测，活着当目标拍成一线时某些目标被挡住而不能进入雷达的视野范围内时，这些缺点因为目标的移动和传感器搜索位置的改变，将随时间的推移而得到解决。

通过去除使$C_{ijk}-3ln\Phi$为正的项，即预先分配给这些项的$\delta_{ijk} = 0$，则可以减少搜索的复杂性，因为和谐解增加了损失函数的值。在上述约束及去除正项的损失函数所对应解的情况下，$0-1$整数规划问题就转变为一个标准的$set-packing$的问题的形式。这个问题可以采用由$Pierce,Lasky,Garfinke,Nemhauser$提出的任何一种集合分离算法来求取最优解。对那些小的损失值，即使他们的损失值时负的，也可以进一步地去除他们，从而得到更简化的计算。这样做虽然只能得到优化的$3-$束，但大大减小了在求取$0-1$整数规划问题中所需要搜索的数目。因为在这个例子中用的是$3$部雷达，所以这个证书规划问题可以用$Frieze,Yadegar$提出的三维匹配算法来求解。

下面3个图，图1和图3给出了运用上面的技术所得到的结果，场景为$10$个目标、$3$部雷达。目标妍一边带区域随机分布如图1中的黑方体所示。这个边带大约在雷达以北$60n \ mile(111km)$处，3部雷达沿$x$轴分布，其坐标为$(-50,0),(0,0),(50,0)$，单位为$n \ mile（50n \ mile = 93km）$，在途中用"黑桃"表示雷达。雷达的分辨率设为$2^\circ$,雷达角度量测的标准差假设为$0.5^\circ$。

图2给出了在用**预先去除技术和其他约束**之前所有可能的候选目标的位置，用空心圈来表示这些候选目标。在图3中显示了用$ 0-1$整数规划前的所有可能目标位置。从图中可以看出，此时的候选目标由于使用预先去除技术而大大减少。最后使用约束条件并用$0-1$整数规划所得的结果在图1中显示，也用空心圈来表示候选目标。由图可以看出，$10$个真实目标中的$8$个被正确识别出来。

![image-20201013153649691](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1zathqtj30xe0lmtbc.jpg)

![image-20201013153731441](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1zi14y7j30u0189wmn.jpg)

在本例中，另外两个真实目标由于其位置距离其他目标在$2^\circ$之外，因此不能被分辨率只有$2^\circ $的雷达检测出。但因为目标是移动的，所以当目标之间的分离度大于$2^\circ$时，这个系统可以分辨出所有的目标。

用高速计算机计算能够减少使用$0-1$整数规划算法所需的计算时间。计算时间的长短与目标数量相关。因为长距离预警雷达的扫描率为$10s$，所以在目标数量有限的情况下（计算时间小于$10s$），实时运行这些算法时可行的。然而当潜在目标增加时，实时执行$0-1$整数规划算法就显得很困难，**这主要因为随着各雷达观测数目的增加，以及具有非多项式的计算与存储要求，最优算法的计算复杂度呈指数形式上升。**所以次优算法如松弛算法就看的很重要，因为他们只需要较少的计算时间。

#### 9.2.3. 松弛算法的研究

为了从潜在解中加快搜索速度，最近发展了一种使用拉格朗日松弛算法的方法。这种方法对于中等数量的目标（20个的级别），在合理计算时间内可以得到近似最优解（最优解大约$1\%$的偏差内产生传感器数据的$M-$束关联对）。在$Pattipati$等人的努力下，提出了一种用无约束的拉格朗日乘子把三维分配空间简化为一系列的二维分配空间的方法，并且在重新计算数据关联对的每一步迭代求解时，采用启发式搜索策略使次优解的损失与最优解的损失相比不断减少。**这种算法具有的特点为：在可行的次优解和全局最优解之间的误差可以进行估计，然后可以用这个误差来控制迭代的次数。**

算法运行的时间是搜索空间稀疏度和来自每个传感器报表数目的函数。**稀疏度定义为一个比值：在三维分配空间中平均潜在的方向角度量测-目标关联对的数目与全维图形空间上所有全连接的角度量测-目标关联对的比值。**这里的全维图形空间代表了传感器量测与目标的所有$M-$束关联对。举例来说，如果某全维图形空间中有$10$个节点（这里节点是指每个传感器的报表数），那么在这个三传感器系统中，就有$10^3 = 1000$对角度量测-目标关联对，再假设事实上有$M$对角度量测-目标关联对，那么该图}形的稀疏度$S$为：
$$
S = \frac{M}{1000}
$$
因此，大的稀疏度表示大的图形密度。

下表中的数据（来源于$Pattipati$等）显示了使用松弛算法相对于枝节-边界（$Branch-and-Bound$）算法在平均$20$次运行中的速度增加情况

![image-20201014142420945](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1zpeviuj314o0jmq8y.jpg)

枝节-边界算法是以结构化搜索的方式来求解的。该算法是基于只计算少量数目的可能解，因为可以通过边界的应用来消除剩下的解。枝节-边界算法涉及到两种操作：1⃣️枝节操作，也就是把可能解集合分裂成多个子集：2⃣️边界操作，也就是消除那些被认为不包含解的子集。最基本的枝节-边界算法就是不断迭代应用这两种操作。

当全维图形空间中包含有$500$对或更多的角度量测-目标关联对时，就认为枝节-边界算法是不实用的，因此也就没有计算这些情况下所运行的计算速度的快慢。下表的括号中标出了在$Sun 386i$机上用拉格朗日松弛算法所运行的平均时间。在这些特定例子中，角度量测-目标关联对问题的平均解位于最优解的$3.4\%$内。当稀疏度降低时，次优解的这个百分比还要一步降低。在另一个由$Pattipati$引用的例子中，当稀疏度为$0.25$，每个传感器的报表数为$10$时，最差的次优解位于最优解$1.2%$的偏差范围内。

尽管松弛算法提供快速的运行速度，但不能保证得到的解是最优解或接近最优解，即所得到的解对应着正确的角度量测-目标关联对。事实上，随着传感器分辨率的降低，从虚警中区分真实面将变得越来越困难。

### 9.3. 分布式融合体系结构

分布式融合体系结构首先从位于多个不同地点，处于**只接收**状态模式的传感器数据中计算出各自的方向角度轨迹，然后再从中找出目标的径向距离信息。这些航迹是由在每个不同位置的被动式传感器量测的方位角和高低角数据所形成的。这些由各传感器建立的航迹传输到融合中心后使用某种度量工具来进行关联。已经被广泛应用的度量方法是各角度航迹之间的最短距离度量和两平面之间的扭转角度量，这里两个平面指的是参考平面和目标与传感器所形成的平面。通过使用已经量测到的方向角和已知的传感器之间的距离及三角关系就可以计算出目标的径向距离信息。

在估计角度轨迹时应用了多种卡尔曼滤波器方法。在前面提到的两种度量方法的第一种方法中，每个传感器包含了两个多状态卡尔曼滤波器来跟踪方位角和高低角，滤波器中状态的数目是由目标的动态特征所决定的。在另一种方法中，方位角和高低角结合在一个滤波器中处理，但是在这种情况下，滤波器和融合算法通常要变得更复杂。不管是哪种方法，卡尔曼滤波器提供的方向角和高低角都是预测空间和量测空间的线性组合，因为输入数据（也就是方位角和高低角）其实就是我们想要对它进行修正的数据，希望它能在输出中给出更精确的数值。

数据分析开始于每个传感器航迹的初始化，并且形成尽可能多的新角度量测与航迹匹配对数来建立航迹信任度。信任度是铜鼓哦多次扫描之间的关联获得的，比如以$m$次扫描中建立$n$次关联。一种最优的分配算法即**拍卖算法**可以用来在第$n$次扫描种检测目标是否与第$n+1$次扫描中检测到的目标配对。在第$n+1$次扫描中希望匹配这样一些目标：期望他们在下次扫描中能移动到的最大相对距离范围内。可以通过计算两次扫描目标之间的距离来建立一个实用的度量函数。拍卖算法在每个扫描周期内分配最优目标配对来获得这个全局最大化实用函数。

下图显示了拍卖算法的性能。随着传感器分辨率的提高和扫描间隔的减少，算法的平均关联错误也减少。因为只依靠每个传感器产生的角度航迹来确定目标的位置是不够充分，所以有必要把局部的角度航迹文件传输到融合中心，在那里大量的航迹被融合起来以计算出目标的径向距离，并把目标的位置信息存储在全局航迹文件。

<img src="/Users/RunshengWU/SensorFusion/Images/appairage.png" alt="image-20201014145453830" style="zoom:50%;" />

#### 9.3.1 方向角度航迹关联的局部优化

首先从各传感器得到的角度航迹估计过去时间的角度信息，然后应用航迹之间某种距离度量来配对航迹，这是一种最简单的使用分布式融合体系结构来融合目标航迹的方法。当航迹见的距离小于某个预定先选定的阈值时，这些航迹就互相关联。这种技术不属于在各传感器之间全局优化的航迹关联，因为当分析了所有航迹和所有数据后，并没有保存或重新计算航迹的配对。

>   在早期的空中防御体系结构中，跟踪传感器检测到的目标往往使用这种局部航迹优化方法。

为了进行航迹局部优化关联，首先从传感器$1$中选出第一条航迹，然后与传感器$2$的第一条航迹进行比较。计算这两条航迹对的**距离度量**，比如计算方向角度航迹距离最近出的$\chi^2$值作为两轨迹之间的距离（也称之为$Mahalanobis$距离）（马氏距离）。如果这个值超过了预先设定的阈值，就抛弃这组航迹配对，因为超过阈值就意味着这组航迹配对来源于同一目标的概率不会高于我们的预先期望值，于是传感器$1$中这条航迹与传感器$2$中的下一条航迹再进行比较。这个过程一直持续到某个$\chi^2$值小于给定的阈值。直到此时，两条角度航迹才被认为是代表同一目标而结合在一起。配对成功后，**从传感器$1$和传感器$2$的可配对航迹列表中删除这两航迹**，然后在从传感器$1$中选择下一条航迹与传感器$2$中没有配对的航迹进行关联。

上述过程一直持续到传感器$1$中所有的航迹都完成关联，或者说整个要关联列表已经清空。没有配上对的航迹也保留着，以便以后与其他传感器为配上对的航迹配对。如果还有第三个传感器提供第三组可用航迹时，它可以和前面两个传感器已经融合的航迹再应用前面同样的方法进行配对，最后也同样保留未配对的航迹。当所有角度航迹都进行了这一配对过程后，对某一传感器未配上对的航迹，是因为在另一传感器量测到航迹时，有可能有某个传感器没有检验到目标。以上描述的技术方法在对传感器$1$选择航迹配对时类似于数据结构中先进先出的原则。

#### 9.3.2 方向角度航迹关联的全局优化

这里讨论两种全局优化来自于两传感器方向角度量测的关联算法。**第一种方法时基于角度方向航迹间最近距离的度量；第二种方法使用扭转角度量。**全局优化方法相对于局部优化方法而言，是以增加计算负担作为代价而实现的。

-   **最近距离作为度量单位**

    为了用最近距离度量来全局优化轨迹关联，需要更复杂的算法，比如$Munkers$算法，该算法后来由$Bourgeois$和$Lassalle$进行了扩展，即称为快速$JVC$算法。这些算法的优点是在所有可能配对都进行评估后，才决定不同传感器之间的航迹配对。通过这种方法，配对是在所有可能进行全局优化。像之前一样，首先从传感器$1$中选择第一条轨迹与传感器$2$中的第一条航迹比较，如果这两条方向角度轨迹的最近距离$\chi^2$值超过了设定的阈值时，抛弃这种配对；然后传感器 1中的这条航迹与传感器$2$中的下一条航迹再比较。这一过程一直持续到某一$\chi^2$值小于设定的阈值，此时这两条轨迹被认为是代表同一目标而进行融合，并且把这个$\chi^2$值放入配对列表中。**然而传感器$2$中这个已经配对的航迹不像以前一样从可配对列表中删除。同样，传感器$1$中的第一条航迹直到与传感器$2$中所有的轨迹都比较后才完成。一旦$\chi^2$值小于给定阈值，这个代表了一个配对的$\chi^2$值就进入配对表中。**因此这种方法会出现在传感器$1$中某条航迹有可能有多于一条潜在的航迹阈值配对的现象。
    
    然后选中传感器$1$中的下一条航迹与传感器$2$航迹列表中的第二条航迹开始比较关联。在这个算法中，**传感器$2$中以前使用过的航迹应该重复使用。**如果$\chi^2$值超过阈值，抛弃这个配对，接着传感器$1$中的这条航迹与传感器$2$中的下一条航迹再比较。当这个$\chi^2$值小于设定的阈值时，这个值就被记录进航迹配对表中。
    
    这个过程一直持续到传感器$1$中所有的航迹都关联过或轨迹列表全部用完。没有配对的航迹将作保留以便与其他传感器为配对的航迹再进行关联。如果还有第三个传感器提供第三套航迹时，通过重复使用以上过程也可以和前两个传感器已融合的航迹再进行融合。
    
    可以使用$Munkers$或快速$JVC$算法来检查表中的$\chi^2$值，这些$\chi^2$值来源于所有可能的配对。**如果角度航迹被使用过多次，这个$\chi^2$值仅仅能保证这个航迹被正确配对的可能性。**$Munkers$和$JVC$算法通过使所有传感器角度航迹配对的$\chi^2$值的和最小，重新分配航迹配对，并且算法只使用一次每个传感器的航迹。
    
    $\chi^2$值可以接受的阈值与其自由度$n_f$有关，自由度反过来又等于传感器$1$和传感器$2$中配对的角度航迹量测的数目和。如果预先给定航迹配对的正确概率，那么此时这个相对于自由度为$n_f$的$\chi^2$阈值能在$\chi^2$表中查到。
    
-   **扭转角作为度量单位**

    扭转角作为度量单位允许实时地实现角度航迹关联，从而确定目标的位置，并且还可以再连续几次扫描后初始化航迹文件。由于使用了目标和传感器之间相对简单的几何关系，所以计算量相比于$Munkers$算法而言要减少一些，该集合关系可以对传感器检测到的角度航迹进行关联。扭转角度度量允许对每个传感器建立按需排列的目标序列，然后使用该序列在各传感器之间进行一对一的关联。

    处理来自两个传感器的信息可以计算出扭转角和目标的径向距离。但是每个传感器需要一个姿态参考坐标系统，该参考系统可以被某一恒星跟踪器或全球定位系统周期性地更新修正。假设传感器具有足够高的分辨率来分辨各目标。并且对所有目标的检测是同时完成的。在偶尔情况下，可能有多个目标的位于同一平面内的情况，不能保证所有传感器都能够将其分辨出来。但随着扫描次数的增多，目标在随后的扫描中就有可能被分辨出来。如果使用三个传感器，就可以减少这种情况的出现。

    用扭转角度量首先要定义一个惟一的目标平面，该平面是基于某个视线（$LOS,line \ of \ sight$），向量和连接两个传感器的线段构成的，见下图。这里某个视线向量是指从某个传感器指向该目标的向量。每个目标平面还都包含一个共同的视线向量，这个视线向量为连续两个传感器的向量。每一个目标平面还都包含一个共同的视线向量，这个视线向量为连续两个传感器的向量。每一个目标平面都可以由一个指定的参考平面绕连接两传感器的视线向量旋转而得到。在目标平面与参考平面之间的夹角就叫扭转角。$Varad$定义了一种参考平面，它包含了两传感器之间的规范化的视线向量。$Kolitz$也定义了另一个参考平面，它包含惯性坐标系的原点，并扩展了$Varad$的处理过程，使之适用于来自三传感器的数据。

    ![image-20201014163624114](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjv1zqkxaij30og0iydhl.jpg)

    扭转角关联，由于只对一个简单的参数进行分类，因此减少了计算负担。这个待分配的参数是一个角度，即为夹在指定的参考平面和包含传感器与目标的平面之间的角度。求取这个角度的方向余弦，构成一组标量集合，并单调地排成一个序列。每个传感器都有一个有序的标量集与之对应。在理想情况下，即没有噪声和所有传感器检测到所有目标的条件下，这个代表目标角度的有序序列能被识别出来，这样在两个排序完的序列中存在一一对应关系，从而实现目标之间的关联。在非理想的现实应用中，算法为匹配由两个传感器形成的两个有序集，匹配的方法就是找两个有序集中具有最靠近的扭转角的目标相配对。

    一旦来自两个传感器的扭转角配对后，通过已知的两个对目标的视线向量之间的夹角即在两传感器之间的视线向量可以计算出目标的径向距离，因为两传感器之间的距离是已知的，所以可以定义一个三角形，三角形的第三个顶点就位于目标所处的位置，从而可以应用余弦定义计算出目标径向距离。

### 9.4. 使用单个传感器的角度航迹计算目标径向距离

目标的径向距离也可以使用来自单个被动传感器的航迹来估计，这是要求被动时传感器处于一种合适的机动状态中。在二维情形中，卡尔曼滤波器跟踪非机动目标采用修正的极坐标系$MPC$是比较合适的。使用这种坐标系减少了在直角坐标系中碰到的很多问题，如可观性、径向距离偏差和病态方差矩阵等。$MPC$滤波器可以扩展成三维时的情形，只需要把修正的极坐标系转化成修正的球坐标系$MSC$即可。这时卡尔曼跟踪滤波器的状态包括**两个角度、两个角速度、目标运动经历径向距离所需的时间的倒数。**这些状态可以转化成直角坐标系下的位置和速度。

采用$MSC$滤波器可以找到机动或非机动目标的径向距离。如果目标不处于机动状态，则径向距离可以从跟踪滤波器中的其他状态中解耦出来，如果目标处于机动状态，可以采用批次处理估计方法（一种同时处理所有观测量的方法）来预测目标将来的状态，因此任何一个成功的径向距离估计算法必须要有机地包含机动检测部分，来合理地解释来自跟踪传感器的数据。**一种传统的机动检测的方法是使用实际值和期望量测值之差（也叫残差）**的$\chi^2$值与一阈值做比较，如果$\chi^2$值这个统计量很大（即超过$0.999$的信任级别），那么就宣布机动存在，如果 $\chi^2$值这个统计量低于某个阈值，就又返回到非机动状态。当然还有其他统计量可以同来检测慢的残差积累。

### 总结

本章介绍了三种数据融合技术来定位能够发射能量的目标，这些技术能应用于被动跟踪系统，活着主动跟踪系统中。在主动跟踪系统中，由于某些原因可鞥得不到本应该得到一些信息，例如径向距离信息。这些技术使用集中式或分布式的融合体系结构来关联数据。每种技术都在数据传输和处理需求上有不同的应用效果。

在第一种集中式融合体系结构的例子中，有两种信号被有机地结合起来，一是预警雷达被动接受的信号，二是多波束天线接收的信号。**最后得到的互相关函数表达了被预警雷达接收的信号和多波束天线接收的信号是来源于同一源的可能性。**这种技术对通讯设施有比较大的影响，因为带宽宽的原始信号可以传输很远的距离。信号处理过程对系统的影响同样很大，因为时间延迟和多普勒频移的范围必须在处理时保证有一个大的搜索空间。

第二种集中式融合体系结构可以对来自每个传感器接收的方位角，或方位角和高低角等角度信息进行处理。这里最重要的是消除由于噪声或不良搜索几何位置所造成的虚警。由于是处理过的数据传输到中央融合处理器，因此相对于第一种融合体系结构而言，通信信道的带宽可以减少。一个集合包含对应着估计目标的量测，而另一个集合包含虚假量测。最后目标的定位是通过把极大似然函数问题转化为$0-1$整数规划这个比较容易解的问题而得到的。**这里把$0$分配给不能最大化目标定位的雷达方向角度信息，而把$1$分配给能最大化目标定位的方向角度信息。通过施加一些约束，比如使每部雷达角度量测数据只能使用一次和消除一些对极大似然函数不起作用的项等措施，$0-1$整数规划问题可以被有效地解决。**一个能显著地加快数据关联过程，但只得到次优解的算法在本章中也被提出，该解决方法使用了**松弛算法**，当目标的数目比较多时是特别有价值的。

在分布式融合体系结构中，对分布于不同位置的单个雷达来说需要更多的信息处理。在每部雷达中使用多扫描来进行目标互联，或使用拍卖算法从而形成每个目标的高信任度的角度航迹，这些航迹连同未关联的数据一同传输到融合中心，在那里与来自其他位置上的从传感器送来的航迹和数据进行关联。我们讨论了两种传感器-传感器的轨迹关联算法：1⃣️一种是简单的局部优化，那就是对已配对的传感器轨迹进行删除从而不参与以后的关联；2⃣️是两种全局优化技术允许来自一个传感器的航迹可以和另一个传感器的所有航迹进行关联。运用航迹间最近距离度量的$\chi^2$值或者扭转角，来全局优化正确配对来组于多个传感器的航迹。**因为大多数的目标位置被简化为航迹，所以用来把信息传输给融合中心的通信信道的带块将进一步减少，而对单个传感器的处理能力要求更高。**

对用单个传感器的角度航迹来估计径向距离，本章也提出了一种可供选择的方法，这个方法要求跟踪传感器处于机动状态并且也能确定被跟踪目标是否处于机动状态。